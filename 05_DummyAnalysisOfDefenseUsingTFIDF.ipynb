{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNzXpuv/CQMHRXnCeDT85W2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Analysis of frecuencies as a defense measure"],"metadata":{"id":"1pmrZkWxT5cs"}},{"cell_type":"code","source":["# Global variables\n","\n","BATCH_SIZE = 32\n","MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n","EPOCHS = 3\n","EMBEDDING_SIZE = 512\n","NUM_CLASSES = 2\n","VOCABULARY_SIZE = 30522\n","NUM_TOKENS = 6\n"],"metadata":{"id":"98PCmDnST5Mt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Installation of packages"],"metadata":{"id":"NFH83DBKUKL2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"59CnQshLTps0"},"outputs":[],"source":["!pip install transformers\n","!pip install torch-lr-finder"]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"TzC5liClUPj4"}},{"cell_type":"code","source":["import torch\n","import os\n","from transformers import BertTokenizer\n","from google.colab import drive\n","from torch.utils.data import TensorDataset, random_split\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import gc\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from copy import deepcopy"],"metadata":{"id":"Y15EMVB3UQ79"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Device"],"metadata":{"id":"Ur96SL8zUTHR"}},{"cell_type":"code","source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"JaoEpefgUUO7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reading dataset"],"metadata":{"id":"G_pVnM2mUYbx"}},{"cell_type":"code","source":["# Mount drive to have access to your files\n","drive.mount('/content/drive')"],"metadata":{"id":"QR46VvdsUY5E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Funtion to read all sentences\n","def get_sentences(path):\n","    sentences= []\n","    for filename in sorted(os.listdir(path)):\n","        with open(path+filename, 'r') as f:\n","            for sentence in f :\n","                sentences.append(sentence)\n","    return sentences\n","\n","# Function to read get all labels\n","def get_labels(path):\n","    all_labels = []\n","    for filename in sorted(os.listdir(path)):\n","        file_labels = []\n","        with open(path+filename, 'r') as f:\n","            for label in f :\n","                all_labels.append(int(label))\n","    return all_labels"],"metadata":{"id":"2hMqL9VGUkOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reading sentences and labels\n","all_sentences = get_sentences(\"ToS/Sentences/\")\n","all_labels = get_labels(\"ToS/Labels/\")"],"metadata":{"id":"pqgSLBRgU5O5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Since unfair sentences are marked as \"-1\", we change them to \"0\" for simplicity. Zero means fair, One means unfair\n","all_labels =  [0 if label ==-1 else label for label in all_labels]"],"metadata":{"id":"ISTv6qBoU5nY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### TFIDF of all sentences"],"metadata":{"id":"1oWFCeQNVbM6"}},{"cell_type":"markdown","source":["##### Imports"],"metadata":{"id":"iBel2FSLVsyR"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd"],"metadata":{"id":"PzPhTJsBVeRH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Functions"],"metadata":{"id":"0l4aA1GbVzi0"}},{"cell_type":"code","source":["def top_tfidf_features(row, features, top_n=15):\n","    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n","    topn_ids = np.argsort(row)[::-1][:top_n]\n","    top_feats = [(features[i], row[i]) for i in topn_ids]\n","    df = pd.DataFrame(top_feats)\n","    df.columns = ['feature', 'tfidf']\n","    return df\n","\n","\n","def top_features_in_doc(Xtr, features, row_id, top_n=60):#15\n","    ''' Top tfidf features in specific document (matrix row) '''\n","    xtr_row = Xtr[row_id]\n","    if type(xtr_row) is not np.ndarray:\n","        xtr_row = xtr_row.toarray()\n","    row = np.squeeze(xtr_row)\n","    return top_tfidf_features(row, features, top_n)\n","\n","\n","def span_top_tfidf(spans_txt, spans_tfidf, features, index):\n","    print('span text:\\n'+spans_txt[index]+' ('+str(index)+')\\n')\n","    print(top_features_in_doc(spans_tfidf, features, index))"],"metadata":{"id":"Kc8zlueoVyds"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Implementation"],"metadata":{"id":"e82qMck9V9e1"}},{"cell_type":"code","source":["tfidf_vectorizer = TfidfVectorizer(min_df=5)#TfidfVectorizer(tokenizer=sentences_custom.get_tokens_spacy, min_df=5, ngram_range=(1,1))\n","tfidf_vectorizer = tfidf_vectorizer.fit(all_sentences)\n","tfidf_features_skl = tfidf_vectorizer.get_feature_names_out()\n","\n","sentences_tfidf_skl = tfidf_vectorizer.transform(all_sentences).toarray()"],"metadata":{"id":"OMGJm0iDV-9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["span_top_tfidf(all_sentences, \n","               sentences_tfidf_skl,\n","               tfidf_features_skl,\n","               5092\n",")"],"metadata":{"id":"6YeZcArVWIXn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test = \"unless the everyone 10.1 if a dispute arises between you and linden lab regarding a claim , you and we agree to alternative dispute resolution .\" #3572\n","#test = \"unless the everyone all information provided as part of our registration process is covered by our privacy policy .\" #885\n","#test = \"unless the everyone you may not copy , modify , distribute , sell , or lease any part of our services or included software , nor may you reverse engineer or attempt to extract the source code of that software , unless laws prohibit those restrictions or you have our written permission .\" #2731\n","test = \"unless the everyone 19.3 to the extent that the provisions in section 18 do not apply , you further agree that all disputes , causes of action , claims or controversies arising under these terms that can not be settled through informal negotiation will be resolved exclusively in the united states district court for the northern district of california or a state court located in san mateo county , and you agree to submit to the personal jurisdiction of such courts for the purposes of litigating all such claims .\" #5092\n","array_test = [test]\n","index = 5092"],"metadata":{"id":"O4S0KTljYNQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in sentences_tfidf_skl[index]:\n","  if i != 0:\n","    print(i, end=\" \")"],"metadata":{"id":"gjap-gCVZnbn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences_tfidf_skl_test = tfidf_vectorizer.transform(array_test).toarray()"],"metadata":{"id":"O1bKGdG2Zop1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["span_top_tfidf(array_test, \n","               sentences_tfidf_skl_test,\n","               tfidf_features_skl,\n","               0)"],"metadata":{"id":"ElEHYPpQawks"},"execution_count":null,"outputs":[]}]}