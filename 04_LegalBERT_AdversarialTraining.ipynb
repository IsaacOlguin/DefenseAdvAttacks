{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LegalBERT_AdversarialTraining.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOmVuxatsCoCkeOrN9415RE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"00ddb6055b934148b64a2e18286d611c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81bd782cf05b4994946f7a442813bdc7","IPY_MODEL_406cc5ee72984d5f8026b975c6f94704","IPY_MODEL_52212e79d27d456095d2111d2f8ecfd1"],"layout":"IPY_MODEL_76657dd80081483db1758fb05c8b9e86"}},"81bd782cf05b4994946f7a442813bdc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d6146a555a24f32b609e1e836ab6854","placeholder":"​","style":"IPY_MODEL_4f518e0353134d7e949bd009de6f78b5","value":"Downloading vocab.txt: 100%"}},"406cc5ee72984d5f8026b975c6f94704":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b162d72af9c4b42afba38d10ab3fbc2","max":221792,"min":0,"orientation":"horizontal","style":"IPY_MODEL_205dde9a09b2409ba71aee29f3542117","value":221792}},"52212e79d27d456095d2111d2f8ecfd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb33947f35194e87ac901d1f37929f9e","placeholder":"​","style":"IPY_MODEL_805e9165ebef4bcfafa471d6648fbc04","value":" 217k/217k [00:00&lt;00:00, 267kB/s]"}},"76657dd80081483db1758fb05c8b9e86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d6146a555a24f32b609e1e836ab6854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f518e0353134d7e949bd009de6f78b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b162d72af9c4b42afba38d10ab3fbc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"205dde9a09b2409ba71aee29f3542117":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb33947f35194e87ac901d1f37929f9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"805e9165ebef4bcfafa471d6648fbc04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a1c366cb38b4ae7beca57bd086f2f02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfacae5cc8594386b99e82c67b096599","IPY_MODEL_29b8a5a376374ee29e33dbbbd61c491b","IPY_MODEL_e9de3f95983a4c8b93bc09587631ca06"],"layout":"IPY_MODEL_1b2fc38eeac5485bb8a8113c19720060"}},"cfacae5cc8594386b99e82c67b096599":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a64ea4811f4e494bae54986d16650f51","placeholder":"​","style":"IPY_MODEL_a35e81c1cc8d4f6c9511d0b94cc43b8c","value":"Downloading tokenizer_config.json: 100%"}},"29b8a5a376374ee29e33dbbbd61c491b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0ec3b7ca6e941ad98e0b1a21ed876e8","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d15119df655542e98380a689eba34b75","value":48}},"e9de3f95983a4c8b93bc09587631ca06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6484c1a2fc634251b53be45aaf019fe9","placeholder":"​","style":"IPY_MODEL_a84aeebe93bf4559bf2a9cadae1bab46","value":" 48.0/48.0 [00:00&lt;00:00, 1.79kB/s]"}},"1b2fc38eeac5485bb8a8113c19720060":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a64ea4811f4e494bae54986d16650f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a35e81c1cc8d4f6c9511d0b94cc43b8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0ec3b7ca6e941ad98e0b1a21ed876e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d15119df655542e98380a689eba34b75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6484c1a2fc634251b53be45aaf019fe9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a84aeebe93bf4559bf2a9cadae1bab46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41b7e52ea2804768964ff40a2cfd9a8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_adc5424a2f9e4756a88b127a6b26ef82","IPY_MODEL_105873afb87d40eabdd37c9dfbe8aa73","IPY_MODEL_abe34e4f47f744829565a7af13049575"],"layout":"IPY_MODEL_fa75ca781a7a4dfb89928e01b95bdb88"}},"adc5424a2f9e4756a88b127a6b26ef82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a45a351007c54a419bd083d9e7eecd71","placeholder":"​","style":"IPY_MODEL_5aa5bde5a1194d6b9cc5d2377bd90e24","value":"Downloading config.json: 100%"}},"105873afb87d40eabdd37c9dfbe8aa73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f293513706f4470927d126d82ae595d","max":989,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2946337d9d6c4d2e87e465718349366d","value":989}},"abe34e4f47f744829565a7af13049575":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_877925f2eab044b78e86648a59df5ee6","placeholder":"​","style":"IPY_MODEL_d3de9ae183a04c33a17fe79e6030ffcb","value":" 989/989 [00:00&lt;00:00, 36.7kB/s]"}},"fa75ca781a7a4dfb89928e01b95bdb88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a45a351007c54a419bd083d9e7eecd71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aa5bde5a1194d6b9cc5d2377bd90e24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f293513706f4470927d126d82ae595d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2946337d9d6c4d2e87e465718349366d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"877925f2eab044b78e86648a59df5ee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3de9ae183a04c33a17fe79e6030ffcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe986c4ed2334492b55d300f0db8df7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76668edea300449c8d07093fae771efc","IPY_MODEL_2b03042293e24b0d836e337dde31c7b9","IPY_MODEL_6d8110f9e0a54f14b6b184281847630a"],"layout":"IPY_MODEL_4d288f6fd5ee4e4c95febb756557ad17"}},"76668edea300449c8d07093fae771efc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37628cedb2f2401985ae3119c8ec1353","placeholder":"​","style":"IPY_MODEL_292eaa8e09194dc79ebc7188fc7312f3","value":"Downloading pytorch_model.bin: 100%"}},"2b03042293e24b0d836e337dde31c7b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1bb601df13d4460a8163c97df215d27","max":141480422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73fdb52ae29b4f9caf45e86a13f8c55d","value":141480422}},"6d8110f9e0a54f14b6b184281847630a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cde73d5c593744b38729d4932eba2eb8","placeholder":"​","style":"IPY_MODEL_e769478ca6f141bf8c95ad39c99edcfe","value":" 135M/135M [00:02&lt;00:00, 66.4MB/s]"}},"4d288f6fd5ee4e4c95febb756557ad17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37628cedb2f2401985ae3119c8ec1353":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"292eaa8e09194dc79ebc7188fc7312f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1bb601df13d4460a8163c97df215d27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73fdb52ae29b4f9caf45e86a13f8c55d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cde73d5c593744b38729d4932eba2eb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e769478ca6f141bf8c95ad39c99edcfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# ***Adversarial Training Legal BERT***\n","\n","This notebook combines the LegalBert model classifier as well as the trigger generation. The implementation is structured as follows:\n","* Read files\n","* Generate tokens (no natural). The previous model is taken into consideration to know what words make the model to perform the worst. N (100) candidates are taken per token (i.e. if it's desired to generate 3 tokens that will be added (concatenated) at the beginning, end or randomly. Then, 100 candidates are taken per each of those 3 tokens). These values are stored in and array, s.t. at the end, we can create new sentences using them.\n","* Data Augmentation. Generated tokens are used to generate new sentences.\n","* Adversarial training. A new model is created using the original dataset and the augmented samples.\n","\n","\n","Technnological details:\n","* Model name: LegalBert (nlpaueb/legal-bert-small-uncased)\n","* Class model: BertForSequenceClassification\n","* Batch size: 16|32\n","* Embedding size: 512 (default)\n","* Dataset: Claudette (Terms of Service)\n","* Num classes: 2 (just considered as a binary classification as {Fair|Unfair} sentences)\n","* Vocabulary size: 30,522 (default)\n","* Num tokens: 3|4|6"],"metadata":{"id":"7pdKG_0kdKNY"}},{"cell_type":"markdown","source":["### Global variables"],"metadata":{"id":"ph2Sd0V0f8zA"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"OtMDzI63cxXF","executionInfo":{"status":"ok","timestamp":1659681797192,"user_tz":-120,"elapsed":11,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"outputs":[],"source":["# Global variables\n","\n","BATCH_SIZE = 32\n","MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n","EPOCHS = 3\n","EMBEDDING_SIZE = 512\n","NUM_CLASSES = 2\n","VOCABULARY_SIZE = 30522\n","NUM_TOKENS = 10\n","DEFAULT_TOKEN = 207 # What in BERT represents the word \"the\"\n","LIST_ID_SPECIAL_TOKENS = [0, 101, 102, 103]\n","LIST_SPECIAL_TOKENS = ['[PAD]', '[CLS]', '[SEP]', '[MASK]']"]},{"cell_type":"markdown","source":["### Installation of packages"],"metadata":{"id":"GkoBzkPfgGbV"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install torch-lr-finder"],"metadata":{"id":"yvLTD3JcgJjj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659681815708,"user_tz":-120,"elapsed":18523,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"68403bf9-ee02-4445-9cc7-51cce25c286a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 16.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 10.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 66.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch-lr-finder\n","  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.64.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.3)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.12.0+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.1.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.4.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n","Installing collected packages: torch-lr-finder\n","Successfully installed torch-lr-finder-0.2.1\n"]}]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"qTV9i90-gMrK"}},{"cell_type":"code","source":["import torch\n","import os\n","from transformers import BertTokenizer\n","from google.colab import drive\n","from torch.utils.data import TensorDataset, random_split\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import gc\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from copy import deepcopy\n","from datetime import datetime\n","import datetime"],"metadata":{"id":"sr1sOPFfgOC1","executionInfo":{"status":"ok","timestamp":1659681822288,"user_tz":-120,"elapsed":6592,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Mount on GoogleDrive"],"metadata":{"id":"jH9Kb1j6gski"}},{"cell_type":"code","source":["# Mount drive to have access to your files\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/\"Colab Notebooks\"/DefenseAdvAttacks"],"metadata":{"id":"ieb8-zc_gvw9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659681853115,"user_tz":-120,"elapsed":30836,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"c3be5dde-66e2-4c7c-dde3-dbb57ad04e38"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/DefenseAdvAttacks\n"]}]},{"cell_type":"markdown","source":["### Device"],"metadata":{"id":"_vK3qX7DgQWi"}},{"cell_type":"code","source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"5Bdcy5UAgRVf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659681853546,"user_tz":-120,"elapsed":32,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"9e9547f1-5440-43a3-8648-ee28825a90d7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"markdown","source":["### Reading original dataset"],"metadata":{"id":"osD8Dk0mgjmd"}},{"cell_type":"code","source":["# Funtion to read all sentences\n","def get_sentences(path):\n","    sentences= []\n","    for filename in sorted(os.listdir(path)):\n","        with open(path+filename, 'r') as f:\n","            for sentence in f :\n","                if sentence.strip() != '':\n","                    sentences.append(sentence)\n","    return sentences\n","\n","# Function to read get all labels\n","def get_labels(path):\n","    all_labels = []\n","    for filename in sorted(os.listdir(path)):\n","        file_labels = []\n","        with open(path+filename, 'r') as f:\n","            for label in f :\n","                if label.strip() != '':\n","                    all_labels.append(int(label))\n","    return all_labels"],"metadata":{"id":"DudLv10rgX8t","executionInfo":{"status":"ok","timestamp":1659681853548,"user_tz":-120,"elapsed":23,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Reading sentences and labels of the Claudette Dataset\n","all_sentences = get_sentences(\"ToS/TrainValSet/Sentences/\")\n","all_labels = get_labels(\"ToS/TrainValSet/Labels/\")\n","\n","# Conversion of unfair sentence's flag|tag. Since unfair sentences are marked as \"-1\", we change them to \"0\" for simplicity. \n","#   Zero means fair, \n","#   One means unfair\n","all_labels =  [0 if label ==-1 else label for label in all_labels]"],"metadata":{"id":"-Mm3CtQmhKZw","executionInfo":{"status":"ok","timestamp":1659681857390,"user_tz":-120,"elapsed":3860,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## **Trigger Generation**"],"metadata":{"id":"GmMyL6l6hgfi"}},{"cell_type":"markdown","source":["### Bert (Model, Tokenizer and Load)"],"metadata":{"id":"VojPVT9why_j"}},{"cell_type":"code","source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True) # the model 'bert-base-uncased' only contains lower case sentences"],"metadata":{"id":"K7BsbevuhvaT","colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["00ddb6055b934148b64a2e18286d611c","81bd782cf05b4994946f7a442813bdc7","406cc5ee72984d5f8026b975c6f94704","52212e79d27d456095d2111d2f8ecfd1","76657dd80081483db1758fb05c8b9e86","6d6146a555a24f32b609e1e836ab6854","4f518e0353134d7e949bd009de6f78b5","8b162d72af9c4b42afba38d10ab3fbc2","205dde9a09b2409ba71aee29f3542117","cb33947f35194e87ac901d1f37929f9e","805e9165ebef4bcfafa471d6648fbc04","1a1c366cb38b4ae7beca57bd086f2f02","cfacae5cc8594386b99e82c67b096599","29b8a5a376374ee29e33dbbbd61c491b","e9de3f95983a4c8b93bc09587631ca06","1b2fc38eeac5485bb8a8113c19720060","a64ea4811f4e494bae54986d16650f51","a35e81c1cc8d4f6c9511d0b94cc43b8c","b0ec3b7ca6e941ad98e0b1a21ed876e8","d15119df655542e98380a689eba34b75","6484c1a2fc634251b53be45aaf019fe9","a84aeebe93bf4559bf2a9cadae1bab46","41b7e52ea2804768964ff40a2cfd9a8d","adc5424a2f9e4756a88b127a6b26ef82","105873afb87d40eabdd37c9dfbe8aa73","abe34e4f47f744829565a7af13049575","fa75ca781a7a4dfb89928e01b95bdb88","a45a351007c54a419bd083d9e7eecd71","5aa5bde5a1194d6b9cc5d2377bd90e24","3f293513706f4470927d126d82ae595d","2946337d9d6c4d2e87e465718349366d","877925f2eab044b78e86648a59df5ee6","d3de9ae183a04c33a17fe79e6030ffcb"]},"executionInfo":{"status":"ok","timestamp":1659681865717,"user_tz":-120,"elapsed":8353,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"d0ca46be-fe7b-4c6f-c23c-743b6e0424fa"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/217k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00ddb6055b934148b64a2e18286d611c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a1c366cb38b4ae7beca57bd086f2f02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/989 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41b7e52ea2804768964ff40a2cfd9a8d"}},"metadata":{}}]},{"cell_type":"markdown","source":["In case that it's desired to know basic functions how to convert sentences to tokens or the other way around.\n","\n","```\n","# ==> Example of first sentence\n","\n","# Print the original sentence.\n","print(' Original: ', all_sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(all_sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(all_sentences[0])))\n","```\n","\n"],"metadata":{"id":"kotGUF2liGj_"}},{"cell_type":"markdown","source":["To get the max length of a sentence within the dataset (sentences that have been already read)\n","```\n","# ==> Get the max length of a sentence\n","\n","max_len = 0\n","\n","# For every sentence...\n","for sent in all_sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)\n","```\n","\n","Output:\n","```\n","Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n","\n","Max sentence length:  598\n","```\n","\n"],"metadata":{"id":"OPrdoqOLibPR"}},{"cell_type":"markdown","source":["### Model BertForSequenceClassification (Load model)"],"metadata":{"id":"M7vhHZYAi7sm"}},{"cell_type":"code","source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = NUM_CLASSES, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"id":"-2fcQVw-i1eb","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["fe986c4ed2334492b55d300f0db8df7f","76668edea300449c8d07093fae771efc","2b03042293e24b0d836e337dde31c7b9","6d8110f9e0a54f14b6b184281847630a","4d288f6fd5ee4e4c95febb756557ad17","37628cedb2f2401985ae3119c8ec1353","292eaa8e09194dc79ebc7188fc7312f3","e1bb601df13d4460a8163c97df215d27","73fdb52ae29b4f9caf45e86a13f8c55d","cde73d5c593744b38729d4932eba2eb8","e769478ca6f141bf8c95ad39c99edcfe"]},"executionInfo":{"status":"ok","timestamp":1659681877614,"user_tz":-120,"elapsed":11903,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"b9fb31ef-dadb-427f-ca4a-2679013cec7e"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe986c4ed2334492b55d300f0db8df7f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n","      (position_embeddings): Embedding(512, 512)\n","      (token_type_embeddings): Embedding(2, 512)\n","      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=512, out_features=512, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Load the model and dictionary\n","model.load_state_dict(torch.load('Bert4SeqClassif_20220804_1134_wPersistency.pt'))#, map_location=torch.device('cpu') or cuda. Both work"],"metadata":{"id":"DLgYcXdvjH37","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659681881076,"user_tz":-120,"elapsed":3481,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"ebe30761-fac4-4e40-fc2b-c25db6ce6acc"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### Trigger generation"],"metadata":{"id":"6ov6kgpbjZF1"}},{"cell_type":"markdown","source":["##### General functions"],"metadata":{"id":"fHepLK4AkHD_"}},{"cell_type":"code","source":["# hook used in add_hooks()\n","extracted_grads = []\n","def extract_grad_hook(module, grad_in, grad_out):\n","    extracted_grads.append(grad_out[0])\n","\n","# returns the wordpiece embedding weight matrix\n","def get_embedding_weight(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522: # only add a hook to wordpiece embeddings, not position embeddings \n","                ##50257 is the size of the vocabulary of GPT\n","                return module.weight.detach()\n","\n","# add hooks for embeddings\n","def add_hooks(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522: # only add a hook to wordpiece embeddings, not position\n","                ##50257 is the size of the vocabulary of GPT\n","                module.weight.requires_grad = True\n","                #module.register_backward_hook(extract_grad_hook)\n","                module.register_full_backward_hook(extract_grad_hook)\n","\n","\n","# creates the batch of target texts with -1 placed at the end of the sequences for padding (for masking out the loss).\n","def make_target_batch(tokenizer, device, target_texts):\n","    # encode items and get the max length\n","    encoded_texts = []\n","    max_len = 0\n","    for target_text in target_texts:\n","        encoded_target_text = tokenizer.encode_plus(\n","            target_text,\n","            add_special_tokens = True,\n","            max_length = EMBEDDING_SIZE - NUM_TOKENS,\n","            pad_to_max_length = True,\n","            return_attention_mask = True\n","        )\n","        encoded_texts.append(encoded_target_text.input_ids)\n","        if len(encoded_target_text.input_ids) > max_len:\n","            max_len = len(encoded_target_text)\n","\n","    # pad tokens, i.e., append -1 to the end of the non-longest ones\n","    for indx, encoded_text in enumerate(encoded_texts):\n","        if len(encoded_text) < max_len:\n","            encoded_texts[indx].extend([-1] * (max_len - len(encoded_text)))\n","\n","    # convert to tensors and batch them up\n","    target_tokens_batch = None\n","    for encoded_text in encoded_texts:\n","        target_tokens = torch.tensor(encoded_text, device=device, dtype=torch.long).unsqueeze(0)\n","        if target_tokens_batch is None:\n","            target_tokens_batch = target_tokens\n","        else:\n","            target_tokens_batch = torch.cat((target_tokens, target_tokens_batch), dim=0)\n","    return target_tokens_batch\n","\n","# Got from https://github.com/Eric-Wallace/universal-triggers/blob/master/attacks.py\n","def hotflip_attack(averaged_grad, embedding_matrix, trigger_token_ids,\n","                   increase_loss=False, num_candidates=1):\n","    \"\"\"\n","    The \"Hotflip\" attack described in Equation (2) of the paper. This code is heavily inspired by\n","    the nice code of Paul Michel here https://github.com/pmichel31415/translate/blob/paul/\n","    pytorch_translate/research/adversarial/adversaries/brute_force_adversary.py\n","    This function takes in the model's average_grad over a batch of examples, the model's\n","    token embedding matrix, and the current trigger token IDs. It returns the top token\n","    candidates for each position.\n","    If increase_loss=True, then the attack reverses the sign of the gradient and tries to increase\n","    the loss (decrease the model's probability of the true class). For targeted attacks, you want\n","    to decrease the loss of the target class (increase_loss=False).\n","    \"\"\"\n","    averaged_grad = averaged_grad.cpu()\n","    embedding_matrix = embedding_matrix.cpu()\n","    trigger_token_embeds = torch.nn.functional.embedding(torch.LongTensor(trigger_token_ids),\n","                                                         embedding_matrix).detach().unsqueeze(0)\n","    averaged_grad = averaged_grad.unsqueeze(0)\n","    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n","                                                 (averaged_grad, embedding_matrix))        \n","    if not increase_loss:\n","        gradient_dot_embedding_matrix *= -1    # lower versus increase the class probability.\n","    if num_candidates > 1: # get top k options\n","        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n","        return best_k_ids.detach().cpu().numpy()[0]\n","    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n","    return best_at_each_step[0].detach().cpu().numpy()\n","\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"xTpEhRQmjNEQ","executionInfo":{"status":"ok","timestamp":1659681881077,"user_tz":-120,"elapsed":26,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def get_input_masks_and_labels_with_tokens(sentences, labels, tokens, position='B'):\n","    input_ids = []\n","    attention_masks = []\n","    number_of_tokens = []\n","\n","    for sent in sentences:\n","\n","        if position == 'B':\n","            sent_with_tokens = tokens + \" \" + sent\n","        elif position == 'E':\n","            sent_with_tokens = sent + \" \" + tokens\n","        else:\n","            print('Wrong position command, please enter \"E\" or \"B\"')\n","            return\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                        sent_with_tokens,\n","                        add_special_tokens = True,\n","                        max_length = 512,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt',\n","                   )\n","\n","\n","        input_ids.append(encoded_dict['input_ids'])\n","\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","\n","    # count number of tokens of each sentence\n","    for idx in range(len(input_ids)):\n","      sent_ids = input_ids[idx, :]\n","\n","      cnt = 0\n","      for id in sent_ids:\n","          if id != 0:\n","              cnt += 1\n","\n","      number_of_tokens.append(cnt)  \n","\n","    return input_ids, attention_masks, labels, number_of_tokens"],"metadata":{"id":"eiuMnLcZkR2j","executionInfo":{"status":"ok","timestamp":1659681881078,"user_tz":-120,"elapsed":23,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def get_loss_and_metrics(model, dataloader, device):\n","    # get initial loss for the trigger\n","    model.zero_grad()\n","\n","    test_preds = []\n","    test_targets = []\n","\n","    # Tracking variables \n","    total_test_accuracy = 0\n","    total_test_loss = 0\n","    io_total_test_acc = 0\n","    io_total_test_prec = 0\n","    io_total_test_recall = 0\n","    io_total_test_f1 = 0\n","\n","    for batch in dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        result = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels,\n","                    return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Accumulate the validation loss.\n","        total_test_loss += loss.item()\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        loss.backward()        \n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.        \n","        test_acc = accuracy_score(test_targets, test_preds)\n","        test_precision = precision_score(test_targets, test_preds)\n","        test_recall = recall_score(test_targets, test_preds)\n","        test_f1 = f1_score(test_targets, test_preds)\n","\n","        io_total_test_acc += test_acc\n","        io_total_test_prec += test_precision\n","        io_total_test_recall += test_recall\n","        io_total_test_f1 += test_f1\n","\n","    io_avg_test_loss = total_test_loss/len(dataloader)\n","    io_avg_test_acc = io_total_test_acc / len(dataloader)\n","    io_avg_test_prec = io_total_test_prec / len(dataloader)\n","    io_avg_test_recall = io_total_test_recall / len(dataloader)\n","    io_avg_test_f1 = io_total_test_f1 / len(dataloader)\n","    \"\"\"\n","    print(\n","            f'Loss {io_avg_test_loss} : \\t\\\n","            Valid_acc : {io_avg_test_acc}\\t\\\n","            Valid_F1 : {io_avg_test_f1}\\t\\\n","            Valid_precision : {io_avg_test_prec}\\t\\\n","            Valid_recall : {io_avg_test_recall}'\n","          )\n","    \"\"\"\n","\n","    return io_avg_test_loss, io_avg_test_acc, io_avg_test_prec, io_avg_test_recall, io_avg_test_f1"],"metadata":{"id":"cVi1JG1ekMkL","executionInfo":{"status":"ok","timestamp":1659681881079,"user_tz":-120,"elapsed":22,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def change_input_ids_with_candidate_token(input_ids, position, candidate, number_of_tokens, trigger_position='B'):\n","    if trigger_position == 'B':\n","        input_ids[:, position] = candidate\n","    elif trigger_position == 'E':\n","        for idx in range(len(input_ids)):\n","            if number_of_tokens[idx] > EMBEDDING_SIZE:\n","                input_ids[idx, EMBEDDING_SIZE-NUM_TOKENS-2+position] = candidate\n","            else:\n","                input_ids[idx, number_of_tokens[idx]-NUM_TOKENS-2+position] = candidate\n","    else:\n","        print('Wrong position command, please enter \"E\" or \"B\"')\n","        return\n","    return input_ids"],"metadata":{"id":"yoPr3yJe1xrG","executionInfo":{"status":"ok","timestamp":1659681881079,"user_tz":-120,"elapsed":20,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["##### Execution of the trigger generation"],"metadata":{"id":"XJsvcJua2FVP"}},{"cell_type":"markdown","source":["###### Get unfair sentences"],"metadata":{"id":"G4fBirI72W6s"}},{"cell_type":"code","source":["positions_unfair = np.where(np.array(all_labels) == 1)[0]\n","print(f'First 32 positions: {positions_unfair[0:32]} with total of unfair sentences {len(positions_unfair)}')\n","\n","target_unfair_sentences = []\n","labels_unfair_sentences = []\n","for index in range(len(positions_unfair)):\n","    target_unfair_sentences.append(all_sentences[positions_unfair[index]])\n","    labels_unfair_sentences.append(all_labels[positions_unfair[index]])\n","\n","# Initialization of tokens with the particle \"the\" whose id number in BERT model is 207\n","trigger_tokens = np.array([DEFAULT_TOKEN]*NUM_TOKENS)\n","print(tokenizer.decode(trigger_tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTKzAMth1-64","executionInfo":{"status":"ok","timestamp":1659681881080,"user_tz":-120,"elapsed":19,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"c9bcb092-85f4-431e-b3ed-c92a992b4ca8"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["First 32 positions: [  7  12  15  24  26  48  54  57  61  62  77  93 102 104 143 151 161 163\n"," 183 194 200 205 219 226 237 241 244 265 275 278 282 294] with total of unfair sentences 991\n","the the the the the the the the the the\n"]}]},{"cell_type":"markdown","source":["###### Addition of hooks and get word embeddings"],"metadata":{"id":"7G6pl7nF2vCB"}},{"cell_type":"code","source":["model.eval()\n","model.to(device)\n","\n","add_hooks(model) # add gradient hooks to embeddings\n","embedding_weight = get_embedding_weight(model) # save the word embedding matrix"],"metadata":{"id":"hUPKtMir24Ww","executionInfo":{"status":"ok","timestamp":1659681881081,"user_tz":-120,"elapsed":14,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["###### Get tensors and creation of dataset and dataloader"],"metadata":{"id":"IBgwSKMk275K"}},{"cell_type":"code","source":["## Define at which position we want to have the triggers\n","position = 'B' # Possible values {B|E} for beginning and end, respectively\n","\n","input_ids, attention_masks, labels, number_of_tokens = get_input_masks_and_labels_with_tokens(target_unfair_sentences, labels_unfair_sentences, tokenizer.decode(trigger_tokens), position=position)\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yv4m7W-w3LQb","executionInfo":{"status":"ok","timestamp":1659681883991,"user_tz":-120,"elapsed":2923,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"35c736c3-6cbd-4fcc-c7eb-b6fc3e0ed549"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","source":["###### Execution of trigger generation"],"metadata":{"id":"qH9EPKm73or2"}},{"cell_type":"code","source":["timestamp = datetime.datetime.now().strftime(\"%y%m%d_%H_%M_%S_%p\")\n","f = open(f\"Execution_Pos{position}_NumTokens_{NUM_TOKENS}_{timestamp}.txt\", \"w\")"],"metadata":{"id":"qJc-5gdiRmpu","executionInfo":{"status":"ok","timestamp":1659681952971,"user_tz":-120,"elapsed":1059,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["candidates_dict = {}\n","candidates_dict[\"combinations_ids\"] = []\n","candidates_dict[\"combinations_labels\"] = []\n","foundX = -1\n","foundY = -1\n","candidates_combination = [DEFAULT_TOKEN]*NUM_TOKENS\n","goalTag = 'Loss'\n","\n","extracted_grads = []\n","\n","loss_obtained, acc_obtained, prec_obtained, recall_obtained, f1_obtained = get_loss_and_metrics(model, dataloader, device)\n","#print(f'loss_obtained {loss_obtained}')\n","\n","candidates_selected = [DEFAULT_TOKEN]*NUM_TOKENS\n","# try all the candidates and pick the best\n","curr_best_loss = loss_obtained\n","curr_best_trigger_tokens = None\n","\n","print(f\"{position}[{foundX:3},{foundY:3}] TokenID[{candidates_combination}] TokensDesc[{tokenizer.decode(candidates_combination)}] Loss[{loss_obtained:3.5}] Acc[{acc_obtained:3.5}] Prec[{prec_obtained:3.5}] Recall[{recall_obtained:3.5}] F1[{f1_obtained:3.5}] => Worst<<{goalTag}>>[{curr_best_loss:3.5}] Found at [{foundX:3},{foundY:3}]\")\n","f.write(f'{position}[{foundX:3},{foundY:3}] TokenID[{candidates_combination}] TokensDesc[{tokenizer.decode(candidates_combination)}] Loss[{loss_obtained:3.5}] Acc[{acc_obtained:3.5}] Prec[{prec_obtained:3.5}] Recall[{recall_obtained:3.5}] F1[{f1_obtained:3.5}] => Worst<<{goalTag}>>[{curr_best_loss:3.5}] Found at [{foundX:3},{foundY:3}]')\n","\n","for id_token_to_flip in range(0, NUM_TOKENS):\n","\n","    averaged_grad = torch.sum(extracted_grads[0], dim=0)\n","    averaged_grad = averaged_grad[id_token_to_flip].unsqueeze(0)\n","\n","    # Use hotflip (linear approximation) attack to get the top num_candidates\n","    candidates = hotflip_attack(averaged_grad, embedding_weight,\n","                                        [trigger_tokens[id_token_to_flip]], \n","                                        increase_loss=False, num_candidates=100)[0]\n","    print(f'candidates {candidates}')\n","    f.write(f'{position} candidates {candidates}')\n","    candidates_dict[id_token_to_flip] = candidates\n","    \n","    for index, cand in enumerate(candidates):\n","        extracted_grads = []\n","\n","        if cand in LIST_ID_SPECIAL_TOKENS:\n","          continue\n","\n","        input_ids_with_candidate_trigger = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, cand, number_of_tokens, trigger_position=position)\n","        dataset_with_candidate_trigger = TensorDataset(input_ids_with_candidate_trigger, attention_masks, labels)\n","        dataloader_with_candidate_trigger = torch.utils.data.DataLoader(dataset_with_candidate_trigger, batch_size=BATCH_SIZE)\n","\n","        current_loss, current_acc, current_prec, current_recall, current_f1 = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device)\n","\n","        if curr_best_loss < current_loss:\n","            curr_best_loss = current_loss\n","            candidates_selected[id_token_to_flip] = cand\n","\n","            foundX = id_token_to_flip\n","            foundY = index\n","        candidates_combination[id_token_to_flip] = cand\n","        candidates_dict[\"combinations_ids\"].append(candidates_combination)\n","        candidates_dict[\"combinations_labels\"].append(tokenizer.decode(candidates_combination))\n","        print(f'[{id_token_to_flip:3},{index:3}] TokenID[{candidates_combination}] TokensDesc[{tokenizer.decode(candidates_combination)}] Loss[{current_loss:3.5}] Acc[{current_acc:3.5}] Prec[{current_prec:3.5}] Recall[{current_recall:3.5}] F1[{current_f1:3.5}] => Worst<<{goalTag}>>[{curr_best_loss:3.5}] Found at [{foundX:3},{foundY:3}]')\n","        f.write(f'{position}[{id_token_to_flip:3},{index:3}] TokenID[{candidates_combination}] TokensDesc[{tokenizer.decode(candidates_combination)}] Loss[{current_loss:3.5}] Acc[{current_acc:3.5}] Prec[{current_prec:3.5}] Recall[{current_recall:3.5}] F1[{current_f1:3.5}] => Worst<<{goalTag}>>[{curr_best_loss:3.5}] Found at [{foundX:3},{foundY:3}]\\n')\n","        \n","        del input_ids_with_candidate_trigger\n","        del dataset_with_candidate_trigger\n","        del dataloader_with_candidate_trigger\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        #print(f'Candidates selected {candidates_selected} VS candidates_combination {candidates_combination}')\n","        #print(f'[{id_token_to_flip}][{index}] loss[{index}] {current_loss} ({curr_best_loss})')\n","\n","    candidates_combination = deepcopy(candidates_selected)\n","    #extracted_grads = []\n","    input_ids = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, candidates_selected[id_token_to_flip], number_of_tokens, trigger_position=position)\n","    print(f'Worst loss {curr_best_loss} with candidates {candidates_selected} in the {id_token_to_flip}-iteration with tokens [{tokenizer.decode(candidates_selected)}]')\n","    f.write(f'{position}Worst loss {curr_best_loss} with candidates {candidates_selected}\\n')\n","f.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sG9jGWwL3t7d","executionInfo":{"status":"ok","timestamp":1659703523997,"user_tz":-120,"elapsed":21569871,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"88ff9659-3fb6-4c11-d977-7d1fa0bb9df2"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["B[ -1, -1] TokenID[[207, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[the the the the the the the the the the] Loss[0.36082] Acc[0.91466] Prec[1.0] Recall[0.91466] F1[0.95527] => Worst<<Loss>>[0.36082] Found at [ -1, -1]\n","candidates [ 4303  5557   908 18883  2436   906 11734  2143  7716  9828  1534  1664\n"," 13916  4599  6665   460 14170  8397  2399   608  1744  7391  1923  6493\n","  3053 18451  7770 15846  2012  3705  3641  1865  1791  6563   266  1824\n"," 20750 21649   986  2225  2527  9496 18858  9148  4839  2823  2921 17225\n"," 13417  6983   377 18554 17779  4691  4065  3566  5072  3643  4270  6021\n"," 19052  3750  1126   579  1412  9978  8530 13248  4084  8625 12708  4374\n"," 14391 15476  5340  6054  7396  5818 14225 11858 23063  3309 11865  1263\n","   753  1072 14479   699  6532  3770  6247  1968 21822 16204  2596  6637\n"," 13959 11356  3437 29347]\n","[  0,  0] TokenID[[4303, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[suffering the the the the the the the the the] Loss[0.34799] Acc[0.91692] Prec[1.0] Recall[0.91692] F1[0.95651] => Worst<<Loss>>[0.36082] Found at [ -1, -1]\n","[  0,  1] TokenID[[5557, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[actively the the the the the the the the the] Loss[0.35868] Acc[0.91172] Prec[1.0] Recall[0.91172] F1[0.95371] => Worst<<Loss>>[0.36082] Found at [ -1, -1]\n","[  0,  2] TokenID[[908, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[award the the the the the the the the the] Loss[0.46872] Acc[0.86991] Prec[1.0] Recall[0.86991] F1[0.93027] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0,  3] TokenID[[18883, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[minds the the the the the the the the the] Loss[0.36454] Acc[0.9093] Prec[1.0] Recall[0.9093] F1[0.95232] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0,  4] TokenID[[2436, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[awards the the the the the the the the the] Loss[0.42105] Acc[0.88819] Prec[1.0] Recall[0.88819] F1[0.94066] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0,  5] TokenID[[906, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[settlement the the the the the the the the the] Loss[0.43981] Acc[0.87606] Prec[1.0] Recall[0.87606] F1[0.93378] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0,  6] TokenID[[11734, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[silence the the the the the the the the the] Loss[0.43147] Acc[0.88805] Prec[1.0] Recall[0.88805] F1[0.94054] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0,  7] TokenID[[2143, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[contractual the the the the the the the the the] Loss[0.3462] Acc[0.91988] Prec[1.0] Recall[0.91988] F1[0.95812] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0,  8] TokenID[[7716, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[inaction the the the the the the the the the] Loss[0.25469] Acc[0.92671] Prec[1.0] Recall[0.92671] F1[0.96191] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0,  9] TokenID[[9828, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[victor the the the the the the the the the] Loss[0.38722] Acc[0.907] Prec[1.0] Recall[0.907] F1[0.95109] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0, 10] TokenID[[1534, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[events the the the the the the the the the] Loss[0.33569] Acc[0.91813] Prec[1.0] Recall[0.91813] F1[0.95718] => Worst<<Loss>>[0.46872] Found at [  0,  2]\n","[  0, 11] TokenID[[1664, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[decree the the the the the the the the the] Loss[0.50004] Acc[0.8553] Prec[1.0] Recall[0.8553] F1[0.92188] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 12] TokenID[[13916, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[##win the the the the the the the the the] Loss[0.33205] Acc[0.91478] Prec[1.0] Recall[0.91478] F1[0.95538] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 13] TokenID[[4599, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[negotiate the the the the the the the the the] Loss[0.36278] Acc[0.91224] Prec[1.0] Recall[0.91224] F1[0.95398] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 14] TokenID[[6665, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[excuse the the the the the the the the the] Loss[0.45811] Acc[0.87682] Prec[1.0] Recall[0.87682] F1[0.93419] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 15] TokenID[[460, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[evidence the the the the the the the the the] Loss[0.45577] Acc[0.87617] Prec[1.0] Recall[0.87617] F1[0.93391] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 16] TokenID[[14170, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[unsuccessfully the the the the the the the the the] Loss[0.32428] Acc[0.92175] Prec[1.0] Recall[0.92175] F1[0.95914] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 17] TokenID[[8397, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[honour the the the the the the the the the] Loss[0.40628] Acc[0.89042] Prec[1.0] Recall[0.89042] F1[0.94192] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 18] TokenID[[2399, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[negotiations the the the the the the the the the] Loss[0.3826] Acc[0.90878] Prec[1.0] Recall[0.90878] F1[0.95203] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 19] TokenID[[608, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[agreements the the the the the the the the the] Loss[0.34846] Acc[0.91523] Prec[1.0] Recall[0.91523] F1[0.95563] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 20] TokenID[[1744, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[oral the the the the the the the the the] Loss[0.37755] Acc[0.90794] Prec[1.0] Recall[0.90794] F1[0.95162] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 21] TokenID[[7391, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[awarding the the the the the the the the the] Loss[0.41346] Acc[0.90136] Prec[1.0] Recall[0.90136] F1[0.94796] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 22] TokenID[[1923, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[plea the the the the the the the the the] Loss[0.45571] Acc[0.8694] Prec[1.0] Recall[0.8694] F1[0.92993] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 23] TokenID[[6493, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[emotional the the the the the the the the the] Loss[0.34719] Acc[0.91243] Prec[1.0] Recall[0.91243] F1[0.9541] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 24] TokenID[[3053, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[denial the the the the the the the the the] Loss[0.41856] Acc[0.88202] Prec[1.0] Recall[0.88202] F1[0.93722] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 25] TokenID[[18451, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[verbally the the the the the the the the the] Loss[0.35664] Acc[0.91318] Prec[1.0] Recall[0.91318] F1[0.95449] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 26] TokenID[[7770, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[lengthy the the the the the the the the the] Loss[0.32126] Acc[0.92352] Prec[1.0] Recall[0.92352] F1[0.9601] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 27] TokenID[[15846, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[economical the the the the the the the the the] Loss[0.34929] Acc[0.91621] Prec[1.0] Recall[0.91621] F1[0.95614] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 28] TokenID[[2012, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[early the the the the the the the the the] Loss[0.38932] Acc[0.89024] Prec[1.0] Recall[0.89024] F1[0.94184] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 29] TokenID[[3705, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[settle the the the the the the the the the] Loss[0.43475] Acc[0.88251] Prec[1.0] Recall[0.88251] F1[0.93746] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 30] TokenID[[3641, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[encourage the the the the the the the the the] Loss[0.42336] Acc[0.88462] Prec[1.0] Recall[0.88462] F1[0.93871] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 31] TokenID[[1865, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[physical the the the the the the the the the] Loss[0.36673] Acc[0.91071] Prec[1.0] Recall[0.91071] F1[0.95315] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 32] TokenID[[1791, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[just the the the the the the the the the] Loss[0.46234] Acc[0.87998] Prec[1.0] Recall[0.87998] F1[0.93599] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 33] TokenID[[6563, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[behavior the the the the the the the the the] Loss[0.33517] Acc[0.91907] Prec[1.0] Recall[0.91907] F1[0.9577] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 34] TokenID[[266, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[law the the the the the the the the the] Loss[0.31452] Acc[0.9241] Prec[1.0] Recall[0.9241] F1[0.96043] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 35] TokenID[[1824, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[am the the the the the the the the the] Loss[0.40858] Acc[0.90307] Prec[1.0] Recall[0.90307] F1[0.94891] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 36] TokenID[[20750, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[yoursel the the the the the the the the the] Loss[0.34724] Acc[0.91213] Prec[1.0] Recall[0.91213] F1[0.95393] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 37] TokenID[[21649, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[parol the the the the the the the the the] Loss[0.44395] Acc[0.88645] Prec[1.0] Recall[0.88645] F1[0.93959] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 38] TokenID[[986, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[courts the the the the the the the the the] Loss[0.30502] Acc[0.92423] Prec[1.0] Recall[0.92423] F1[0.96049] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 39] TokenID[[2225, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[awarded the the the the the the the the the] Loss[0.4385] Acc[0.88638] Prec[1.0] Recall[0.88638] F1[0.93964] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 40] TokenID[[2527, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[automatically the the the the the the the the the] Loss[0.39057] Acc[0.90319] Prec[1.0] Recall[0.90319] F1[0.949] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 41] TokenID[[9496, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[strikes the the the the the the the the the] Loss[0.36579] Acc[0.90668] Prec[1.0] Recall[0.90668] F1[0.95092] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 42] TokenID[[18858, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[hell the the the the the the the the the] Loss[0.34028] Acc[0.91613] Prec[1.0] Recall[0.91613] F1[0.95608] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 43] TokenID[[9148, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[arithmetic the the the the the the the the the] Loss[0.35728] Acc[0.91538] Prec[1.0] Recall[0.91538] F1[0.95572] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 44] TokenID[[4839, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[implication the the the the the the the the the] Loss[0.37707] Acc[0.90523] Prec[1.0] Recall[0.90523] F1[0.9501] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 45] TokenID[[2823, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[propose the the the the the the the the the] Loss[0.43651] Acc[0.89238] Prec[1.0] Recall[0.89238] F1[0.94305] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 46] TokenID[[2921, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[mind the the the the the the the the the] Loss[0.41074] Acc[0.90212] Prec[1.0] Recall[0.90212] F1[0.94837] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 47] TokenID[[17225, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[impunity the the the the the the the the the] Loss[0.36557] Acc[0.90358] Prec[1.0] Recall[0.90358] F1[0.94921] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 48] TokenID[[13417, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[frustration the the the the the the the the the] Loss[0.31582] Acc[0.92117] Prec[1.0] Recall[0.92117] F1[0.95884] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 49] TokenID[[6983, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[physically the the the the the the the the the] Loss[0.36508] Acc[0.91061] Prec[1.0] Recall[0.91061] F1[0.95309] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 50] TokenID[[377, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[event the the the the the the the the the] Loss[0.38019] Acc[0.90468] Prec[1.0] Recall[0.90468] F1[0.94983] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 51] TokenID[[18554, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[grie the the the the the the the the the] Loss[0.33165] Acc[0.91652] Prec[1.0] Recall[0.91652] F1[0.9563] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 52] TokenID[[17779, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[##amy the the the the the the the the the] Loss[0.37003] Acc[0.91175] Prec[1.0] Recall[0.91175] F1[0.95367] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 53] TokenID[[4691, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[sue the the the the the the the the the] Loss[0.42467] Acc[0.87555] Prec[1.0] Recall[0.87555] F1[0.93352] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 54] TokenID[[4065, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[signatures the the the the the the the the the] Loss[0.40196] Acc[0.90721] Prec[1.0] Recall[0.90721] F1[0.9512] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 55] TokenID[[3566, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[email the the the the the the the the the] Loss[0.46941] Acc[0.88296] Prec[1.0] Recall[0.88296] F1[0.93776] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 56] TokenID[[5072, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[gravit the the the the the the the the the] Loss[0.34234] Acc[0.91486] Prec[1.0] Recall[0.91486] F1[0.95544] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 57] TokenID[[3643, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[181 the the the the the the the the the] Loss[0.32926] Acc[0.91776] Prec[1.0] Recall[0.91776] F1[0.95699] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 58] TokenID[[4270, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[pleas the the the the the the the the the] Loss[0.37442] Acc[0.91296] Prec[1.0] Recall[0.91296] F1[0.95433] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 59] TokenID[[6021, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[ordering the the the the the the the the the] Loss[0.45619] Acc[0.87704] Prec[1.0] Recall[0.87704] F1[0.93439] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 60] TokenID[[19052, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[##asta the the the the the the the the the] Loss[0.36502] Acc[0.9098] Prec[1.0] Recall[0.9098] F1[0.95265] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 61] TokenID[[3750, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[attempted the the the the the the the the the] Loss[0.37703] Acc[0.91025] Prec[1.0] Recall[0.91025] F1[0.95285] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 62] TokenID[[1126, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[remedies the the the the the the the the the] Loss[0.31031] Acc[0.91869] Prec[1.0] Recall[0.91869] F1[0.95752] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 63] TokenID[[579, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[performance the the the the the the the the the] Loss[0.33653] Acc[0.91756] Prec[1.0] Recall[0.91756] F1[0.95687] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 64] TokenID[[1412, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[language the the the the the the the the the] Loss[0.4245] Acc[0.89595] Prec[1.0] Recall[0.89595] F1[0.94502] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 65] TokenID[[9978, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[arbitrate the the the the the the the the the] Loss[0.37865] Acc[0.90269] Prec[1.0] Recall[0.90269] F1[0.9487] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 66] TokenID[[8530, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[excessively the the the the the the the the the] Loss[0.33142] Acc[0.91585] Prec[1.0] Recall[0.91585] F1[0.95594] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 67] TokenID[[13248, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[reinstate the the the the the the the the the] Loss[0.35758] Acc[0.91102] Prec[1.0] Recall[0.91102] F1[0.95334] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 68] TokenID[[4084, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[negotiation the the the the the the the the the] Loss[0.38177] Acc[0.90699] Prec[1.0] Recall[0.90699] F1[0.95109] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 69] TokenID[[8625, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[plainly the the the the the the the the the] Loss[0.40523] Acc[0.89449] Prec[1.0] Recall[0.89449] F1[0.94416] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 70] TokenID[[12708, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[anna the the the the the the the the the] Loss[0.35871] Acc[0.91288] Prec[1.0] Recall[0.91288] F1[0.95433] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 71] TokenID[[4374, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[recommend the the the the the the the the the] Loss[0.47119] Acc[0.86924] Prec[1.0] Recall[0.86924] F1[0.92994] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 72] TokenID[[14391, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[myself the the the the the the the the the] Loss[0.35935] Acc[0.91899] Prec[1.0] Recall[0.91899] F1[0.95764] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 73] TokenID[[15476, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[proffer the the the the the the the the the] Loss[0.42534] Acc[0.89724] Prec[1.0] Recall[0.89724] F1[0.9457] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 74] TokenID[[5340, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[instances the the the the the the the the the] Loss[0.40936] Acc[0.88968] Prec[1.0] Recall[0.88968] F1[0.94152] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 75] TokenID[[6054, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[elimination the the the the the the the the the] Loss[0.33972] Acc[0.91752] Prec[1.0] Recall[0.91752] F1[0.95686] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 76] TokenID[[7396, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[bench the the the the the the the the the] Loss[0.40605] Acc[0.90165] Prec[1.0] Recall[0.90165] F1[0.94817] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 77] TokenID[[5818, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[plead the the the the the the the the the] Loss[0.38632] Acc[0.89104] Prec[1.0] Recall[0.89104] F1[0.9423] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 78] TokenID[[14225, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[amicabl the the the the the the the the the] Loss[0.32763] Acc[0.91857] Prec[1.0] Recall[0.91857] F1[0.95743] => Worst<<Loss>>[0.50004] Found at [  0, 11]\n","[  0, 79] TokenID[[11858, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram the the the the the the the the the] Loss[0.64178] Acc[0.80362] Prec[1.0] Recall[0.80362] F1[0.89102] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 80] TokenID[[23063, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[mediate the the the the the the the the the] Loss[0.39616] Acc[0.89824] Prec[1.0] Recall[0.89824] F1[0.94627] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 81] TokenID[[3309, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[personally the the the the the the the the the] Loss[0.40038] Acc[0.90786] Prec[1.0] Recall[0.90786] F1[0.95156] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 82] TokenID[[11865, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[tacit the the the the the the the the the] Loss[0.38002] Acc[0.91195] Prec[1.0] Recall[0.91195] F1[0.95377] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 83] TokenID[[1263, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[judicial the the the the the the the the the] Loss[0.35204] Acc[0.91223] Prec[1.0] Recall[0.91223] F1[0.95393] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 84] TokenID[[753, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[agree the the the the the the the the the] Loss[0.28209] Acc[0.92944] Prec[1.0] Recall[0.92944] F1[0.96333] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 85] TokenID[[1072, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[expressly the the the the the the the the the] Loss[0.3228] Acc[0.92167] Prec[1.0] Recall[0.92167] F1[0.95911] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 86] TokenID[[14479, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[prayer the the the the the the the the the] Loss[0.41888] Acc[0.89124] Prec[1.0] Recall[0.89124] F1[0.94237] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 87] TokenID[[699, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[writing the the the the the the the the the] Loss[0.44018] Acc[0.88332] Prec[1.0] Recall[0.88332] F1[0.93799] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 88] TokenID[[6532, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[learned the the the the the the the the the] Loss[0.42273] Acc[0.892] Prec[1.0] Recall[0.892] F1[0.94282] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 89] TokenID[[3770, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[relieve the the the the the the the the the] Loss[0.37273] Acc[0.88989] Prec[1.0] Recall[0.88989] F1[0.94162] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 90] TokenID[[6247, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[kar the the the the the the the the the] Loss[0.34326] Acc[0.91613] Prec[1.0] Recall[0.91613] F1[0.95608] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 91] TokenID[[1968, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[seek the the the the the the the the the] Loss[0.38935] Acc[0.89615] Prec[1.0] Recall[0.89615] F1[0.94513] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 92] TokenID[[21822, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[##termination the the the the the the the the the] Loss[0.32367] Acc[0.92172] Prec[1.0] Recall[0.92172] F1[0.95914] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 93] TokenID[[16204, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[##iam the the the the the the the the the] Loss[0.37469] Acc[0.90838] Prec[1.0] Recall[0.90838] F1[0.95185] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 94] TokenID[[2596, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[disputes the the the the the the the the the] Loss[0.33315] Acc[0.91326] Prec[1.0] Recall[0.91326] F1[0.95451] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 95] TokenID[[6637, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[posting the the the the the the the the the] Loss[0.36338] Acc[0.91116] Prec[1.0] Recall[0.91116] F1[0.95339] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 96] TokenID[[13959, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[incarceration the the the the the the the the the] Loss[0.36836] Acc[0.91168] Prec[1.0] Recall[0.91168] F1[0.95364] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 97] TokenID[[11356, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[authorship the the the the the the the the the] Loss[0.34951] Acc[0.91348] Prec[1.0] Recall[0.91348] F1[0.95467] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 98] TokenID[[3437, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[fifteen the the the the the the the the the] Loss[0.36882] Acc[0.9153] Prec[1.0] Recall[0.9153] F1[0.95562] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  0, 99] TokenID[[29347, 207, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[##vab the the the the the the the the the] Loss[0.3543] Acc[0.91276] Prec[1.0] Recall[0.91276] F1[0.95424] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","Worst loss 0.6417847410325082 with candidates [11858, 207, 207, 207, 207, 207, 207, 207, 207, 207] in the 0-iteration with tokens [telegram the the the the the the the the the]\n","candidates [10900 26376 24881 11373  9480 22822 15287 23249 22149 20045 19987 13428\n","  9570 27416 17933 30367 27388 28039 10964 29828 19103 25203 23196 12474\n"," 10146  5018  9090  1772  5306 13228 28090 24453 22295  5601  6900 21754\n","  6357 28336 30152 30516 17307 11160 19815  4378 26570 25012 22108  4370\n"," 22012 27175 27039  8748 12492 28550 28022 27512 28128  4620 29478 30312\n"," 19487 27179 14310 20143  3224 26476 26090 21945 20894 12825  5453 18769\n","  3611 20065 25852 16773 24197 25740 27689  8098 20801 27821 27632 18205\n"," 18316 13482 11580 17506 30252 15301 16038 26417 24439 16855  6545 26575\n"," 20478 26317 14170 24347]\n","[  1,  0] TokenID[[11858, 10900, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram rptr the the the the the the the the] Loss[0.57543] Acc[0.8313] Prec[1.0] Recall[0.8313] F1[0.90778] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  1] TokenID[[11858, 26376, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram yonk the the the the the the the the] Loss[0.60471] Acc[0.8147] Prec[1.0] Recall[0.8147] F1[0.8978] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  2] TokenID[[11858, 24881, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramrizo the the the the the the the the] Loss[0.59514] Acc[0.82098] Prec[1.0] Recall[0.82098] F1[0.90161] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  3] TokenID[[11858, 11373, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram arguabl the the the the the the the the] Loss[0.47439] Acc[0.87984] Prec[1.0] Recall[0.87984] F1[0.93597] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  4] TokenID[[11858, 9480, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram sarban the the the the the the the the] Loss[0.57487] Acc[0.82397] Prec[1.0] Recall[0.82397] F1[0.90343] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  5] TokenID[[11858, 22822, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram buckey the the the the the the the the] Loss[0.61387] Acc[0.81032] Prec[1.0] Recall[0.81032] F1[0.89511] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  6] TokenID[[11858, 15287, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramsight the the the the the the the the] Loss[0.51459] Acc[0.85934] Prec[1.0] Recall[0.85934] F1[0.92423] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  7] TokenID[[11858, 23249, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram shaba the the the the the the the the] Loss[0.58171] Acc[0.83012] Prec[1.0] Recall[0.83012] F1[0.90706] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  8] TokenID[[11858, 22149, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramasserted the the the the the the the the] Loss[0.56457] Acc[0.83049] Prec[1.0] Recall[0.83049] F1[0.9073] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1,  9] TokenID[[11858, 20045, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram sulfa the the the the the the the the] Loss[0.6151] Acc[0.81494] Prec[1.0] Recall[0.81494] F1[0.89794] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 10] TokenID[[11858, 19987, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramibi the the the the the the the the] Loss[0.5462] Acc[0.83844] Prec[1.0] Recall[0.83844] F1[0.91202] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 11] TokenID[[11858, 13428, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramfolia the the the the the the the the] Loss[0.6104] Acc[0.81162] Prec[1.0] Recall[0.81162] F1[0.8959] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 12] TokenID[[11858, 9570, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram arguable the the the the the the the the] Loss[0.4856] Acc[0.86974] Prec[1.0] Recall[0.86974] F1[0.93025] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 13] TokenID[[11858, 27416, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramcrystallin the the the the the the the the] Loss[0.59233] Acc[0.82196] Prec[1.0] Recall[0.82196] F1[0.9022] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 14] TokenID[[11858, 17933, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram stam the the the the the the the the] Loss[0.55157] Acc[0.8339] Prec[1.0] Recall[0.8339] F1[0.90938] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 15] TokenID[[11858, 30367, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram congenital the the the the the the the the] Loss[0.5657] Acc[0.83486] Prec[1.0] Recall[0.83486] F1[0.90982] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 16] TokenID[[11858, 27388, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramchemi the the the the the the the the] Loss[0.568] Acc[0.82852] Prec[1.0] Recall[0.82852] F1[0.9061] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 17] TokenID[[11858, 28039, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram stoic the the the the the the the the] Loss[0.60199] Acc[0.82105] Prec[1.0] Recall[0.82105] F1[0.90165] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 18] TokenID[[11858, 10964, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram indus the the the the the the the the] Loss[0.57976] Acc[0.8267] Prec[1.0] Recall[0.8267] F1[0.90501] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 19] TokenID[[11858, 29828, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram scler the the the the the the the the] Loss[0.60355] Acc[0.82075] Prec[1.0] Recall[0.82075] F1[0.9014] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 20] TokenID[[11858, 19103, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramopol the the the the the the the the] Loss[0.61438] Acc[0.80537] Prec[1.0] Recall[0.80537] F1[0.89206] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 21] TokenID[[11858, 25203, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram tjhe the the the the the the the the] Loss[0.58811] Acc[0.81692] Prec[1.0] Recall[0.81692] F1[0.89913] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 22] TokenID[[11858, 23196, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram plausibl the the the the the the the the] Loss[0.49718] Acc[0.86712] Prec[1.0] Recall[0.86712] F1[0.92874] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 23] TokenID[[11858, 12474, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram frydlender the the the the the the the the] Loss[0.57072] Acc[0.82755] Prec[1.0] Recall[0.82755] F1[0.90552] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 24] TokenID[[11858, 10146, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram impermissibl the the the the the the the the] Loss[0.52689] Acc[0.85776] Prec[1.0] Recall[0.85776] F1[0.9233] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 25] TokenID[[11858, 5018, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramchlor the the the the the the the the] Loss[0.63988] Acc[0.80278] Prec[1.0] Recall[0.80278] F1[0.89045] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 26] TokenID[[11858, 9090, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramurea the the the the the the the the] Loss[0.61233] Acc[0.81042] Prec[1.0] Recall[0.81042] F1[0.89516] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 27] TokenID[[11858, 1772, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram supp the the the the the the the the] Loss[0.60539] Acc[0.81159] Prec[1.0] Recall[0.81159] F1[0.89591] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 28] TokenID[[11858, 5306, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram mezzanin the the the the the the the the] Loss[0.59846] Acc[0.82143] Prec[1.0] Recall[0.82143] F1[0.90182] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 29] TokenID[[11858, 13228, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram hostilit the the the the the the the the] Loss[0.5543] Acc[0.83503] Prec[1.0] Recall[0.83503] F1[0.90998] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 30] TokenID[[11858, 28090, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram almen the the the the the the the the] Loss[0.54686] Acc[0.83922] Prec[1.0] Recall[0.83922] F1[0.91247] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 31] TokenID[[11858, 24453, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram unpredictabl the the the the the the the the] Loss[0.55136] Acc[0.84141] Prec[1.0] Recall[0.84141] F1[0.91379] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 32] TokenID[[11858, 22295, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram zagor the the the the the the the the] Loss[0.60513] Acc[0.81801] Prec[1.0] Recall[0.81801] F1[0.89981] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 33] TokenID[[11858, 5601, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram larges the the the the the the the the] Loss[0.57335] Acc[0.82577] Prec[1.0] Recall[0.82577] F1[0.90451] => Worst<<Loss>>[0.64178] Found at [  0, 79]\n","[  1, 34] TokenID[[11858, 6900, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth the the the the the the the the] Loss[0.6676] Acc[0.79873] Prec[1.0] Recall[0.79873] F1[0.88798] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 35] TokenID[[11858, 21754, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram deteriorat the the the the the the the the] Loss[0.53592] Acc[0.84183] Prec[1.0] Recall[0.84183] F1[0.91398] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 36] TokenID[[11858, 6357, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram lacked the the the the the the the the] Loss[0.5616] Acc[0.84509] Prec[1.0] Recall[0.84509] F1[0.91596] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 37] TokenID[[11858, 28336, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram repugnan the the the the the the the the] Loss[0.58833] Acc[0.81566] Prec[1.0] Recall[0.81566] F1[0.89834] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 38] TokenID[[11858, 30152, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramuip the the the the the the the the] Loss[0.59176] Acc[0.82011] Prec[1.0] Recall[0.82011] F1[0.90107] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 39] TokenID[[11858, 30516, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram, the the the the the the the the] Loss[0.59887] Acc[0.81766] Prec[1.0] Recall[0.81766] F1[0.89953] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 40] TokenID[[11858, 17307, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram fdc the the the the the the the the] Loss[0.56841] Acc[0.82954] Prec[1.0] Recall[0.82954] F1[0.90672] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 41] TokenID[[11858, 11160, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram tendenc the the the the the the the the] Loss[0.59924] Acc[0.81321] Prec[1.0] Recall[0.81321] F1[0.8969] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 42] TokenID[[11858, 19815, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramtriti the the the the the the the the] Loss[0.5746] Acc[0.82527] Prec[1.0] Recall[0.82527] F1[0.9042] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 43] TokenID[[11858, 4378, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram bylaw the the the the the the the the] Loss[0.60712] Acc[0.81743] Prec[1.0] Recall[0.81743] F1[0.89926] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 44] TokenID[[11858, 26570, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram rsfs the the the the the the the the] Loss[0.63776] Acc[0.8154] Prec[1.0] Recall[0.8154] F1[0.89812] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 45] TokenID[[11858, 25012, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram ramz the the the the the the the the] Loss[0.58846] Acc[0.82152] Prec[1.0] Recall[0.82152] F1[0.90194] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 46] TokenID[[11858, 22108, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram odes the the the the the the the the] Loss[0.60978] Acc[0.81071] Prec[1.0] Recall[0.81071] F1[0.89537] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 47] TokenID[[11858, 4370, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram insofar the the the the the the the the] Loss[0.62278] Acc[0.80938] Prec[1.0] Recall[0.80938] F1[0.89457] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 48] TokenID[[11858, 22012, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram liq the the the the the the the the] Loss[0.62381] Acc[0.80473] Prec[1.0] Recall[0.80473] F1[0.89167] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 49] TokenID[[11858, 27175, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram distri the the the the the the the the] Loss[0.61557] Acc[0.80784] Prec[1.0] Recall[0.80784] F1[0.89358] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 50] TokenID[[11858, 27039, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramraco the the the the the the the the] Loss[0.62648] Acc[0.80863] Prec[1.0] Recall[0.80863] F1[0.89407] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 51] TokenID[[11858, 8748, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram nlr the the the the the the the the] Loss[0.63204] Acc[0.80399] Prec[1.0] Recall[0.80399] F1[0.89124] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 52] TokenID[[11858, 12492, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram presidi the the the the the the the the] Loss[0.62328] Acc[0.80915] Prec[1.0] Recall[0.80915] F1[0.89442] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 53] TokenID[[11858, 28550, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram9606 the the the the the the the the] Loss[0.58452] Acc[0.82164] Prec[1.0] Recall[0.82164] F1[0.90202] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 54] TokenID[[11858, 28022, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram blurr the the the the the the the the] Loss[0.5229] Acc[0.8541] Prec[1.0] Recall[0.8541] F1[0.92121] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 55] TokenID[[11858, 27512, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegrametamine the the the the the the the the] Loss[0.60534] Acc[0.81278] Prec[1.0] Recall[0.81278] F1[0.89662] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 56] TokenID[[11858, 28128, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegrambashi the the the the the the the the] Loss[0.62338] Acc[0.80486] Prec[1.0] Recall[0.80486] F1[0.89173] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 57] TokenID[[11858, 4620, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram additionally the the the the the the the the] Loss[0.54414] Acc[0.84247] Prec[1.0] Recall[0.84247] F1[0.91441] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 58] TokenID[[11858, 29478, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramdavid the the the the the the the the] Loss[0.59625] Acc[0.82118] Prec[1.0] Recall[0.82118] F1[0.90167] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 59] TokenID[[11858, 30312, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram nonfrivolous the the the the the the the the] Loss[0.57038] Acc[0.82806] Prec[1.0] Recall[0.82806] F1[0.90589] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 60] TokenID[[11858, 19487, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramghli the the the the the the the the] Loss[0.59048] Acc[0.81904] Prec[1.0] Recall[0.81904] F1[0.90043] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 61] TokenID[[11858, 27179, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram 1598 the the the the the the the the] Loss[0.59504] Acc[0.81541] Prec[1.0] Recall[0.81541] F1[0.89822] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 62] TokenID[[11858, 14310, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram 078 the the the the the the the the] Loss[0.61249] Acc[0.812] Prec[1.0] Recall[0.812] F1[0.89613] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 63] TokenID[[11858, 20143, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram burle the the the the the the the the] Loss[0.64765] Acc[0.79634] Prec[1.0] Recall[0.79634] F1[0.88649] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 64] TokenID[[11858, 3224, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram 1934 the the the the the the the the] Loss[0.56237] Acc[0.8311] Prec[1.0] Recall[0.8311] F1[0.90767] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 65] TokenID[[11858, 26476, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramocar the the the the the the the the] Loss[0.58164] Acc[0.82251] Prec[1.0] Recall[0.82251] F1[0.90254] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 66] TokenID[[11858, 26090, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram tigerstedt the the the the the the the the] Loss[0.6414] Acc[0.804] Prec[1.0] Recall[0.804] F1[0.89124] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 67] TokenID[[11858, 21945, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram centuri the the the the the the the the] Loss[0.54595] Acc[0.83768] Prec[1.0] Recall[0.83768] F1[0.91159] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 68] TokenID[[11858, 20894, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram structurally the the the the the the the the] Loss[0.58484] Acc[0.81711] Prec[1.0] Recall[0.81711] F1[0.89926] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 69] TokenID[[11858, 12825, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram reversibl the the the the the the the the] Loss[0.57788] Acc[0.82293] Prec[1.0] Recall[0.82293] F1[0.90279] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 70] TokenID[[11858, 5453, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram citations the the the the the the the the] Loss[0.55587] Acc[0.83974] Prec[1.0] Recall[0.83974] F1[0.91286] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 71] TokenID[[11858, 18769, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram twombly the the the the the the the the] Loss[0.52823] Acc[0.85223] Prec[1.0] Recall[0.85223] F1[0.92016] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 72] TokenID[[11858, 3611, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram sixt the the the the the the the the] Loss[0.62752] Acc[0.80667] Prec[1.0] Recall[0.80667] F1[0.89288] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 73] TokenID[[11858, 20065, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram hirvela the the the the the the the the] Loss[0.63059] Acc[0.80552] Prec[1.0] Recall[0.80552] F1[0.89217] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 74] TokenID[[11858, 25852, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramimica the the the the the the the the] Loss[0.55008] Acc[0.83599] Prec[1.0] Recall[0.83599] F1[0.91058] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 75] TokenID[[11858, 16773, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram zenit the the the the the the the the] Loss[0.63749] Acc[0.80305] Prec[1.0] Recall[0.80305] F1[0.89067] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 76] TokenID[[11858, 24197, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramhasse the the the the the the the the] Loss[0.64117] Acc[0.79663] Prec[1.0] Recall[0.79663] F1[0.88667] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 77] TokenID[[11858, 25740, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram embra the the the the the the the the] Loss[0.60306] Acc[0.81578] Prec[1.0] Recall[0.81578] F1[0.89846] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 78] TokenID[[11858, 27689, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram 25444 the the the the the the the the] Loss[0.65196] Acc[0.80377] Prec[1.0] Recall[0.80377] F1[0.89108] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 79] TokenID[[11858, 8098, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram causati the the the the the the the the] Loss[0.54455] Acc[0.8396] Prec[1.0] Recall[0.8396] F1[0.91273] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 80] TokenID[[11858, 20801, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram qata the the the the the the the the] Loss[0.58764] Acc[0.82452] Prec[1.0] Recall[0.82452] F1[0.90375] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 81] TokenID[[11858, 27821, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram wjhe the the the the the the the the] Loss[0.54769] Acc[0.84205] Prec[1.0] Recall[0.84205] F1[0.91418] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 82] TokenID[[11858, 27632, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram stens the the the the the the the the] Loss[0.60008] Acc[0.82056] Prec[1.0] Recall[0.82056] F1[0.90134] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 83] TokenID[[11858, 18205, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram bahra the the the the the the the the] Loss[0.62344] Acc[0.81448] Prec[1.0] Recall[0.81448] F1[0.89766] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 84] TokenID[[11858, 18316, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram contrari the the the the the the the the] Loss[0.59307] Acc[0.82829] Prec[1.0] Recall[0.82829] F1[0.90595] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 85] TokenID[[11858, 13482, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram racketeer the the the the the the the the] Loss[0.5735] Acc[0.83671] Prec[1.0] Recall[0.83671] F1[0.91092] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 86] TokenID[[11858, 11580, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram balkan the the the the the the the the] Loss[0.5823] Acc[0.82591] Prec[1.0] Recall[0.82591] F1[0.9046] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 87] TokenID[[11858, 17506, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegrambov the the the the the the the the] Loss[0.60995] Acc[0.81525] Prec[1.0] Recall[0.81525] F1[0.89814] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 88] TokenID[[11858, 30252, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram montenegr the the the the the the the the] Loss[0.61935] Acc[0.81402] Prec[1.0] Recall[0.81402] F1[0.89737] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 89] TokenID[[11858, 15301, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegrampam the the the the the the the the] Loss[0.60272] Acc[0.81521] Prec[1.0] Recall[0.81521] F1[0.89811] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 90] TokenID[[11858, 16038, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramomo the the the the the the the the] Loss[0.58312] Acc[0.81837] Prec[1.0] Recall[0.81837] F1[0.90003] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 91] TokenID[[11858, 26417, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegrampani the the the the the the the the] Loss[0.6077] Acc[0.81775] Prec[1.0] Recall[0.81775] F1[0.89958] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 92] TokenID[[11858, 24439, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram fontan the the the the the the the the] Loss[0.58856] Acc[0.82179] Prec[1.0] Recall[0.82179] F1[0.9021] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 93] TokenID[[11858, 16855, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramcarba the the the the the the the the] Loss[0.62056] Acc[0.80769] Prec[1.0] Recall[0.80769] F1[0.89349] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 94] TokenID[[11858, 6545, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram herzegovina the the the the the the the the] Loss[0.58539] Acc[0.82042] Prec[1.0] Recall[0.82042] F1[0.90128] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 95] TokenID[[11858, 26575, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram vandalis the the the the the the the the] Loss[0.54843] Acc[0.8335] Prec[1.0] Recall[0.8335] F1[0.9091] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 96] TokenID[[11858, 20478, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramriou the the the the the the the the] Loss[0.56599] Acc[0.82738] Prec[1.0] Recall[0.82738] F1[0.90541] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 97] TokenID[[11858, 26317, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram shul the the the the the the the the] Loss[0.58681] Acc[0.82536] Prec[1.0] Recall[0.82536] F1[0.90426] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 98] TokenID[[11858, 14170, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram unsuccessfully the the the the the the the the] Loss[0.51154] Acc[0.85951] Prec[1.0] Recall[0.85951] F1[0.92434] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  1, 99] TokenID[[11858, 24347, 207, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegramnji the the the the the the the the] Loss[0.57738] Acc[0.83109] Prec[1.0] Recall[0.83109] F1[0.90764] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","Worst loss 0.6675952701799331 with candidates [11858, 6900, 207, 207, 207, 207, 207, 207, 207, 207] in the 1-iteration with tokens [telegram naphth the the the the the the the the]\n","candidates [ 7791 12224  2145  4774  6532  4401  2852  9843  3986  1689  4108  5101\n","  1619  7633  2196  2053  2018  9048  4621  4146 11554  7716  2009  4090\n","  1372  1795  1930 13370  5424  2287  1096  2480  2533  5374  5044  3098\n"," 20394  1534  2690  1591   276  2248   808   972  1004  4336  3803 17251\n","  2577  3176  8462  4191  6034  7102  6762  1313  1396  3956  5312  2266\n","  4673  1270   891  2300  5198 20895  1498  7376  2284  4609  3194  2522\n"," 16571  2828 11742  7012  6426  6869 15287   867 12943  1620 19079 13076\n"," 10026  3281  3754  3914  3158  1626  4342  2357  7533 13753  8743 30116\n","  2774  4748  6457  5220]\n","[  2,  0] TokenID[[11858, 6900, 7791, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphthories the the the the the the the] Loss[0.52437] Acc[0.85705] Prec[1.0] Recall[0.85705] F1[0.92295] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  2,  1] TokenID[[11858, 6900, 12224, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth americans the the the the the the the] Loss[0.55718] Acc[0.84793] Prec[1.0] Recall[0.84793] F1[0.91754] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  2,  2] TokenID[[11858, 6900, 2145, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth threatened the the the the the the the] Loss[0.51427] Acc[0.85173] Prec[1.0] Recall[0.85173] F1[0.91971] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  2,  3] TokenID[[11858, 6900, 4774, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth divest the the the the the the the] Loss[0.65484] Acc[0.80197] Prec[1.0] Recall[0.80197] F1[0.89001] => Worst<<Loss>>[0.6676] Found at [  1, 34]\n","[  2,  4] TokenID[[11858, 6900, 6532, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth learned the the the the the the the] Loss[0.75448] Acc[0.76575] Prec[1.0] Recall[0.76575] F1[0.86724] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2,  5] TokenID[[11858, 6900, 4401, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth reputation the the the the the the the] Loss[0.51477] Acc[0.86875] Prec[1.0] Recall[0.86875] F1[0.9296] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2,  6] TokenID[[11858, 6900, 2852, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth lost the the the the the the the] Loss[0.55054] Acc[0.82725] Prec[1.0] Recall[0.82725] F1[0.9053] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2,  7] TokenID[[11858, 6900, 9843, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth acquitted the the the the the the the] Loss[0.73096] Acc[0.77396] Prec[1.0] Recall[0.77396] F1[0.87232] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2,  8] TokenID[[11858, 6900, 3986, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth likelihood the the the the the the the] Loss[0.45147] Acc[0.87587] Prec[1.0] Recall[0.87587] F1[0.93377] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2,  9] TokenID[[11858, 6900, 1689, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth arguments the the the the the the the] Loss[0.51798] Acc[0.85948] Prec[1.0] Recall[0.85948] F1[0.92428] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 10] TokenID[[11858, 6900, 4108, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth ineffective the the the the the the the] Loss[0.55177] Acc[0.83172] Prec[1.0] Recall[0.83172] F1[0.908] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 11] TokenID[[11858, 6900, 5101, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth inability the the the the the the the] Loss[0.51087] Acc[0.85846] Prec[1.0] Recall[0.85846] F1[0.92368] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 12] TokenID[[11858, 6900, 1619, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth intellectual the the the the the the the] Loss[0.5543] Acc[0.85417] Prec[1.0] Recall[0.85417] F1[0.92111] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 13] TokenID[[11858, 6900, 7633, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth gained the the the the the the the] Loss[0.56744] Acc[0.83161] Prec[1.0] Recall[0.83161] F1[0.90796] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 14] TokenID[[11858, 6900, 2196, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth experience the the the the the the the] Loss[0.51155] Acc[0.86254] Prec[1.0] Recall[0.86254] F1[0.92607] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 15] TokenID[[11858, 6900, 2053, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth ability the the the the the the the] Loss[0.4449] Acc[0.88619] Prec[1.0] Recall[0.88619] F1[0.93951] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 16] TokenID[[11858, 6900, 2018, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth complained the the the the the the the] Loss[0.6439] Acc[0.78882] Prec[1.0] Recall[0.78882] F1[0.88181] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 17] TokenID[[11858, 6900, 9048, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth conceived the the the the the the the] Loss[0.64825] Acc[0.81776] Prec[1.0] Recall[0.81776] F1[0.89964] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 18] TokenID[[11858, 6900, 4621, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth refrain the the the the the the the] Loss[0.6371] Acc[0.80935] Prec[1.0] Recall[0.80935] F1[0.89432] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 19] TokenID[[11858, 6900, 4146, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth releases the the the the the the the] Loss[0.72603] Acc[0.77957] Prec[1.0] Recall[0.77957] F1[0.87588] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 20] TokenID[[11858, 6900, 11554, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth unforeseeable the the the the the the the] Loss[0.52338] Acc[0.84199] Prec[1.0] Recall[0.84199] F1[0.91408] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 21] TokenID[[11858, 6900, 7716, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth inaction the the the the the the the] Loss[0.42572] Acc[0.88112] Prec[1.0] Recall[0.88112] F1[0.93669] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 22] TokenID[[11858, 6900, 2009, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth favor the the the the the the the] Loss[0.60172] Acc[0.82257] Prec[1.0] Recall[0.82257] F1[0.90246] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 23] TokenID[[11858, 6900, 4090, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth challenges the the the the the the the] Loss[0.59394] Acc[0.82688] Prec[1.0] Recall[0.82688] F1[0.90508] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 24] TokenID[[11858, 6900, 1372, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth defense the the the the the the the] Loss[0.66143] Acc[0.80353] Prec[1.0] Recall[0.80353] F1[0.89074] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 25] TokenID[[11858, 6900, 1795, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth continued the the the the the the the] Loss[0.59039] Acc[0.81313] Prec[1.0] Recall[0.81313] F1[0.89684] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 26] TokenID[[11858, 6900, 1930, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth aware the the the the the the the] Loss[0.57453] Acc[0.82704] Prec[1.0] Recall[0.82704] F1[0.90522] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 27] TokenID[[11858, 6900, 13370, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth transpire the the the the the the the] Loss[0.60744] Acc[0.81885] Prec[1.0] Recall[0.81885] F1[0.90031] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 28] TokenID[[11858, 6900, 5424, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth usage the the the the the the the] Loss[0.52496] Acc[0.86531] Prec[1.0] Recall[0.86531] F1[0.92759] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 29] TokenID[[11858, 6900, 2287, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth abuse the the the the the the the] Loss[0.56782] Acc[0.841] Prec[1.0] Recall[0.841] F1[0.91345] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 30] TokenID[[11858, 6900, 1096, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth failed the the the the the the the] Loss[0.5431] Acc[0.83491] Prec[1.0] Recall[0.83491] F1[0.90988] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 31] TokenID[[11858, 6900, 2480, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth survive the the the the the the the] Loss[0.60051] Acc[0.81663] Prec[1.0] Recall[0.81663] F1[0.8989] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 32] TokenID[[11858, 6900, 2533, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth challenge the the the the the the the] Loss[0.62027] Acc[0.81544] Prec[1.0] Recall[0.81544] F1[0.89818] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 33] TokenID[[11858, 6900, 5374, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth resort the the the the the the the] Loss[0.5488] Acc[0.84857] Prec[1.0] Recall[0.84857] F1[0.91787] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 34] TokenID[[11858, 6900, 5044, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth irreparabl the the the the the the the] Loss[0.60553] Acc[0.82099] Prec[1.0] Recall[0.82099] F1[0.90148] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 35] TokenID[[11858, 6900, 3098, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth incident the the the the the the the] Loss[0.63161] Acc[0.81093] Prec[1.0] Recall[0.81093] F1[0.89539] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 36] TokenID[[11858, 6900, 20394, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth conceive the the the the the the the] Loss[0.64811] Acc[0.80292] Prec[1.0] Recall[0.80292] F1[0.89058] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 37] TokenID[[11858, 6900, 1534, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth events the the the the the the the] Loss[0.58706] Acc[0.82873] Prec[1.0] Recall[0.82873] F1[0.9062] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 38] TokenID[[11858, 6900, 2690, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth deleted the the the the the the the] Loss[0.64886] Acc[0.79442] Prec[1.0] Recall[0.79442] F1[0.88528] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 39] TokenID[[11858, 6900, 1591, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth lack the the the the the the the] Loss[0.57942] Acc[0.8293] Prec[1.0] Recall[0.8293] F1[0.90654] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 40] TokenID[[11858, 6900, 276, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth parties the the the the the the the] Loss[0.52211] Acc[0.85284] Prec[1.0] Recall[0.85284] F1[0.92039] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 41] TokenID[[11858, 6900, 2248, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth regardless the the the the the the the] Loss[0.62688] Acc[0.81595] Prec[1.0] Recall[0.81595] F1[0.8985] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 42] TokenID[[11858, 6900, 808, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth access the the the the the the the] Loss[0.5458] Acc[0.85361] Prec[1.0] Recall[0.85361] F1[0.92087] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 43] TokenID[[11858, 6900, 972, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth independent the the the the the the the] Loss[0.61932] Acc[0.81814] Prec[1.0] Recall[0.81814] F1[0.8998] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 44] TokenID[[11858, 6900, 1004, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth contrary the the the the the the the] Loss[0.54213] Acc[0.82929] Prec[1.0] Recall[0.82929] F1[0.9065] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 45] TokenID[[11858, 6900, 4336, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth participated the the the the the the the] Loss[0.57775] Acc[0.83353] Prec[1.0] Recall[0.83353] F1[0.90909] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 46] TokenID[[11858, 6900, 3803, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth absent the the the the the the the] Loss[0.60755] Acc[0.81509] Prec[1.0] Recall[0.81509] F1[0.89799] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 47] TokenID[[11858, 6900, 17251, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth killings the the the the the the the] Loss[0.55396] Acc[0.84882] Prec[1.0] Recall[0.84882] F1[0.91809] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 48] TokenID[[11858, 6900, 2577, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth removed the the the the the the the] Loss[0.53846] Acc[0.82343] Prec[1.0] Recall[0.82343] F1[0.90297] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 49] TokenID[[11858, 6900, 3176, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth history the the the the the the the] Loss[0.62321] Acc[0.81189] Prec[1.0] Recall[0.81189] F1[0.8961] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 50] TokenID[[11858, 6900, 8462, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth motivated the the the the the the the] Loss[0.646] Acc[0.80766] Prec[1.0] Recall[0.80766] F1[0.89337] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 51] TokenID[[11858, 6900, 4191, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth prima the the the the the the the] Loss[0.66619] Acc[0.79628] Prec[1.0] Recall[0.79628] F1[0.88647] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 52] TokenID[[11858, 6900, 6034, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth overlap the the the the the the the] Loss[0.57241] Acc[0.83467] Prec[1.0] Recall[0.83467] F1[0.90978] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 53] TokenID[[11858, 6900, 7102, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth devote the the the the the the the] Loss[0.61896] Acc[0.81798] Prec[1.0] Recall[0.81798] F1[0.89973] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 54] TokenID[[11858, 6900, 6762, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth credible the the the the the the the] Loss[0.63281] Acc[0.81602] Prec[1.0] Recall[0.81602] F1[0.89854] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 55] TokenID[[11858, 6900, 1313, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth supreme the the the the the the the] Loss[0.55241] Acc[0.83762] Prec[1.0] Recall[0.83762] F1[0.91138] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 56] TokenID[[11858, 6900, 1396, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth omitted the the the the the the the] Loss[0.56311] Acc[0.82458] Prec[1.0] Recall[0.82458] F1[0.90373] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 57] TokenID[[11858, 6900, 3956, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth geographic the the the the the the the] Loss[0.49391] Acc[0.87581] Prec[1.0] Recall[0.87581] F1[0.93362] => Worst<<Loss>>[0.75448] Found at [  2,  4]\n","[  2, 58] TokenID[[11858, 6900, 5312, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify the the the the the the the] Loss[0.84632] Acc[0.75765] Prec[1.0] Recall[0.75765] F1[0.86192] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 59] TokenID[[11858, 6900, 2266, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth choice the the the the the the the] Loss[0.66401] Acc[0.80114] Prec[1.0] Recall[0.80114] F1[0.88938] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 60] TokenID[[11858, 6900, 4673, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth recalls the the the the the the the] Loss[0.60929] Acc[0.82672] Prec[1.0] Recall[0.82672] F1[0.90499] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 61] TokenID[[11858, 6900, 1270, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth faith the the the the the the the] Loss[0.53423] Acc[0.86517] Prec[1.0] Recall[0.86517] F1[0.92747] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 62] TokenID[[11858, 6900, 891, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth affiliates the the the the the the the] Loss[0.45594] Acc[0.88388] Prec[1.0] Recall[0.88388] F1[0.93818] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 63] TokenID[[11858, 6900, 2300, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth cooperate the the the the the the the] Loss[0.56323] Acc[0.83849] Prec[1.0] Recall[0.83849] F1[0.91196] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 64] TokenID[[11858, 6900, 5198, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth aff the the the the the the the] Loss[0.61826] Acc[0.81703] Prec[1.0] Recall[0.81703] F1[0.89913] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 65] TokenID[[11858, 6900, 20895, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth resorted the the the the the the the] Loss[0.61779] Acc[0.81708] Prec[1.0] Recall[0.81708] F1[0.89908] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 66] TokenID[[11858, 6900, 1498, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth potential the the the the the the the] Loss[0.58386] Acc[0.82965] Prec[1.0] Recall[0.82965] F1[0.9067] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 67] TokenID[[11858, 6900, 7376, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth wear the the the the the the the] Loss[0.5662] Acc[0.83061] Prec[1.0] Recall[0.83061] F1[0.90734] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 68] TokenID[[11858, 6900, 2284, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth recitals the the the the the the the] Loss[0.59507] Acc[0.82849] Prec[1.0] Recall[0.82849] F1[0.90603] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 69] TokenID[[11858, 6900, 4609, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth ceo the the the the the the the] Loss[0.57234] Acc[0.83498] Prec[1.0] Recall[0.83498] F1[0.90991] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 70] TokenID[[11858, 6900, 3194, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth argue the the the the the the the] Loss[0.57341] Acc[0.83056] Prec[1.0] Recall[0.83056] F1[0.90735] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 71] TokenID[[11858, 6900, 2522, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testified the the the the the the the] Loss[0.75392] Acc[0.77534] Prec[1.0] Recall[0.77534] F1[0.87332] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 72] TokenID[[11858, 6900, 16571, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth decades the the the the the the the] Loss[0.55444] Acc[0.84527] Prec[1.0] Recall[0.84527] F1[0.91604] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 73] TokenID[[11858, 6900, 2828, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth guilty the the the the the the the] Loss[0.6573] Acc[0.80269] Prec[1.0] Recall[0.80269] F1[0.89027] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 74] TokenID[[11858, 6900, 11742, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth declines the the the the the the the] Loss[0.52114] Acc[0.84764] Prec[1.0] Recall[0.84764] F1[0.91746] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 75] TokenID[[11858, 6900, 7012, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth exclusivity the the the the the the the] Loss[0.56218] Acc[0.84821] Prec[1.0] Recall[0.84821] F1[0.91761] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 76] TokenID[[11858, 6900, 6426, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth incidents the the the the the the the] Loss[0.59236] Acc[0.83189] Prec[1.0] Recall[0.83189] F1[0.90808] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 77] TokenID[[11858, 6900, 6869, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth prejudiced the the the the the the the] Loss[0.52914] Acc[0.83844] Prec[1.0] Recall[0.83844] F1[0.91199] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 78] TokenID[[11858, 6900, 15287, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphthsight the the the the the the the] Loss[0.56488] Acc[0.83334] Prec[1.0] Recall[0.83334] F1[0.90898] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 79] TokenID[[11858, 6900, 867, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth motion the the the the the the the] Loss[0.61718] Acc[0.81586] Prec[1.0] Recall[0.81586] F1[0.89844] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 80] TokenID[[11858, 6900, 12943, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth severed the the the the the the the] Loss[0.64566] Acc[0.80177] Prec[1.0] Recall[0.80177] F1[0.8898] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 81] TokenID[[11858, 6900, 1620, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth ms the the the the the the the] Loss[0.61898] Acc[0.81566] Prec[1.0] Recall[0.81566] F1[0.89819] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 82] TokenID[[11858, 6900, 19079, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth accuse the the the the the the the] Loss[0.74722] Acc[0.77266] Prec[1.0] Recall[0.77266] F1[0.87159] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 83] TokenID[[11858, 6900, 13076, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth penetration the the the the the the the] Loss[0.53243] Acc[0.86143] Prec[1.0] Recall[0.86143] F1[0.92538] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 84] TokenID[[11858, 6900, 10026, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth leadership the the the the the the the] Loss[0.54816] Acc[0.84901] Prec[1.0] Recall[0.84901] F1[0.91811] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 85] TokenID[[11858, 6900, 3281, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth opposition the the the the the the the] Loss[0.62745] Acc[0.80928] Prec[1.0] Recall[0.80928] F1[0.89439] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 86] TokenID[[11858, 6900, 3754, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth moved the the the the the the the] Loss[0.59081] Acc[0.82178] Prec[1.0] Recall[0.82178] F1[0.90205] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 87] TokenID[[11858, 6900, 3914, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth developments the the the the the the the] Loss[0.52185] Acc[0.85493] Prec[1.0] Recall[0.85493] F1[0.92166] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 88] TokenID[[11858, 6900, 3158, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth born the the the the the the the] Loss[0.57866] Acc[0.83388] Prec[1.0] Recall[0.83388] F1[0.9093] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 89] TokenID[[11858, 6900, 1626, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth attention the the the the the the the] Loss[0.64694] Acc[0.80466] Prec[1.0] Recall[0.80466] F1[0.89151] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 90] TokenID[[11858, 6900, 4342, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth erred the the the the the the the] Loss[0.56341] Acc[0.82713] Prec[1.0] Recall[0.82713] F1[0.90528] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 91] TokenID[[11858, 6900, 2357, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth rely the the the the the the the] Loss[0.65265] Acc[0.80723] Prec[1.0] Recall[0.80723] F1[0.89314] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 92] TokenID[[11858, 6900, 7533, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth professionals the the the the the the the] Loss[0.51395] Acc[0.87213] Prec[1.0] Recall[0.87213] F1[0.9315] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 93] TokenID[[11858, 6900, 13753, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth inactive the the the the the the the] Loss[0.5839] Acc[0.82559] Prec[1.0] Recall[0.82559] F1[0.90433] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 94] TokenID[[11858, 6900, 8743, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth withdrew the the the the the the the] Loss[0.66288] Acc[0.79354] Prec[1.0] Recall[0.79354] F1[0.8847] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 95] TokenID[[11858, 6900, 30116, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth disrespect the the the the the the the] Loss[0.54487] Acc[0.84757] Prec[1.0] Recall[0.84757] F1[0.91738] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 96] TokenID[[11858, 6900, 2774, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth prevail the the the the the the the] Loss[0.58077] Acc[0.82436] Prec[1.0] Recall[0.82436] F1[0.90359] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 97] TokenID[[11858, 6900, 4748, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth carte the the the the the the the] Loss[0.64472] Acc[0.81055] Prec[1.0] Recall[0.81055] F1[0.89515] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 98] TokenID[[11858, 6900, 6457, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth sic the the the the the the the] Loss[0.6611] Acc[0.8033] Prec[1.0] Recall[0.8033] F1[0.89079] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  2, 99] TokenID[[11858, 6900, 5220, 207, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth undisputed the the the the the the the] Loss[0.62778] Acc[0.80924] Prec[1.0] Recall[0.80924] F1[0.89437] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","Worst loss 0.8463165625449149 with candidates [11858, 6900, 5312, 207, 207, 207, 207, 207, 207, 207] in the 2-iteration with tokens [telegram naphth testify the the the the the the the]\n","candidates [23067 24137  7560 12474 19962  2843 11748  4861 29905 25946 22111 15346\n","  5374  6248  4162 10950 24621  3632  9321  1619  7012 24289 13398 13545\n","  1814  3956  7234 16478 29079 10900 27249 29493 25730 17882  1897 20285\n"," 15944 22125 12083 16077 16237  2010  4645 27996  6478  3517  3345 12202\n"," 10738 20621 19987 19954 16828 23169 16662 18258 19886  8169 10391 21458\n"," 16456 26099 12689 15460  4851  4181   926 24631 18542 15119 16584 29668\n"," 20303  8914  2120 19073 21647 17622 15805 30154 23249  1823 12224  5287\n"," 22453 28709  1251  6102 22770  2858 20870  5975 22182  9124 10088 10318\n"," 25388 25325  8415 24551]\n","[  3,  0] TokenID[[11858, 6900, 5312, 23067, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyravan the the the the the the] Loss[0.70715] Acc[0.79009] Prec[1.0] Recall[0.79009] F1[0.88262] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  1] TokenID[[11858, 6900, 5312, 24137, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify distraction the the the the the the] Loss[0.60071] Acc[0.83191] Prec[1.0] Recall[0.83191] F1[0.90817] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  2] TokenID[[11858, 6900, 5312, 7560, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify nace the the the the the the] Loss[0.76716] Acc[0.76625] Prec[1.0] Recall[0.76625] F1[0.86749] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  3] TokenID[[11858, 6900, 5312, 12474, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify frydlender the the the the the the] Loss[0.77472] Acc[0.76418] Prec[1.0] Recall[0.76418] F1[0.86618] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  4] TokenID[[11858, 6900, 5312, 19962, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyevic the the the the the the] Loss[0.70028] Acc[0.79252] Prec[1.0] Recall[0.79252] F1[0.88415] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  5] TokenID[[11858, 6900, 5312, 2843, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify freedoms the the the the the the] Loss[0.80477] Acc[0.76512] Prec[1.0] Recall[0.76512] F1[0.86671] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  6] TokenID[[11858, 6900, 5312, 11748, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify 4999 the the the the the the] Loss[0.72366] Acc[0.79157] Prec[1.0] Recall[0.79157] F1[0.88346] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  7] TokenID[[11858, 6900, 5312, 4861, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify capacities the the the the the the] Loss[0.67641] Acc[0.79869] Prec[1.0] Recall[0.79869] F1[0.88789] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  8] TokenID[[11858, 6900, 5312, 29905, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify totalitarian the the the the the the] Loss[0.765] Acc[0.7697] Prec[1.0] Recall[0.7697] F1[0.86969] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3,  9] TokenID[[11858, 6900, 5312, 25946, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify sodisc the the the the the the] Loss[0.79105] Acc[0.76635] Prec[1.0] Recall[0.76635] F1[0.86753] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3, 10] TokenID[[11858, 6900, 5312, 22111, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify ccg the the the the the the] Loss[0.74401] Acc[0.7796] Prec[1.0] Recall[0.7796] F1[0.87601] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3, 11] TokenID[[11858, 6900, 5312, 15346, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify maximize the the the the the the] Loss[0.62622] Acc[0.82317] Prec[1.0] Recall[0.82317] F1[0.90284] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3, 12] TokenID[[11858, 6900, 5312, 5374, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify resort the the the the the the] Loss[0.68195] Acc[0.78937] Prec[1.0] Recall[0.78937] F1[0.88214] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3, 13] TokenID[[11858, 6900, 5312, 6248, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify opt the the the the the the] Loss[0.67779] Acc[0.79619] Prec[1.0] Recall[0.79619] F1[0.88644] => Worst<<Loss>>[0.84632] Found at [  2, 58]\n","[  3, 14] TokenID[[11858, 6900, 5312, 4162, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the the the the the the] Loss[0.85837] Acc[0.7485] Prec[1.0] Recall[0.7485] F1[0.8561] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 15] TokenID[[11858, 6900, 5312, 10950, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify competences the the the the the the] Loss[0.75196] Acc[0.78687] Prec[1.0] Recall[0.78687] F1[0.8806] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 16] TokenID[[11858, 6900, 5312, 24621, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify efficienc the the the the the the] Loss[0.7241] Acc[0.78458] Prec[1.0] Recall[0.78458] F1[0.87915] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 17] TokenID[[11858, 6900, 5312, 3632, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify deprived the the the the the the] Loss[0.7455] Acc[0.78144] Prec[1.0] Recall[0.78144] F1[0.87712] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 18] TokenID[[11858, 6900, 5312, 9321, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify subsidiar the the the the the the] Loss[0.73363] Acc[0.78287] Prec[1.0] Recall[0.78287] F1[0.87807] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 19] TokenID[[11858, 6900, 5312, 1619, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify intellectual the the the the the the] Loss[0.71874] Acc[0.79866] Prec[1.0] Recall[0.79866] F1[0.88788] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 20] TokenID[[11858, 6900, 5312, 7012, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify exclusivity the the the the the the] Loss[0.7108] Acc[0.79637] Prec[1.0] Recall[0.79637] F1[0.88651] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 21] TokenID[[11858, 6900, 5312, 24289, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify commercializ the the the the the the] Loss[0.68705] Acc[0.81632] Prec[1.0] Recall[0.81632] F1[0.89871] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 22] TokenID[[11858, 6900, 5312, 13398, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify scal the the the the the the] Loss[0.76958] Acc[0.76846] Prec[1.0] Recall[0.76846] F1[0.86889] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 23] TokenID[[11858, 6900, 5312, 13545, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify activist the the the the the the] Loss[0.74383] Acc[0.77696] Prec[1.0] Recall[0.77696] F1[0.87434] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 24] TokenID[[11858, 6900, 5312, 1814, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify possibility the the the the the the] Loss[0.63433] Acc[0.80755] Prec[1.0] Recall[0.80755] F1[0.89335] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 25] TokenID[[11858, 6900, 5312, 3956, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify geographic the the the the the the] Loss[0.64348] Acc[0.82005] Prec[1.0] Recall[0.82005] F1[0.90092] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 26] TokenID[[11858, 6900, 5312, 7234, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify diligently the the the the the the] Loss[0.72223] Acc[0.78974] Prec[1.0] Recall[0.78974] F1[0.88236] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 27] TokenID[[11858, 6900, 5312, 16478, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify coalition the the the the the the] Loss[0.67389] Acc[0.81011] Prec[1.0] Recall[0.81011] F1[0.8949] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 28] TokenID[[11858, 6900, 5312, 29079, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyceutica the the the the the the] Loss[0.76087] Acc[0.7685] Prec[1.0] Recall[0.7685] F1[0.86893] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 29] TokenID[[11858, 6900, 5312, 10900, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify rptr the the the the the the] Loss[0.72138] Acc[0.79389] Prec[1.0] Recall[0.79389] F1[0.885] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 30] TokenID[[11858, 6900, 5312, 27249, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify utm the the the the the the] Loss[0.78444] Acc[0.76955] Prec[1.0] Recall[0.76955] F1[0.8696] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 31] TokenID[[11858, 6900, 5312, 29493, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify reappoint the the the the the the] Loss[0.72122] Acc[0.78844] Prec[1.0] Recall[0.78844] F1[0.8815] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 32] TokenID[[11858, 6900, 5312, 25730, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyerung the the the the the the] Loss[0.73042] Acc[0.78016] Prec[1.0] Recall[0.78016] F1[0.87635] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 33] TokenID[[11858, 6900, 5312, 17882, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify villiger the the the the the the] Loss[0.78145] Acc[0.76756] Prec[1.0] Recall[0.76756] F1[0.86833] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 34] TokenID[[11858, 6900, 5312, 1897, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify political the the the the the the] Loss[0.70153] Acc[0.79254] Prec[1.0] Recall[0.79254] F1[0.88411] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 35] TokenID[[11858, 6900, 5312, 20285, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify kyrgyz the the the the the the] Loss[0.75239] Acc[0.76904] Prec[1.0] Recall[0.76904] F1[0.86929] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 36] TokenID[[11858, 6900, 5312, 15944, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify spielmann the the the the the the] Loss[0.79057] Acc[0.75941] Prec[1.0] Recall[0.75941] F1[0.86307] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 37] TokenID[[11858, 6900, 5312, 22125, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify jociene the the the the the the] Loss[0.8017] Acc[0.76025] Prec[1.0] Recall[0.76025] F1[0.86362] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 38] TokenID[[11858, 6900, 5312, 12083, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify collaborative the the the the the the] Loss[0.70783] Acc[0.79402] Prec[1.0] Recall[0.79402] F1[0.88509] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 39] TokenID[[11858, 6900, 5312, 16077, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify reluctant the the the the the the] Loss[0.6799] Acc[0.80127] Prec[1.0] Recall[0.80127] F1[0.88958] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 40] TokenID[[11858, 6900, 5312, 16237, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify convenien the the the the the the] Loss[0.79889] Acc[0.76935] Prec[1.0] Recall[0.76935] F1[0.86948] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 41] TokenID[[11858, 6900, 5312, 2010, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify competitive the the the the the the] Loss[0.70045] Acc[0.79263] Prec[1.0] Recall[0.79263] F1[0.88418] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 42] TokenID[[11858, 6900, 5312, 4645, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify austrian the the the the the the] Loss[0.74775] Acc[0.77451] Prec[1.0] Recall[0.77451] F1[0.87279] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 43] TokenID[[11858, 6900, 5312, 27996, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify lucr the the the the the the] Loss[0.73374] Acc[0.77414] Prec[1.0] Recall[0.77414] F1[0.87254] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 44] TokenID[[11858, 6900, 5312, 6478, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify innovative the the the the the the] Loss[0.68542] Acc[0.80114] Prec[1.0] Recall[0.80114] F1[0.88952] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 45] TokenID[[11858, 6900, 5312, 3517, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify appellate the the the the the the] Loss[0.73823] Acc[0.7827] Prec[1.0] Recall[0.7827] F1[0.87795] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 46] TokenID[[11858, 6900, 5312, 3345, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify opportunities the the the the the the] Loss[0.68838] Acc[0.7946] Prec[1.0] Recall[0.7946] F1[0.88541] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 47] TokenID[[11858, 6900, 5312, 12202, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify lenienc the the the the the the] Loss[0.72075] Acc[0.78018] Prec[1.0] Recall[0.78018] F1[0.87639] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 48] TokenID[[11858, 6900, 5312, 10738, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify abstention the the the the the the] Loss[0.83197] Acc[0.75611] Prec[1.0] Recall[0.75611] F1[0.86094] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 49] TokenID[[11858, 6900, 5312, 20621, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify hurdle the the the the the the] Loss[0.71412] Acc[0.79232] Prec[1.0] Recall[0.79232] F1[0.884] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 50] TokenID[[11858, 6900, 5312, 19987, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyibi the the the the the the] Loss[0.73292] Acc[0.78241] Prec[1.0] Recall[0.78241] F1[0.87774] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 51] TokenID[[11858, 6900, 5312, 19954, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifylaki the the the the the the] Loss[0.76718] Acc[0.77173] Prec[1.0] Recall[0.77173] F1[0.871] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 52] TokenID[[11858, 6900, 5312, 16828, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify contender the the the the the the] Loss[0.72273] Acc[0.78895] Prec[1.0] Recall[0.78895] F1[0.88191] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 53] TokenID[[11858, 6900, 5312, 23169, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify malinverni the the the the the the] Loss[0.77759] Acc[0.7604] Prec[1.0] Recall[0.7604] F1[0.86372] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 54] TokenID[[11858, 6900, 5312, 16662, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify csm the the the the the the] Loss[0.75982] Acc[0.77865] Prec[1.0] Recall[0.77865] F1[0.87531] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 55] TokenID[[11858, 6900, 5312, 18258, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify vicarious the the the the the the] Loss[0.80504] Acc[0.76524] Prec[1.0] Recall[0.76524] F1[0.86689] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 56] TokenID[[11858, 6900, 5312, 19886, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify wiel the the the the the the] Loss[0.7333] Acc[0.78223] Prec[1.0] Recall[0.78223] F1[0.87768] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 57] TokenID[[11858, 6900, 5312, 8169, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify inconvenien the the the the the the] Loss[0.76796] Acc[0.77282] Prec[1.0] Recall[0.77282] F1[0.8717] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 58] TokenID[[11858, 6900, 5312, 10391, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify immune the the the the the the] Loss[0.68736] Acc[0.7936] Prec[1.0] Recall[0.7936] F1[0.8847] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 59] TokenID[[11858, 6900, 5312, 21458, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify notions the the the the the the] Loss[0.73886] Acc[0.78122] Prec[1.0] Recall[0.78122] F1[0.87702] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 60] TokenID[[11858, 6900, 5312, 16456, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify nolo the the the the the the] Loss[0.72948] Acc[0.77998] Prec[1.0] Recall[0.77998] F1[0.87625] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 61] TokenID[[11858, 6900, 5312, 26099, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify dysfunction the the the the the the] Loss[0.67913] Acc[0.80392] Prec[1.0] Recall[0.80392] F1[0.89123] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 62] TokenID[[11858, 6900, 5312, 12689, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify leisure the the the the the the] Loss[0.72146] Acc[0.79486] Prec[1.0] Recall[0.79486] F1[0.88559] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 63] TokenID[[11858, 6900, 5312, 15460, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify univ the the the the the the] Loss[0.71329] Acc[0.79338] Prec[1.0] Recall[0.79338] F1[0.88469] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 64] TokenID[[11858, 6900, 5312, 4851, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify punitive the the the the the the] Loss[0.7421] Acc[0.78306] Prec[1.0] Recall[0.78306] F1[0.87819] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 65] TokenID[[11858, 6900, 5312, 4181, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify billion the the the the the the] Loss[0.70269] Acc[0.7883] Prec[1.0] Recall[0.7883] F1[0.88148] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 66] TokenID[[11858, 6900, 5312, 926, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify kingdom the the the the the the] Loss[0.74469] Acc[0.78075] Prec[1.0] Recall[0.78075] F1[0.8766] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 67] TokenID[[11858, 6900, 5312, 24631, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify mhr the the the the the the] Loss[0.77552] Acc[0.76698] Prec[1.0] Recall[0.76698] F1[0.86797] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 68] TokenID[[11858, 6900, 5312, 18542, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify decade the the the the the the] Loss[0.69646] Acc[0.7962] Prec[1.0] Recall[0.7962] F1[0.88642] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 69] TokenID[[11858, 6900, 5312, 15119, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyulic the the the the the the] Loss[0.80196] Acc[0.75738] Prec[1.0] Recall[0.75738] F1[0.86177] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 70] TokenID[[11858, 6900, 5312, 16584, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify sibling the the the the the the] Loss[0.73631] Acc[0.78395] Prec[1.0] Recall[0.78395] F1[0.87878] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 71] TokenID[[11858, 6900, 5312, 29668, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyordinated the the the the the the] Loss[0.7456] Acc[0.77873] Prec[1.0] Recall[0.77873] F1[0.87543] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 72] TokenID[[11858, 6900, 5312, 20303, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify deadly the the the the the the] Loss[0.76555] Acc[0.77319] Prec[1.0] Recall[0.77319] F1[0.87194] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 73] TokenID[[11858, 6900, 5312, 8914, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify commercialize the the the the the the] Loss[0.68245] Acc[0.80828] Prec[1.0] Recall[0.80828] F1[0.89379] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 74] TokenID[[11858, 6900, 5312, 2120, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify role the the the the the the] Loss[0.6852] Acc[0.79818] Prec[1.0] Recall[0.79818] F1[0.88764] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 75] TokenID[[11858, 6900, 5312, 19073, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyriva the the the the the the] Loss[0.75634] Acc[0.77035] Prec[1.0] Recall[0.77035] F1[0.87013] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 76] TokenID[[11858, 6900, 5312, 21647, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify msm the the the the the the] Loss[0.79163] Acc[0.76461] Prec[1.0] Recall[0.76461] F1[0.86641] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 77] TokenID[[11858, 6900, 5312, 17622, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify sajo the the the the the the] Loss[0.74545] Acc[0.77731] Prec[1.0] Recall[0.77731] F1[0.87457] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 78] TokenID[[11858, 6900, 5312, 15805, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify litigat the the the the the the] Loss[0.75793] Acc[0.7752] Prec[1.0] Recall[0.7752] F1[0.87322] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 79] TokenID[[11858, 6900, 5312, 30154, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify heterosexual the the the the the the] Loss[0.73324] Acc[0.77097] Prec[1.0] Recall[0.77097] F1[0.87054] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 80] TokenID[[11858, 6900, 5312, 23249, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify shaba the the the the the the] Loss[0.77222] Acc[0.76886] Prec[1.0] Recall[0.76886] F1[0.86918] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 81] TokenID[[11858, 6900, 5312, 1823, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify merits the the the the the the] Loss[0.6847] Acc[0.793] Prec[1.0] Recall[0.793] F1[0.88443] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 82] TokenID[[11858, 6900, 5312, 12224, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify americans the the the the the the] Loss[0.68529] Acc[0.80332] Prec[1.0] Recall[0.80332] F1[0.89082] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 83] TokenID[[11858, 6900, 5312, 5287, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify strategi the the the the the the] Loss[0.70237] Acc[0.79395] Prec[1.0] Recall[0.79395] F1[0.88503] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 84] TokenID[[11858, 6900, 5312, 22453, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify elite the the the the the the] Loss[0.76864] Acc[0.7747] Prec[1.0] Recall[0.7747] F1[0.8729] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 85] TokenID[[11858, 6900, 5312, 28709, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifyarme the the the the the the] Loss[0.79057] Acc[0.76063] Prec[1.0] Recall[0.76063] F1[0.86386] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 86] TokenID[[11858, 6900, 5312, 1251, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify regulatory the the the the the the] Loss[0.67247] Acc[0.80049] Prec[1.0] Recall[0.80049] F1[0.889] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 87] TokenID[[11858, 6900, 5312, 6102, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify career the the the the the the] Loss[0.7471] Acc[0.78169] Prec[1.0] Recall[0.78169] F1[0.87732] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 88] TokenID[[11858, 6900, 5312, 22770, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify remittal the the the the the the] Loss[0.76669] Acc[0.76948] Prec[1.0] Recall[0.76948] F1[0.86955] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 89] TokenID[[11858, 6900, 5312, 2858, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify imposition the the the the the the] Loss[0.66577] Acc[0.8046] Prec[1.0] Recall[0.8046] F1[0.89145] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 90] TokenID[[11858, 6900, 5312, 20870, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testifybarment the the the the the the] Loss[0.80108] Acc[0.76421] Prec[1.0] Recall[0.76421] F1[0.86616] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 91] TokenID[[11858, 6900, 5312, 5975, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify ventures the the the the the the] Loss[0.74094] Acc[0.77833] Prec[1.0] Recall[0.77833] F1[0.87519] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 92] TokenID[[11858, 6900, 5312, 22182, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify zagrebelsky the the the the the the] Loss[0.75379] Acc[0.77152] Prec[1.0] Recall[0.77152] F1[0.87087] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 93] TokenID[[11858, 6900, 5312, 9124, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify nederland the the the the the the] Loss[0.74761] Acc[0.77491] Prec[1.0] Recall[0.77491] F1[0.87303] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 94] TokenID[[11858, 6900, 5312, 10088, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify judgement the the the the the the] Loss[0.70996] Acc[0.79089] Prec[1.0] Recall[0.79089] F1[0.88312] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 95] TokenID[[11858, 6900, 5312, 10318, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify ftc the the the the the the] Loss[0.71935] Acc[0.7934] Prec[1.0] Recall[0.7934] F1[0.88469] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 96] TokenID[[11858, 6900, 5312, 25388, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify innovat the the the the the the] Loss[0.76711] Acc[0.77287] Prec[1.0] Recall[0.77287] F1[0.87171] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 97] TokenID[[11858, 6900, 5312, 25325, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify bono the the the the the the] Loss[0.8388] Acc[0.75498] Prec[1.0] Recall[0.75498] F1[0.86019] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 98] TokenID[[11858, 6900, 5312, 8415, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify wfb the the the the the the] Loss[0.79131] Acc[0.77082] Prec[1.0] Recall[0.77082] F1[0.87041] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  3, 99] TokenID[[11858, 6900, 5312, 24551, 207, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify nonjudicial the the the the the the] Loss[0.76498] Acc[0.76686] Prec[1.0] Recall[0.76686] F1[0.86789] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","Worst loss 0.8583706742332827 with candidates [11858, 6900, 5312, 4162, 207, 207, 207, 207, 207, 207] in the 3-iteration with tokens [telegram naphth testify injunctive the the the the the the]\n","candidates [ 1498  1884  1137  5152 28076  1363  5467  2644   410  3371   753   655\n","   283  3652  3555 17937  1968  7791  9221  3492  2533  9932  3287  7858\n","  2574   911  1930   773  2300   689  4090 17879  4441  3068  6537   424\n","  6826  2196  2926  3497  8518   891  4972   751 17551 10165  3714  2117\n","   807  3194  4539  1598  7345   338   840  2642 11251   276  8262   321\n","  2315   811   641  4683  6913  5605  2819  2548  5714  1275  9235  2773\n","  5704  3618 15858  2120   215  1344  1741  3586  3102  1273  7885  6710\n","  2202  5545  1131  3183 28535  1372 17623   872   724  1996 20811  2145\n","  7633 23243  1843  9016]\n","[  4,  0] TokenID[[11858, 6900, 5312, 4162, 1498, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive potential the the the the the] Loss[0.67696] Acc[0.81037] Prec[1.0] Recall[0.81037] F1[0.89496] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  1] TokenID[[11858, 6900, 5312, 4162, 1884, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive currently the the the the the] Loss[0.64438] Acc[0.82404] Prec[1.0] Recall[0.82404] F1[0.90331] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  2] TokenID[[11858, 6900, 5312, 4162, 1137, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive acknowledge the the the the the] Loss[0.6519] Acc[0.81842] Prec[1.0] Recall[0.81842] F1[0.89996] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  3] TokenID[[11858, 6900, 5312, 4162, 5152, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive opposed the the the the the] Loss[0.62684] Acc[0.8291] Prec[1.0] Recall[0.8291] F1[0.90628] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  4] TokenID[[11858, 6900, 5312, 4162, 28076, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive spokesperson the the the the the] Loss[0.73892] Acc[0.79335] Prec[1.0] Recall[0.79335] F1[0.88459] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  5] TokenID[[11858, 6900, 5312, 4162, 1363, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive example the the the the the] Loss[0.71201] Acc[0.79797] Prec[1.0] Recall[0.79797] F1[0.8874] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  6] TokenID[[11858, 6900, 5312, 4162, 5467, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive challenging the the the the the] Loss[0.68273] Acc[0.80683] Prec[1.0] Recall[0.80683] F1[0.89293] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  7] TokenID[[11858, 6900, 5312, 4162, 2644, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive media the the the the the] Loss[0.63653] Acc[0.8233] Prec[1.0] Recall[0.8233] F1[0.90289] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  8] TokenID[[11858, 6900, 5312, 4162, 410, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive services the the the the the] Loss[0.60772] Acc[0.82889] Prec[1.0] Recall[0.82889] F1[0.90625] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4,  9] TokenID[[11858, 6900, 5312, 4162, 3371, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive contest the the the the the] Loss[0.61662] Acc[0.82824] Prec[1.0] Recall[0.82824] F1[0.9058] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 10] TokenID[[11858, 6900, 5312, 4162, 753, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive agree the the the the the] Loss[0.53573] Acc[0.85224] Prec[1.0] Recall[0.85224] F1[0.9201] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 11] TokenID[[11858, 6900, 5312, 4162, 655, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive 2009 the the the the the] Loss[0.68855] Acc[0.80027] Prec[1.0] Recall[0.80027] F1[0.88881] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 12] TokenID[[11858, 6900, 5312, 4162, 283, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive including the the the the the] Loss[0.659] Acc[0.81182] Prec[1.0] Recall[0.81182] F1[0.89594] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 13] TokenID[[11858, 6900, 5312, 4162, 3652, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive understand the the the the the] Loss[0.73007] Acc[0.80584] Prec[1.0] Recall[0.80584] F1[0.89231] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 14] TokenID[[11858, 6900, 5312, 4162, 3555, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive unlike the the the the the] Loss[0.82068] Acc[0.76995] Prec[1.0] Recall[0.76995] F1[0.86995] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 15] TokenID[[11858, 6900, 5312, 4162, 17937, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive doj the the the the the] Loss[0.65341] Acc[0.8111] Prec[1.0] Recall[0.8111] F1[0.89549] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 16] TokenID[[11858, 6900, 5312, 4162, 1968, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive seek the the the the the] Loss[0.72354] Acc[0.79673] Prec[1.0] Recall[0.79673] F1[0.88666] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 17] TokenID[[11858, 6900, 5312, 4162, 7791, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctiveories the the the the the] Loss[0.60378] Acc[0.83191] Prec[1.0] Recall[0.83191] F1[0.90806] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 18] TokenID[[11858, 6900, 5312, 4162, 9221, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive attribute the the the the the] Loss[0.76043] Acc[0.79701] Prec[1.0] Recall[0.79701] F1[0.88688] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 19] TokenID[[11858, 6900, 5312, 4162, 3492, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive internet the the the the the] Loss[0.68089] Acc[0.81245] Prec[1.0] Recall[0.81245] F1[0.89629] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 20] TokenID[[11858, 6900, 5312, 4162, 2533, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive challenge the the the the the] Loss[0.67082] Acc[0.81812] Prec[1.0] Recall[0.81812] F1[0.89968] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 21] TokenID[[11858, 6900, 5312, 4162, 9932, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctiveistic the the the the the] Loss[0.60233] Acc[0.82776] Prec[1.0] Recall[0.82776] F1[0.90557] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 22] TokenID[[11858, 6900, 5312, 4162, 3287, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive website the the the the the] Loss[0.63342] Acc[0.82876] Prec[1.0] Recall[0.82876] F1[0.90616] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 23] TokenID[[11858, 6900, 5312, 4162, 7858, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive server the the the the the] Loss[0.64876] Acc[0.82429] Prec[1.0] Recall[0.82429] F1[0.9035] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 24] TokenID[[11858, 6900, 5312, 4162, 2574, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive achieve the the the the the] Loss[0.65877] Acc[0.81486] Prec[1.0] Recall[0.81486] F1[0.89783] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 25] TokenID[[11858, 6900, 5312, 4162, 911, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive notwithstanding the the the the the] Loss[0.7342] Acc[0.78361] Prec[1.0] Recall[0.78361] F1[0.87855] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 26] TokenID[[11858, 6900, 5312, 4162, 1930, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive aware the the the the the] Loss[0.68386] Acc[0.81397] Prec[1.0] Recall[0.81397] F1[0.89727] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 27] TokenID[[11858, 6900, 5312, 4162, 773, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive 2011 the the the the the] Loss[0.67365] Acc[0.80523] Prec[1.0] Recall[0.80523] F1[0.89189] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 28] TokenID[[11858, 6900, 5312, 4162, 2300, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive cooperate the the the the the] Loss[0.6894] Acc[0.80833] Prec[1.0] Recall[0.80833] F1[0.89376] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 29] TokenID[[11858, 6900, 5312, 4162, 689, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive 2001 the the the the the] Loss[0.65951] Acc[0.81336] Prec[1.0] Recall[0.81336] F1[0.89687] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 30] TokenID[[11858, 6900, 5312, 4162, 4090, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive challenges the the the the the] Loss[0.67098] Acc[0.81545] Prec[1.0] Recall[0.81545] F1[0.89802] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 31] TokenID[[11858, 6900, 5312, 4162, 17879, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive loa the the the the the] Loss[0.6728] Acc[0.80429] Prec[1.0] Recall[0.80429] F1[0.89128] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 32] TokenID[[11858, 6900, 5312, 4162, 4441, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive dep the the the the the] Loss[0.75698] Acc[0.78633] Prec[1.0] Recall[0.78633] F1[0.88028] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 33] TokenID[[11858, 6900, 5312, 4162, 3068, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive remove the the the the the] Loss[0.56722] Acc[0.83612] Prec[1.0] Recall[0.83612] F1[0.91056] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 34] TokenID[[11858, 6900, 5312, 4162, 6537, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive detriment the the the the the] Loss[0.55386] Acc[0.83949] Prec[1.0] Recall[0.83949] F1[0.91254] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 35] TokenID[[11858, 6900, 5312, 4162, 424, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive product the the the the the] Loss[0.65894] Acc[0.82211] Prec[1.0] Recall[0.82211] F1[0.90215] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 36] TokenID[[11858, 6900, 5312, 4162, 6826, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive sensor the the the the the] Loss[0.65746] Acc[0.82348] Prec[1.0] Recall[0.82348] F1[0.903] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 37] TokenID[[11858, 6900, 5312, 4162, 2196, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive experience the the the the the] Loss[0.6718] Acc[0.81381] Prec[1.0] Recall[0.81381] F1[0.89717] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 38] TokenID[[11858, 6900, 5312, 4162, 2926, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive job the the the the the] Loss[0.64372] Acc[0.82406] Prec[1.0] Recall[0.82406] F1[0.90332] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 39] TokenID[[11858, 6900, 5312, 4162, 3497, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive doctrine the the the the the] Loss[0.56926] Acc[0.84305] Prec[1.0] Recall[0.84305] F1[0.91461] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 40] TokenID[[11858, 6900, 5312, 4162, 8518, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive perceived the the the the the] Loss[0.64774] Acc[0.81222] Prec[1.0] Recall[0.81222] F1[0.89622] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 41] TokenID[[11858, 6900, 5312, 4162, 891, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive affiliates the the the the the] Loss[0.56022] Acc[0.8521] Prec[1.0] Recall[0.8521] F1[0.92001] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 42] TokenID[[11858, 6900, 5312, 4162, 4972, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive deposition the the the the the] Loss[0.74861] Acc[0.78827] Prec[1.0] Recall[0.78827] F1[0.88143] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 43] TokenID[[11858, 6900, 5312, 4162, 751, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive 1999 the the the the the] Loss[0.67316] Acc[0.80877] Prec[1.0] Recall[0.80877] F1[0.89405] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 44] TokenID[[11858, 6900, 5312, 4162, 17551, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive scc the the the the the] Loss[0.64285] Acc[0.8194] Prec[1.0] Recall[0.8194] F1[0.90049] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 45] TokenID[[11858, 6900, 5312, 4162, 10165, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive villa the the the the the] Loss[0.69229] Acc[0.80529] Prec[1.0] Recall[0.80529] F1[0.89186] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 46] TokenID[[11858, 6900, 5312, 4162, 3714, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive hr the the the the the] Loss[0.70955] Acc[0.79702] Prec[1.0] Recall[0.79702] F1[0.88687] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 47] TokenID[[11858, 6900, 5312, 4162, 2117, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive separation the the the the the] Loss[0.67809] Acc[0.80737] Prec[1.0] Recall[0.80737] F1[0.89315] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 48] TokenID[[11858, 6900, 5312, 4162, 807, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive limitation the the the the the] Loss[0.60176] Acc[0.83438] Prec[1.0] Recall[0.83438] F1[0.90951] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 49] TokenID[[11858, 6900, 5312, 4162, 3194, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive argue the the the the the] Loss[0.63559] Acc[0.82287] Prec[1.0] Recall[0.82287] F1[0.90261] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 50] TokenID[[11858, 6900, 5312, 4162, 4539, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive def the the the the the] Loss[0.7244] Acc[0.79825] Prec[1.0] Recall[0.79825] F1[0.88752] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 51] TokenID[[11858, 6900, 5312, 4162, 1598, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive response the the the the the] Loss[0.68329] Acc[0.79916] Prec[1.0] Recall[0.79916] F1[0.88822] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 52] TokenID[[11858, 6900, 5312, 4162, 7345, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive removing the the the the the] Loss[0.56395] Acc[0.83928] Prec[1.0] Recall[0.83928] F1[0.91236] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 53] TokenID[[11858, 6900, 5312, 4162, 338, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive products the the the the the] Loss[0.63365] Acc[0.82087] Prec[1.0] Recall[0.82087] F1[0.90141] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 54] TokenID[[11858, 6900, 5312, 4162, 840, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive materials the the the the the] Loss[0.66512] Acc[0.81844] Prec[1.0] Recall[0.81844] F1[0.89992] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 55] TokenID[[11858, 6900, 5312, 4162, 2642, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive despite the the the the the] Loss[0.7408] Acc[0.78027] Prec[1.0] Recall[0.78027] F1[0.8765] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 56] TokenID[[11858, 6900, 5312, 4162, 11251, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive suffers the the the the the] Loss[0.6533] Acc[0.81965] Prec[1.0] Recall[0.81965] F1[0.90062] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 57] TokenID[[11858, 6900, 5312, 4162, 276, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive parties the the the the the] Loss[0.64903] Acc[0.81665] Prec[1.0] Recall[0.81665] F1[0.89887] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 58] TokenID[[11858, 6900, 5312, 4162, 8262, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive assertions the the the the the] Loss[0.68171] Acc[0.81189] Prec[1.0] Recall[0.81189] F1[0.89602] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 59] TokenID[[11858, 6900, 5312, 4162, 321, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive see the the the the the] Loss[0.75813] Acc[0.7877] Prec[1.0] Recall[0.7877] F1[0.88107] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 60] TokenID[[11858, 6900, 5312, 4162, 2315, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive understood the the the the the] Loss[0.66511] Acc[0.81883] Prec[1.0] Recall[0.81883] F1[0.90021] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 61] TokenID[[11858, 6900, 5312, 4162, 811, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive position the the the the the] Loss[0.6448] Acc[0.82025] Prec[1.0] Recall[0.82025] F1[0.90101] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 62] TokenID[[11858, 6900, 5312, 4162, 641, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive 2003 the the the the the] Loss[0.67212] Acc[0.81092] Prec[1.0] Recall[0.81092] F1[0.89537] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 63] TokenID[[11858, 6900, 5312, 4162, 4683, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive platform the the the the the] Loss[0.61279] Acc[0.82995] Prec[1.0] Recall[0.82995] F1[0.90689] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 64] TokenID[[11858, 6900, 5312, 4162, 6913, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive sac the the the the the] Loss[0.68417] Acc[0.80537] Prec[1.0] Recall[0.80537] F1[0.89195] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 65] TokenID[[11858, 6900, 5312, 4162, 5605, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive oppose the the the the the] Loss[0.66825] Acc[0.81589] Prec[1.0] Recall[0.81589] F1[0.89835] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 66] TokenID[[11858, 6900, 5312, 4162, 2819, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive exclusion the the the the the] Loss[0.70125] Acc[0.80578] Prec[1.0] Recall[0.80578] F1[0.89217] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 67] TokenID[[11858, 6900, 5312, 4162, 2548, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive study the the the the the] Loss[0.6445] Acc[0.82693] Prec[1.0] Recall[0.82693] F1[0.90505] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 68] TokenID[[11858, 6900, 5312, 4162, 5714, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive rejects the the the the the] Loss[0.6655] Acc[0.81658] Prec[1.0] Recall[0.81658] F1[0.89875] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 69] TokenID[[11858, 6900, 5312, 4162, 1275, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive acts the the the the the] Loss[0.61717] Acc[0.82639] Prec[1.0] Recall[0.82639] F1[0.90473] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 70] TokenID[[11858, 6900, 5312, 4162, 9235, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive anywhere the the the the the] Loss[0.68835] Acc[0.79882] Prec[1.0] Recall[0.79882] F1[0.88796] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 71] TokenID[[11858, 6900, 5312, 4162, 2773, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive strategy the the the the the] Loss[0.65855] Acc[0.82124] Prec[1.0] Recall[0.82124] F1[0.90159] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 72] TokenID[[11858, 6900, 5312, 4162, 5704, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive examples the the the the the] Loss[0.73654] Acc[0.78891] Prec[1.0] Recall[0.78891] F1[0.8819] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 73] TokenID[[11858, 6900, 5312, 4162, 3618, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive respond the the the the the] Loss[0.68174] Acc[0.8051] Prec[1.0] Recall[0.8051] F1[0.89186] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 74] TokenID[[11858, 6900, 5312, 4162, 15858, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive mccarthy the the the the the] Loss[0.68517] Acc[0.80917] Prec[1.0] Recall[0.80917] F1[0.89426] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 75] TokenID[[11858, 6900, 5312, 4162, 2120, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive role the the the the the] Loss[0.6886] Acc[0.81187] Prec[1.0] Recall[0.81187] F1[0.89582] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 76] TokenID[[11858, 6900, 5312, 4162, 215, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive or the the the the the] Loss[0.56393] Acc[0.84096] Prec[1.0] Recall[0.84096] F1[0.9134] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 77] TokenID[[11858, 6900, 5312, 4162, 1344, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive 1991 the the the the the] Loss[0.68379] Acc[0.80407] Prec[1.0] Recall[0.80407] F1[0.89114] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 78] TokenID[[11858, 6900, 5312, 4162, 1741, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive tr the the the the the] Loss[0.7633] Acc[0.78342] Prec[1.0] Recall[0.78342] F1[0.87849] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 79] TokenID[[11858, 6900, 5312, 4162, 3586, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive recall the the the the the] Loss[0.85832] Acc[0.7576] Prec[1.0] Recall[0.7576] F1[0.86191] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 80] TokenID[[11858, 6900, 5312, 4162, 3102, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive replace the the the the the] Loss[0.73708] Acc[0.79571] Prec[1.0] Recall[0.79571] F1[0.88607] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 81] TokenID[[11858, 6900, 5312, 4162, 1273, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive post the the the the the] Loss[0.75473] Acc[0.78025] Prec[1.0] Recall[0.78025] F1[0.87644] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 82] TokenID[[11858, 6900, 5312, 4162, 7885, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive chose the the the the the] Loss[0.77791] Acc[0.77914] Prec[1.0] Recall[0.77914] F1[0.87574] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 83] TokenID[[11858, 6900, 5312, 4162, 6710, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive disagree the the the the the] Loss[0.63103] Acc[0.82111] Prec[1.0] Recall[0.82111] F1[0.90153] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 84] TokenID[[11858, 6900, 5312, 4162, 2202, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctiveec the the the the the] Loss[0.65813] Acc[0.81363] Prec[1.0] Recall[0.81363] F1[0.89702] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 85] TokenID[[11858, 6900, 5312, 4162, 5545, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive inappropriate the the the the the] Loss[0.62993] Acc[0.81779] Prec[1.0] Recall[0.81779] F1[0.89949] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 86] TokenID[[11858, 6900, 5312, 4162, 1131, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive se the the the the the] Loss[0.7332] Acc[0.78628] Prec[1.0] Recall[0.78628] F1[0.88015] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 87] TokenID[[11858, 6900, 5312, 4162, 3183, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive positions the the the the the] Loss[0.61251] Acc[0.83116] Prec[1.0] Recall[0.83116] F1[0.90759] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 88] TokenID[[11858, 6900, 5312, 4162, 28535, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive bork the the the the the] Loss[0.72204] Acc[0.79804] Prec[1.0] Recall[0.79804] F1[0.88739] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 89] TokenID[[11858, 6900, 5312, 4162, 1372, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive defense the the the the the] Loss[0.74429] Acc[0.7856] Prec[1.0] Recall[0.7856] F1[0.87972] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 90] TokenID[[11858, 6900, 5312, 4162, 17623, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive paradigm the the the the the] Loss[0.69722] Acc[0.80427] Prec[1.0] Recall[0.80427] F1[0.89122] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 91] TokenID[[11858, 6900, 5312, 4162, 872, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive actions the the the the the] Loss[0.59783] Acc[0.83297] Prec[1.0] Recall[0.83297] F1[0.9087] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 92] TokenID[[11858, 6900, 5312, 4162, 724, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive investigation the the the the the] Loss[0.67211] Acc[0.81627] Prec[1.0] Recall[0.81627] F1[0.89867] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 93] TokenID[[11858, 6900, 5312, 4162, 1996, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive know the the the the the] Loss[0.73561] Acc[0.7982] Prec[1.0] Recall[0.7982] F1[0.88769] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 94] TokenID[[11858, 6900, 5312, 4162, 20811, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive afraid the the the the the] Loss[0.66613] Acc[0.80817] Prec[1.0] Recall[0.80817] F1[0.89368] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 95] TokenID[[11858, 6900, 5312, 4162, 2145, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive threatened the the the the the] Loss[0.60374] Acc[0.83354] Prec[1.0] Recall[0.83354] F1[0.90898] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 96] TokenID[[11858, 6900, 5312, 4162, 7633, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive gained the the the the the] Loss[0.6605] Acc[0.81628] Prec[1.0] Recall[0.81628] F1[0.89856] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 97] TokenID[[11858, 6900, 5312, 4162, 23243, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctivewerb the the the the the] Loss[0.71654] Acc[0.7972] Prec[1.0] Recall[0.7972] F1[0.88686] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 98] TokenID[[11858, 6900, 5312, 4162, 1843, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive receiving the the the the the] Loss[0.8103] Acc[0.76718] Prec[1.0] Recall[0.76718] F1[0.86816] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  4, 99] TokenID[[11858, 6900, 5312, 4162, 9016, 207, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive suggesting the the the the the] Loss[0.78727] Acc[0.77098] Prec[1.0] Recall[0.77098] F1[0.87061] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","Worst loss 0.8583706742332827 with candidates [11858, 6900, 5312, 4162, 207, 207, 207, 207, 207, 207] in the 4-iteration with tokens [telegram naphth testify injunctive the the the the the the]\n","candidates [26167 14414  4402 13124  5984  7716 20208 26238  9523 26272 23703 30205\n"," 25072 15784 10166 25523 27249  3354 12468  1462 25899 17252 22149  9768\n"," 29288  3955 11748 27159 25215 12201 24253  1579 13521 10263 17933 16415\n","  2286 12128 29467 18082 21636 26943  7700 22850 24928 15361 25749 29132\n"," 20597 14670 27028 14098  9861 19103  1688 27089 20835 23135 17418 23772\n"," 11331  6038  7897 21423 16714 30162 29350 15460 29454 14926 12107 14507\n"," 22087 22572  5152 25831 19642 24195 17987 14745 12358 24751  2695  8787\n"," 24264 14783 28894 11316 23197 22844 29673 23630   926 29795 24518 23907\n"," 20593 17184 24419 14337]\n","[  5,  0] TokenID[[11858, 6900, 5312, 4162, 207, 26167, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the diverg the the the the] Loss[0.76921] Acc[0.77765] Prec[1.0] Recall[0.77765] F1[0.87471] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  1] TokenID[[11858, 6900, 5312, 4162, 207, 14414, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the relian the the the the] Loss[0.76954] Acc[0.78258] Prec[1.0] Recall[0.78258] F1[0.8778] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  2] TokenID[[11858, 6900, 5312, 4162, 207, 4402, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thecured the the the the] Loss[0.78624] Acc[0.77012] Prec[1.0] Recall[0.77012] F1[0.87005] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  3] TokenID[[11858, 6900, 5312, 4162, 207, 13124, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thesoever the the the the] Loss[0.75595] Acc[0.77673] Prec[1.0] Recall[0.77673] F1[0.87425] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  4] TokenID[[11858, 6900, 5312, 4162, 207, 5984, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thedollar the the the the] Loss[0.80285] Acc[0.76328] Prec[1.0] Recall[0.76328] F1[0.86563] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  5] TokenID[[11858, 6900, 5312, 4162, 207, 7716, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the inaction the the the the] Loss[0.53302] Acc[0.83378] Prec[1.0] Recall[0.83378] F1[0.90918] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  6] TokenID[[11858, 6900, 5312, 4162, 207, 20208, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thedesk the the the the] Loss[0.74462] Acc[0.79537] Prec[1.0] Recall[0.79537] F1[0.88571] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  7] TokenID[[11858, 6900, 5312, 4162, 207, 26238, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thelimit the the the the] Loss[0.78548] Acc[0.76968] Prec[1.0] Recall[0.76968] F1[0.86975] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  8] TokenID[[11858, 6900, 5312, 4162, 207, 9523, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the asterisk the the the the] Loss[0.77316] Acc[0.77848] Prec[1.0] Recall[0.77848] F1[0.87522] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5,  9] TokenID[[11858, 6900, 5312, 4162, 207, 26272, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the sensu the the the the] Loss[0.79185] Acc[0.76669] Prec[1.0] Recall[0.76669] F1[0.86782] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 10] TokenID[[11858, 6900, 5312, 4162, 207, 23703, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thekontroll the the the the] Loss[0.82269] Acc[0.76183] Prec[1.0] Recall[0.76183] F1[0.8646] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 11] TokenID[[11858, 6900, 5312, 4162, 207, 30205, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thethird the the the the] Loss[0.75479] Acc[0.77701] Prec[1.0] Recall[0.77701] F1[0.87436] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 12] TokenID[[11858, 6900, 5312, 4162, 207, 25072, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thebbie the the the the] Loss[0.78035] Acc[0.77589] Prec[1.0] Recall[0.77589] F1[0.87364] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 13] TokenID[[11858, 6900, 5312, 4162, 207, 15784, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the odj the the the the] Loss[0.77014] Acc[0.77718] Prec[1.0] Recall[0.77718] F1[0.87446] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 14] TokenID[[11858, 6900, 5312, 4162, 207, 10166, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theubs the the the the] Loss[0.80837] Acc[0.77126] Prec[1.0] Recall[0.77126] F1[0.87067] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 15] TokenID[[11858, 6900, 5312, 4162, 207, 25523, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the ferrer the the the the] Loss[0.84265] Acc[0.76625] Prec[1.0] Recall[0.76625] F1[0.8675] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 16] TokenID[[11858, 6900, 5312, 4162, 207, 27249, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the utm the the the the] Loss[0.81489] Acc[0.76478] Prec[1.0] Recall[0.76478] F1[0.86668] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 17] TokenID[[11858, 6900, 5312, 4162, 207, 3354, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the territori the the the the] Loss[0.77219] Acc[0.78293] Prec[1.0] Recall[0.78293] F1[0.878] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 18] TokenID[[11858, 6900, 5312, 4162, 207, 12468, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the indoor the the the the] Loss[0.73301] Acc[0.79108] Prec[1.0] Recall[0.79108] F1[0.88314] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 19] TokenID[[11858, 6900, 5312, 4162, 207, 1462, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the collectively the the the the] Loss[0.71722] Acc[0.80258] Prec[1.0] Recall[0.80258] F1[0.89018] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 20] TokenID[[11858, 6900, 5312, 4162, 207, 25899, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thequita the the the the] Loss[0.79878] Acc[0.77692] Prec[1.0] Recall[0.77692] F1[0.87419] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 21] TokenID[[11858, 6900, 5312, 4162, 207, 17252, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thehout the the the the] Loss[0.84272] Acc[0.75445] Prec[1.0] Recall[0.75445] F1[0.85993] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 22] TokenID[[11858, 6900, 5312, 4162, 207, 22149, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theasserted the the the the] Loss[0.7732] Acc[0.77621] Prec[1.0] Recall[0.77621] F1[0.87392] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 23] TokenID[[11858, 6900, 5312, 4162, 207, 9768, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the nonrecourse the the the the] Loss[0.85114] Acc[0.75395] Prec[1.0] Recall[0.75395] F1[0.85958] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 24] TokenID[[11858, 6900, 5312, 4162, 207, 29288, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theigger the the the the] Loss[0.81283] Acc[0.76334] Prec[1.0] Recall[0.76334] F1[0.8657] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 25] TokenID[[11858, 6900, 5312, 4162, 207, 3955, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thefeu the the the the] Loss[0.74316] Acc[0.78738] Prec[1.0] Recall[0.78738] F1[0.88075] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 26] TokenID[[11858, 6900, 5312, 4162, 207, 11748, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the 4999 the the the the] Loss[0.77243] Acc[0.78998] Prec[1.0] Recall[0.78998] F1[0.88231] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 27] TokenID[[11858, 6900, 5312, 4162, 207, 27159, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the 4042 the the the the] Loss[0.84579] Acc[0.76438] Prec[1.0] Recall[0.76438] F1[0.86621] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 28] TokenID[[11858, 6900, 5312, 4162, 207, 25215, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the afg the the the the] Loss[0.84514] Acc[0.75455] Prec[1.0] Recall[0.75455] F1[0.85999] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 29] TokenID[[11858, 6900, 5312, 4162, 207, 12201, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theaffiliate the the the the] Loss[0.78553] Acc[0.77723] Prec[1.0] Recall[0.77723] F1[0.8745] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 30] TokenID[[11858, 6900, 5312, 4162, 207, 24253, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theracor the the the the] Loss[0.80766] Acc[0.76758] Prec[1.0] Recall[0.76758] F1[0.86835] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 31] TokenID[[11858, 6900, 5312, 4162, 207, 1579, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the longer the the the the] Loss[0.69839] Acc[0.81138] Prec[1.0] Recall[0.81138] F1[0.89563] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 32] TokenID[[11858, 6900, 5312, 4162, 207, 13521, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thestan the the the the] Loss[0.77351] Acc[0.77262] Prec[1.0] Recall[0.77262] F1[0.87164] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 33] TokenID[[11858, 6900, 5312, 4162, 207, 10263, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the transpos the the the the] Loss[0.77504] Acc[0.77426] Prec[1.0] Recall[0.77426] F1[0.87262] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 34] TokenID[[11858, 6900, 5312, 4162, 207, 17933, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the stam the the the the] Loss[0.76333] Acc[0.78439] Prec[1.0] Recall[0.78439] F1[0.87893] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 35] TokenID[[11858, 6900, 5312, 4162, 207, 16415, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theicide the the the the] Loss[0.79271] Acc[0.76956] Prec[1.0] Recall[0.76956] F1[0.86958] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 36] TokenID[[11858, 6900, 5312, 4162, 207, 2286, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the gc the the the the] Loss[0.7346] Acc[0.7966] Prec[1.0] Recall[0.7966] F1[0.88649] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 37] TokenID[[11858, 6900, 5312, 4162, 207, 12128, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theotte the the the the] Loss[0.78953] Acc[0.77634] Prec[1.0] Recall[0.77634] F1[0.87393] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 38] TokenID[[11858, 6900, 5312, 4162, 207, 29467, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the carinthia the the the the] Loss[0.81346] Acc[0.761] Prec[1.0] Recall[0.761] F1[0.86418] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 39] TokenID[[11858, 6900, 5312, 4162, 207, 18082, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the corollar the the the the] Loss[0.78447] Acc[0.77422] Prec[1.0] Recall[0.77422] F1[0.87262] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 40] TokenID[[11858, 6900, 5312, 4162, 207, 21636, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thereich the the the the] Loss[0.82342] Acc[0.76588] Prec[1.0] Recall[0.76588] F1[0.86725] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 41] TokenID[[11858, 6900, 5312, 4162, 207, 26943, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the targ the the the the] Loss[0.79481] Acc[0.77376] Prec[1.0] Recall[0.77376] F1[0.87229] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 42] TokenID[[11858, 6900, 5312, 4162, 207, 7700, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the otc the the the the] Loss[0.74853] Acc[0.79344] Prec[1.0] Recall[0.79344] F1[0.8845] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 43] TokenID[[11858, 6900, 5312, 4162, 207, 22850, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thelimitation the the the the] Loss[0.81152] Acc[0.76558] Prec[1.0] Recall[0.76558] F1[0.86714] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 44] TokenID[[11858, 6900, 5312, 4162, 207, 24928, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thecide the the the the] Loss[0.79558] Acc[0.77617] Prec[1.0] Recall[0.77617] F1[0.87382] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 45] TokenID[[11858, 6900, 5312, 4162, 207, 15361, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thepir the the the the] Loss[0.78625] Acc[0.77305] Prec[1.0] Recall[0.77305] F1[0.87192] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 46] TokenID[[11858, 6900, 5312, 4162, 207, 25749, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theroth the the the the] Loss[0.80332] Acc[0.77601] Prec[1.0] Recall[0.77601] F1[0.87363] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 47] TokenID[[11858, 6900, 5312, 4162, 207, 29132, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the deviat the the the the] Loss[0.75388] Acc[0.78244] Prec[1.0] Recall[0.78244] F1[0.87774] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 48] TokenID[[11858, 6900, 5312, 4162, 207, 20597, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theldc the the the the] Loss[0.82193] Acc[0.76146] Prec[1.0] Recall[0.76146] F1[0.86446] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 49] TokenID[[11858, 6900, 5312, 4162, 207, 14670, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the equitabl the the the the] Loss[0.81218] Acc[0.76631] Prec[1.0] Recall[0.76631] F1[0.86761] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 50] TokenID[[11858, 6900, 5312, 4162, 207, 27028, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thethele the the the the] Loss[0.80944] Acc[0.76613] Prec[1.0] Recall[0.76613] F1[0.86748] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 51] TokenID[[11858, 6900, 5312, 4162, 207, 14098, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theogle the the the the] Loss[0.73644] Acc[0.79119] Prec[1.0] Recall[0.79119] F1[0.88324] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 52] TokenID[[11858, 6900, 5312, 4162, 207, 9861, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the413 the the the the] Loss[0.76418] Acc[0.78396] Prec[1.0] Recall[0.78396] F1[0.87865] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 53] TokenID[[11858, 6900, 5312, 4162, 207, 19103, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theopol the the the the] Loss[0.79844] Acc[0.77359] Prec[1.0] Recall[0.77359] F1[0.87219] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 54] TokenID[[11858, 6900, 5312, 4162, 207, 1688, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the rise the the the the] Loss[0.71568] Acc[0.79104] Prec[1.0] Recall[0.79104] F1[0.88312] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 55] TokenID[[11858, 6900, 5312, 4162, 207, 27089, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive themanta the the the the] Loss[0.83461] Acc[0.75981] Prec[1.0] Recall[0.75981] F1[0.86338] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 56] TokenID[[11858, 6900, 5312, 4162, 207, 20835, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thehrad the the the the] Loss[0.79714] Acc[0.76868] Prec[1.0] Recall[0.76868] F1[0.86913] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 57] TokenID[[11858, 6900, 5312, 4162, 207, 23135, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the nephrop the the the the] Loss[0.83371] Acc[0.7569] Prec[1.0] Recall[0.7569] F1[0.86152] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 58] TokenID[[11858, 6900, 5312, 4162, 207, 17418, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive themicrobi the the the the] Loss[0.82064] Acc[0.76169] Prec[1.0] Recall[0.76169] F1[0.86467] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 59] TokenID[[11858, 6900, 5312, 4162, 207, 23772, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the oberste the the the the] Loss[0.81705] Acc[0.76855] Prec[1.0] Recall[0.76855] F1[0.86895] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 60] TokenID[[11858, 6900, 5312, 4162, 207, 11331, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the correlative the the the the] Loss[0.73513] Acc[0.78725] Prec[1.0] Recall[0.78725] F1[0.88075] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 61] TokenID[[11858, 6900, 5312, 4162, 207, 6038, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the omni the the the the] Loss[0.75745] Acc[0.78398] Prec[1.0] Recall[0.78398] F1[0.87877] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 62] TokenID[[11858, 6900, 5312, 4162, 207, 7897, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the duch the the the the] Loss[0.8312] Acc[0.75913] Prec[1.0] Recall[0.75913] F1[0.86295] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 63] TokenID[[11858, 6900, 5312, 4162, 207, 21423, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theowiec the the the the] Loss[0.81487] Acc[0.76683] Prec[1.0] Recall[0.76683] F1[0.86786] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 64] TokenID[[11858, 6900, 5312, 4162, 207, 16714, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the windfall the the the the] Loss[0.78672] Acc[0.77304] Prec[1.0] Recall[0.77304] F1[0.87173] => Worst<<Loss>>[0.85837] Found at [  3, 14]\n","[  5, 65] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap the the the the] Loss[0.88803] Acc[0.74482] Prec[1.0] Recall[0.74482] F1[0.85366] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 66] TokenID[[11858, 6900, 5312, 4162, 207, 29350, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the wauke the the the the] Loss[0.8208] Acc[0.76323] Prec[1.0] Recall[0.76323] F1[0.86561] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 67] TokenID[[11858, 6900, 5312, 4162, 207, 15460, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the univ the the the the] Loss[0.74349] Acc[0.79091] Prec[1.0] Recall[0.79091] F1[0.88303] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 68] TokenID[[11858, 6900, 5312, 4162, 207, 29454, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the overstep the the the the] Loss[0.73283] Acc[0.78674] Prec[1.0] Recall[0.78674] F1[0.88042] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 69] TokenID[[11858, 6900, 5312, 4162, 207, 14926, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the collegi the the the the] Loss[0.79466] Acc[0.77407] Prec[1.0] Recall[0.77407] F1[0.87247] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 70] TokenID[[11858, 6900, 5312, 4162, 207, 12107, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the piggyback the the the the] Loss[0.84753] Acc[0.76789] Prec[1.0] Recall[0.76789] F1[0.86853] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 71] TokenID[[11858, 6900, 5312, 4162, 207, 14507, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theelec the the the the] Loss[0.76522] Acc[0.78635] Prec[1.0] Recall[0.78635] F1[0.88016] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 72] TokenID[[11858, 6900, 5312, 4162, 207, 22087, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the intranet the the the the] Loss[0.78062] Acc[0.78715] Prec[1.0] Recall[0.78715] F1[0.88068] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 73] TokenID[[11858, 6900, 5312, 4162, 207, 22572, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theitic the the the the] Loss[0.79801] Acc[0.76389] Prec[1.0] Recall[0.76389] F1[0.86605] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 74] TokenID[[11858, 6900, 5312, 4162, 207, 5152, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the opposed the the the the] Loss[0.69231] Acc[0.80082] Prec[1.0] Recall[0.80082] F1[0.88919] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 75] TokenID[[11858, 6900, 5312, 4162, 207, 25831, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thedamia the the the the] Loss[0.82791] Acc[0.75816] Prec[1.0] Recall[0.75816] F1[0.86233] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 76] TokenID[[11858, 6900, 5312, 4162, 207, 19642, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the berec the the the the] Loss[0.77109] Acc[0.77659] Prec[1.0] Recall[0.77659] F1[0.87398] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 77] TokenID[[11858, 6900, 5312, 4162, 207, 24195, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thesurmount the the the the] Loss[0.81789] Acc[0.76378] Prec[1.0] Recall[0.76378] F1[0.86598] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 78] TokenID[[11858, 6900, 5312, 4162, 207, 17987, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thehealth the the the the] Loss[0.77408] Acc[0.78304] Prec[1.0] Recall[0.78304] F1[0.87806] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 79] TokenID[[11858, 6900, 5312, 4162, 207, 14745, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theother the the the the] Loss[0.79169] Acc[0.77129] Prec[1.0] Recall[0.77129] F1[0.87079] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 80] TokenID[[11858, 6900, 5312, 4162, 207, 12358, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theamber the the the the] Loss[0.80928] Acc[0.76252] Prec[1.0] Recall[0.76252] F1[0.86515] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 81] TokenID[[11858, 6900, 5312, 4162, 207, 24751, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theensa the the the the] Loss[0.7947] Acc[0.77132] Prec[1.0] Recall[0.77132] F1[0.87071] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 82] TokenID[[11858, 6900, 5312, 4162, 207, 2695, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the threshold the the the the] Loss[0.65674] Acc[0.81148] Prec[1.0] Recall[0.81148] F1[0.89569] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 83] TokenID[[11858, 6900, 5312, 4162, 207, 8787, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the 080 the the the the] Loss[0.79581] Acc[0.77379] Prec[1.0] Recall[0.77379] F1[0.87232] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 84] TokenID[[11858, 6900, 5312, 4162, 207, 24264, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thedistribute the the the the] Loss[0.83794] Acc[0.75118] Prec[1.0] Recall[0.75118] F1[0.85777] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 85] TokenID[[11858, 6900, 5312, 4162, 207, 14783, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thebutan the the the the] Loss[0.82166] Acc[0.76512] Prec[1.0] Recall[0.76512] F1[0.86683] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 86] TokenID[[11858, 6900, 5312, 4162, 207, 28894, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the soderman the the the the] Loss[0.79446] Acc[0.76513] Prec[1.0] Recall[0.76513] F1[0.86677] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 87] TokenID[[11858, 6900, 5312, 4162, 207, 11316, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the 085 the the the the] Loss[0.8031] Acc[0.7721] Prec[1.0] Recall[0.7721] F1[0.87122] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 88] TokenID[[11858, 6900, 5312, 4162, 207, 23197, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the aeronautic the the the the] Loss[0.85342] Acc[0.76229] Prec[1.0] Recall[0.76229] F1[0.86491] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 89] TokenID[[11858, 6900, 5312, 4162, 207, 22844, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theebro the the the the] Loss[0.85262] Acc[0.75438] Prec[1.0] Recall[0.75438] F1[0.85994] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 90] TokenID[[11858, 6900, 5312, 4162, 207, 29673, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive themajority the the the the] Loss[0.79461] Acc[0.77576] Prec[1.0] Recall[0.77576] F1[0.87348] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 91] TokenID[[11858, 6900, 5312, 4162, 207, 23630, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thezlau the the the the] Loss[0.77463] Acc[0.7752] Prec[1.0] Recall[0.7752] F1[0.8732] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 92] TokenID[[11858, 6900, 5312, 4162, 207, 926, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the kingdom the the the the] Loss[0.77556] Acc[0.78181] Prec[1.0] Recall[0.78181] F1[0.8772] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 93] TokenID[[11858, 6900, 5312, 4162, 207, 29795, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thecoagula the the the the] Loss[0.79554] Acc[0.77361] Prec[1.0] Recall[0.77361] F1[0.8722] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 94] TokenID[[11858, 6900, 5312, 4162, 207, 24518, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theapplied the the the the] Loss[0.80597] Acc[0.77089] Prec[1.0] Recall[0.77089] F1[0.87053] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 95] TokenID[[11858, 6900, 5312, 4162, 207, 23907, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theproc the the the the] Loss[0.81474] Acc[0.76482] Prec[1.0] Recall[0.76482] F1[0.86664] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 96] TokenID[[11858, 6900, 5312, 4162, 207, 20593, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thepolska the the the the] Loss[0.80149] Acc[0.76599] Prec[1.0] Recall[0.76599] F1[0.86741] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 97] TokenID[[11858, 6900, 5312, 4162, 207, 17184, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive thewalk the the the the] Loss[0.76131] Acc[0.78188] Prec[1.0] Recall[0.78188] F1[0.87747] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 98] TokenID[[11858, 6900, 5312, 4162, 207, 24419, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theeez the the the the] Loss[0.80151] Acc[0.77318] Prec[1.0] Recall[0.77318] F1[0.87193] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  5, 99] TokenID[[11858, 6900, 5312, 4162, 207, 14337, 207, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive the opted the the the the] Loss[0.78236] Acc[0.77122] Prec[1.0] Recall[0.77122] F1[0.87076] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","Worst loss 0.8880311116095512 with candidates [11858, 6900, 5312, 4162, 207, 30162, 207, 207, 207, 207] in the 5-iteration with tokens [telegram naphth testify injunctive theenskap the the the the]\n","candidates [ 6440  5942  1137  1251   891   694  2510  2058  7111  8506  3068  2695\n"," 23010   753  3287  8034  8153  1626  3566  3745  5646   410  1410  3462\n","  6447  2650  5880 24289   448  4774  6269 28312  1352 10194  4329  2470\n","  2577 11516 22111 20208  1126  1227  2730  1316 16460  3492  2108   283\n","   232  2497 22821   278 21798  4683  2491  3084  2401  4114  2489   618\n","   671  2696  1139  2020  2294  2769  6470   358 11788 19754  1228  5197\n"," 22087  8895  2360   625   819   326  6077  2683   582  7251 14044  1158\n","  1681  1623  2831  1773   377 14389 14098  2922  3102  6430  1375  1308\n","  2300  4879  3776 11790]\n","[  6,  0] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 6440, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap denominator the the the] Loss[0.79033] Acc[0.7743] Prec[1.0] Recall[0.7743] F1[0.87265] => Worst<<Loss>>[0.88803] Found at [  5, 65]\n","[  6,  1] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 5942, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifies the the the] Loss[0.90764] Acc[0.7288] Prec[1.0] Recall[0.7288] F1[0.84299] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6,  2] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1137, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap acknowledge the the the] Loss[0.70489] Acc[0.79855] Prec[1.0] Recall[0.79855] F1[0.88772] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6,  3] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1251, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap regulatory the the the] Loss[0.72875] Acc[0.78265] Prec[1.0] Recall[0.78265] F1[0.8778] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6,  4] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 891, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap affiliates the the the] Loss[0.65942] Acc[0.80709] Prec[1.0] Recall[0.80709] F1[0.893] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6,  5] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 694, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap agrees the the the] Loss[0.60349] Acc[0.82396] Prec[1.0] Recall[0.82396] F1[0.90334] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6,  6] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2510, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap irrevocably the the the] Loss[0.74247] Acc[0.77888] Prec[1.0] Recall[0.77888] F1[0.87553] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6,  7] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2058, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap acceptable the the the] Loss[0.7241] Acc[0.77802] Prec[1.0] Recall[0.77802] F1[0.87508] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6,  8] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 7111, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap remedied the the the] Loss[0.67491] Acc[0.79026] Prec[1.0] Recall[0.79026] F1[0.88265] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6,  9] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 8506, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap consensus the the the] Loss[0.68343] Acc[0.80682] Prec[1.0] Recall[0.80682] F1[0.8929] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 10] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3068, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap remove the the the] Loss[0.39254] Acc[0.8792] Prec[1.0] Recall[0.8792] F1[0.93555] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 11] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2695, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap threshold the the the] Loss[0.68675] Acc[0.79765] Prec[1.0] Recall[0.79765] F1[0.88715] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 12] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 23010, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskapmedi the the the] Loss[0.79314] Acc[0.75898] Prec[1.0] Recall[0.75898] F1[0.86285] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 13] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 753, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap agree the the the] Loss[0.483] Acc[0.87763] Prec[1.0] Recall[0.87763] F1[0.93461] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 14] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3287, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap website the the the] Loss[0.83441] Acc[0.76839] Prec[1.0] Recall[0.76839] F1[0.86887] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 15] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 8034, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap divestiture the the the] Loss[0.6599] Acc[0.81336] Prec[1.0] Recall[0.81336] F1[0.89681] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 16] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 8153, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap updates the the the] Loss[0.73608] Acc[0.77485] Prec[1.0] Recall[0.77485] F1[0.87307] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 17] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1626, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap attention the the the] Loss[0.82274] Acc[0.75771] Prec[1.0] Recall[0.75771] F1[0.86205] => Worst<<Loss>>[0.90764] Found at [  6,  1]\n","[  6, 18] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3566, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap email the the the] Loss[0.9683] Acc[0.72205] Prec[1.0] Recall[0.72205] F1[0.83849] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 19] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3745, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap solutions the the the] Loss[0.71407] Acc[0.7954] Prec[1.0] Recall[0.7954] F1[0.88585] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 20] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 5646, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap remit the the the] Loss[0.81752] Acc[0.75647] Prec[1.0] Recall[0.75647] F1[0.86111] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 21] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 410, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap services the the the] Loss[0.73165] Acc[0.78754] Prec[1.0] Recall[0.78754] F1[0.88094] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 22] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1410, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap network the the the] Loss[0.77048] Acc[0.77949] Prec[1.0] Recall[0.77949] F1[0.87593] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 23] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3462, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap understands the the the] Loss[0.80979] Acc[0.77004] Prec[1.0] Recall[0.77004] F1[0.86991] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 24] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 6447, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap mitigate the the the] Loss[0.73242] Acc[0.78566] Prec[1.0] Recall[0.78566] F1[0.87971] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 25] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2650, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap waives the the the] Loss[0.89721] Acc[0.74191] Prec[1.0] Recall[0.74191] F1[0.8517] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 26] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 5880, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap clarification the the the] Loss[0.72475] Acc[0.78483] Prec[1.0] Recall[0.78483] F1[0.87932] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 27] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 24289, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap commercializ the the the] Loss[0.7482] Acc[0.78926] Prec[1.0] Recall[0.78926] F1[0.8821] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 28] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 448, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap executive the the the] Loss[0.89134] Acc[0.75026] Prec[1.0] Recall[0.75026] F1[0.85699] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 29] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 4774, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap divest the the the] Loss[0.74548] Acc[0.79612] Prec[1.0] Recall[0.79612] F1[0.88625] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 30] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 6269, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap posted the the the] Loss[0.81546] Acc[0.76356] Prec[1.0] Recall[0.76356] F1[0.86585] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 31] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 28312, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskapvnet the the the] Loss[0.8452] Acc[0.75498] Prec[1.0] Recall[0.75498] F1[0.86023] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 32] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1352, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notification the the the] Loss[0.93263] Acc[0.74042] Prec[1.0] Recall[0.74042] F1[0.85066] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 33] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 10194, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap imperative the the the] Loss[0.74077] Acc[0.77642] Prec[1.0] Recall[0.77642] F1[0.87399] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 34] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 4329, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap reimbursed the the the] Loss[0.84715] Acc[0.74379] Prec[1.0] Recall[0.74379] F1[0.85277] => Worst<<Loss>>[0.9683] Found at [  6, 18]\n","[  6, 35] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2470, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap grants the the the] Loss[1.0161] Acc[0.71231] Prec[1.0] Recall[0.71231] F1[0.83174] => Worst<<Loss>>[1.0161] Found at [  6, 35]\n","[  6, 36] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2577, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap removed the the the] Loss[0.59039] Acc[0.8132] Prec[1.0] Recall[0.8132] F1[0.89668] => Worst<<Loss>>[1.0161] Found at [  6, 35]\n","[  6, 37] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 11516, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap timeframe the the the] Loss[0.73956] Acc[0.77762] Prec[1.0] Recall[0.77762] F1[0.87476] => Worst<<Loss>>[1.0161] Found at [  6, 35]\n","[  6, 38] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 22111, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap ccg the the the] Loss[0.76444] Acc[0.77834] Prec[1.0] Recall[0.77834] F1[0.87509] => Worst<<Loss>>[1.0161] Found at [  6, 35]\n","[  6, 39] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 20208, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskapdesk the the the] Loss[0.77447] Acc[0.78072] Prec[1.0] Recall[0.78072] F1[0.87657] => Worst<<Loss>>[1.0161] Found at [  6, 35]\n","[  6, 40] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1126, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap remedies the the the] Loss[0.61815] Acc[0.81494] Prec[1.0] Recall[0.81494] F1[0.89789] => Worst<<Loss>>[1.0161] Found at [  6, 35]\n","[  6, 41] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify the the the] Loss[1.0502] Acc[0.69558] Prec[1.0] Recall[0.69558] F1[0.82021] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 42] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2730, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap solution the the the] Loss[0.77009] Acc[0.76919] Prec[1.0] Recall[0.76919] F1[0.86945] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 43] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1316, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap prospectus the the the] Loss[0.82305] Acc[0.76491] Prec[1.0] Recall[0.76491] F1[0.86668] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 44] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 16460, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap emea the the the] Loss[0.75237] Acc[0.78527] Prec[1.0] Recall[0.78527] F1[0.87935] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 45] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3492, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap internet the the the] Loss[0.81512] Acc[0.77415] Prec[1.0] Recall[0.77415] F1[0.87253] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 46] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2108, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap consents the the the] Loss[0.66459] Acc[0.8117] Prec[1.0] Recall[0.8117] F1[0.89581] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 47] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 283, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap including the the the] Loss[0.75927] Acc[0.78365] Prec[1.0] Recall[0.78365] F1[0.87847] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 48] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 232, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap agreement the the the] Loss[0.75757] Acc[0.78675] Prec[1.0] Recall[0.78675] F1[0.88027] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 49] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2497, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap infrastructure the the the] Loss[0.73957] Acc[0.78689] Prec[1.0] Recall[0.78689] F1[0.88053] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 50] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 22821, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskapmission the the the] Loss[0.78791] Acc[0.76864] Prec[1.0] Recall[0.76864] F1[0.86908] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 51] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 278, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap applicable the the the] Loss[0.70077] Acc[0.79653] Prec[1.0] Recall[0.79653] F1[0.88644] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 52] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 21798, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskaparound the the the] Loss[0.75338] Acc[0.77437] Prec[1.0] Recall[0.77437] F1[0.87273] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 53] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 4683, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap platform the the the] Loss[0.77954] Acc[0.77997] Prec[1.0] Recall[0.77997] F1[0.87622] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 54] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2491, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap unenforceable the the the] Loss[0.82336] Acc[0.75054] Prec[1.0] Recall[0.75054] F1[0.85722] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 55] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3084, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap submits the the the] Loss[0.80806] Acc[0.77794] Prec[1.0] Recall[0.77794] F1[0.87495] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 56] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2401, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap delegate the the the] Loss[0.86773] Acc[0.75957] Prec[1.0] Recall[0.75957] F1[0.86309] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 57] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 4114, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap accepts the the the] Loss[0.72426] Acc[0.80181] Prec[1.0] Recall[0.80181] F1[0.8897] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 58] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2489, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap commercially the the the] Loss[0.77278] Acc[0.76945] Prec[1.0] Recall[0.76945] F1[0.86966] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 59] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 618, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap delivered the the the] Loss[0.96251] Acc[0.72261] Prec[1.0] Recall[0.72261] F1[0.83876] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 60] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 671, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap letter the the the] Loss[0.88218] Acc[0.75285] Prec[1.0] Recall[0.75285] F1[0.85874] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 61] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2696, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap limiting the the the] Loss[0.72813] Acc[0.78958] Prec[1.0] Recall[0.78958] F1[0.88219] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 62] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1139, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap considers the the the] Loss[0.69792] Acc[0.79211] Prec[1.0] Recall[0.79211] F1[0.88371] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 63] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2020, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap managing the the the] Loss[0.7625] Acc[0.77014] Prec[1.0] Recall[0.77014] F1[0.86995] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 64] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2294, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap acknowledged the the the] Loss[0.77288] Acc[0.7742] Prec[1.0] Recall[0.7742] F1[0.87258] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 65] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2769, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap determines the the the] Loss[0.68759] Acc[0.80514] Prec[1.0] Recall[0.80514] F1[0.89187] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 66] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 6470, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap abolish the the the] Loss[0.66209] Acc[0.80299] Prec[1.0] Recall[0.80299] F1[0.89038] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 67] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 358, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap means the the the] Loss[0.84273] Acc[0.75522] Prec[1.0] Recall[0.75522] F1[0.86049] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 68] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 11788, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap pct the the the] Loss[0.78656] Acc[0.77146] Prec[1.0] Recall[0.77146] F1[0.87078] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 69] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 19754, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskapcrc the the the] Loss[0.79724] Acc[0.76765] Prec[1.0] Recall[0.76765] F1[0.86821] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 70] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1228, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap successor the the the] Loss[0.78128] Acc[0.7752] Prec[1.0] Recall[0.7752] F1[0.87308] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 71] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 5197, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap moratorium the the the] Loss[0.69289] Acc[0.79811] Prec[1.0] Recall[0.79811] F1[0.88743] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 72] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 22087, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap intranet the the the] Loss[0.82488] Acc[0.76803] Prec[1.0] Recall[0.76803] F1[0.86858] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 73] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 8895, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap deploy the the the] Loss[0.74705] Acc[0.78722] Prec[1.0] Recall[0.78722] F1[0.88065] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 74] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2360, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskapisation the the the] Loss[0.77322] Acc[0.7703] Prec[1.0] Recall[0.7703] F1[0.87006] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 75] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 625, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap reasonably the the the] Loss[0.82224] Acc[0.75868] Prec[1.0] Recall[0.75868] F1[0.86272] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 76] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 819, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap mean the the the] Loss[0.84598] Acc[0.74652] Prec[1.0] Recall[0.74652] F1[0.85483] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 77] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 326, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notice the the the] Loss[0.85438] Acc[0.74639] Prec[1.0] Recall[0.74639] F1[0.85463] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 78] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 6077, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap discontinued the the the] Loss[0.72083] Acc[0.78013] Prec[1.0] Recall[0.78013] F1[0.87613] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 79] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2683, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap consultation the the the] Loss[0.77049] Acc[0.77864] Prec[1.0] Recall[0.77864] F1[0.8754] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 80] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 582, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap consent the the the] Loss[0.75414] Acc[0.77867] Prec[1.0] Recall[0.77867] F1[0.87538] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 81] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 7251, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap endeavour the the the] Loss[0.76656] Acc[0.77585] Prec[1.0] Recall[0.77585] F1[0.87347] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 82] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 14044, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap basel the the the] Loss[0.75365] Acc[0.77748] Prec[1.0] Recall[0.77748] F1[0.87464] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 83] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1158, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap context the the the] Loss[0.74405] Acc[0.77894] Prec[1.0] Recall[0.77894] F1[0.87565] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 84] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1681, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap reporting the the the] Loss[0.91813] Acc[0.7431] Prec[1.0] Recall[0.7431] F1[0.85244] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 85] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1623, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap alternative the the the] Loss[0.60656] Acc[0.82834] Prec[1.0] Recall[0.82834] F1[0.90587] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 86] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2831, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap reimburse the the the] Loss[0.82806] Acc[0.74745] Prec[1.0] Recall[0.74745] F1[0.85519] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 87] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1773, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap allocated the the the] Loss[0.81853] Acc[0.76456] Prec[1.0] Recall[0.76456] F1[0.86645] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 88] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 377, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap event the the the] Loss[0.7716] Acc[0.75973] Prec[1.0] Recall[0.75973] F1[0.86335] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 89] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 14389, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap divisional the the the] Loss[0.80336] Acc[0.76631] Prec[1.0] Recall[0.76631] F1[0.86747] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 90] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 14098, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskapogle the the the] Loss[0.79521] Acc[0.77571] Prec[1.0] Recall[0.77571] F1[0.8734] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 91] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2922, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap shared the the the] Loss[0.77888] Acc[0.77684] Prec[1.0] Recall[0.77684] F1[0.87424] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 92] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3102, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap replace the the the] Loss[0.82479] Acc[0.77524] Prec[1.0] Recall[0.77524] F1[0.87309] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 93] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 6430, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap logo the the the] Loss[0.77879] Acc[0.77471] Prec[1.0] Recall[0.77471] F1[0.87291] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 94] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1375, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap majority the the the] Loss[0.75485] Acc[0.78228] Prec[1.0] Recall[0.78228] F1[0.87771] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 95] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1308, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap licence the the the] Loss[0.91088] Acc[0.7429] Prec[1.0] Recall[0.7429] F1[0.85238] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 96] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 2300, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap cooperate the the the] Loss[0.75292] Acc[0.77594] Prec[1.0] Recall[0.77594] F1[0.87376] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 97] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 4879, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap ceases the the the] Loss[0.73353] Acc[0.77876] Prec[1.0] Recall[0.77876] F1[0.87523] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 98] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 3776, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap proportionate the the the] Loss[0.77159] Acc[0.76656] Prec[1.0] Recall[0.76656] F1[0.86774] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  6, 99] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 11790, 207, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap relocate the the the] Loss[0.67122] Acc[0.80146] Prec[1.0] Recall[0.80146] F1[0.88951] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","Worst loss 1.0502373422345808 with candidates [11858, 6900, 5312, 4162, 207, 30162, 1227, 207, 207, 207] in the 6-iteration with tokens [telegram naphth testify injunctive theenskap notify the the the]\n","candidates [  753  1137  9312  3652  2284  2315 17825  6710  6440 12323 19693  5818\n","  4353 10859   601  2294  4114  2389 14405  2793  5942  5238  4347  5880\n","  4414   512  8397 14354  3466   566  6007  7415   694  3861  2510  1599\n"," 15198 24013 15166  4980  1996   154  7918  3025  7111  5332 23010  8680\n","  2659   457 11149  1305 17071   326  4074   744  3462 14990  5605   819\n"," 18868  2491   552   911  1836  6743  1643  1015   936  6144  3194  9148\n","  9263  3680 13438  3558  5008  8973  3575   400 28914  5099  9140 23832\n","  2547 21462  1866 12259 23442  1361  8416  2985 25487  8739  7380 30484\n"," 11724 11156 18949  3042]\n","[  7,  0] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 753, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify agree the the] Loss[0.66102] Acc[0.80517] Prec[1.0] Recall[0.80517] F1[0.89189] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  1] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1137, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify acknowledge the the] Loss[0.76902] Acc[0.78197] Prec[1.0] Recall[0.78197] F1[0.8774] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  2] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 9312, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify restate the the] Loss[0.86361] Acc[0.74878] Prec[1.0] Recall[0.74878] F1[0.85619] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  3] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3652, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify understand the the] Loss[0.86047] Acc[0.75192] Prec[1.0] Recall[0.75192] F1[0.85832] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  4] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2284, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify recitals the the] Loss[0.83433] Acc[0.7534] Prec[1.0] Recall[0.7534] F1[0.85925] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  5] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2315, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify understood the the] Loss[0.81964] Acc[0.76322] Prec[1.0] Recall[0.76322] F1[0.8655] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  6] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 17825, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifytitu the the] Loss[0.96994] Acc[0.71017] Prec[1.0] Recall[0.71017] F1[0.83037] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  7] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 6710, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify disagree the the] Loss[0.79002] Acc[0.7689] Prec[1.0] Recall[0.7689] F1[0.86927] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  8] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 6440, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify denominator the the] Loss[0.88229] Acc[0.73532] Prec[1.0] Recall[0.73532] F1[0.84738] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7,  9] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 12323, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify witnesse the the] Loss[0.98626] Acc[0.71498] Prec[1.0] Recall[0.71498] F1[0.83357] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 10] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 19693, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifywhereas the the] Loss[0.90045] Acc[0.73768] Prec[1.0] Recall[0.73768] F1[0.84881] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 11] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 5818, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify plead the the] Loss[0.94587] Acc[0.71858] Prec[1.0] Recall[0.71858] F1[0.83617] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 12] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 4353, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify intend the the] Loss[0.81668] Acc[0.76657] Prec[1.0] Recall[0.76657] F1[0.86764] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 13] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 10859, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify determin the the] Loss[0.94037] Acc[0.72703] Prec[1.0] Recall[0.72703] F1[0.84171] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 14] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 601, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify adopted the the] Loss[0.82519] Acc[0.7568] Prec[1.0] Recall[0.7568] F1[0.86145] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 15] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2294, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify acknowledged the the] Loss[0.8309] Acc[0.76773] Prec[1.0] Recall[0.76773] F1[0.86842] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 16] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 4114, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify accepts the the] Loss[0.85197] Acc[0.75416] Prec[1.0] Recall[0.75416] F1[0.85962] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 17] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2389, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify reflect the the] Loss[0.78215] Acc[0.77712] Prec[1.0] Recall[0.77712] F1[0.87443] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 18] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 14405, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifygoing the the] Loss[0.79657] Acc[0.76558] Prec[1.0] Recall[0.76558] F1[0.86713] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 19] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2793, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify considering the the] Loss[0.81485] Acc[0.76214] Prec[1.0] Recall[0.76214] F1[0.86488] => Worst<<Loss>>[1.0502] Found at [  6, 41]\n","[  7, 20] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 5942, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify notifies the the] Loss[1.0543] Acc[0.69807] Prec[1.0] Recall[0.69807] F1[0.82193] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 21] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 5238, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify uncertainty the the] Loss[0.73893] Acc[0.77942] Prec[1.0] Recall[0.77942] F1[0.87589] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 22] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 4347, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify repeated the the] Loss[0.8603] Acc[0.74748] Prec[1.0] Recall[0.74748] F1[0.85536] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 23] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 5880, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify clarification the the] Loss[0.76417] Acc[0.77404] Prec[1.0] Recall[0.77404] F1[0.87249] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 24] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 4414, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify breached the the] Loss[0.74491] Acc[0.78039] Prec[1.0] Recall[0.78039] F1[0.87649] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 25] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 512, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify defined the the] Loss[0.82674] Acc[0.7571] Prec[1.0] Recall[0.7571] F1[0.86164] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 26] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 8397, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify honour the the] Loss[0.93963] Acc[0.71976] Prec[1.0] Recall[0.71976] F1[0.8369] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 27] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 14354, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify targa the the] Loss[0.96279] Acc[0.71478] Prec[1.0] Recall[0.71478] F1[0.83351] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 28] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3466, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify sense the the] Loss[0.83337] Acc[0.75574] Prec[1.0] Recall[0.75574] F1[0.86083] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 29] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 566, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify hereof the the] Loss[0.83744] Acc[0.74742] Prec[1.0] Recall[0.74742] F1[0.85531] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 30] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 6007, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify stress the the] Loss[0.83682] Acc[0.74607] Prec[1.0] Recall[0.74607] F1[0.85445] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 31] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 7415, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify clarified the the] Loss[0.78162] Acc[0.7793] Prec[1.0] Recall[0.7793] F1[0.87581] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 32] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 694, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify agrees the the] Loss[0.8117] Acc[0.76917] Prec[1.0] Recall[0.76917] F1[0.86942] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 33] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3861, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify adopting the the] Loss[0.90813] Acc[0.73468] Prec[1.0] Recall[0.73468] F1[0.84694] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 34] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2510, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify irrevocably the the] Loss[0.98354] Acc[0.72029] Prec[1.0] Recall[0.72029] F1[0.8372] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 35] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1599, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify accept the the] Loss[0.87771] Acc[0.74251] Prec[1.0] Recall[0.74251] F1[0.85215] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 36] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 15198, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify ade the the] Loss[0.89351] Acc[0.73492] Prec[1.0] Recall[0.73492] F1[0.84711] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 37] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 24013, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify misconstrue the the] Loss[0.87965] Acc[0.74185] Prec[1.0] Recall[0.74185] F1[0.85165] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 38] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 15166, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify emphasise the the] Loss[0.87137] Acc[0.73925] Prec[1.0] Recall[0.73925] F1[0.84991] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 39] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 4980, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify clarity the the] Loss[0.7762] Acc[0.76801] Prec[1.0] Recall[0.76801] F1[0.86869] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 40] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1996, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify know the the] Loss[0.89951] Acc[0.74753] Prec[1.0] Recall[0.74753] F1[0.85543] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 41] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 154, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify j the the] Loss[0.99375] Acc[0.70528] Prec[1.0] Recall[0.70528] F1[0.827] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 42] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 7918, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify agreeing the the] Loss[0.83982] Acc[0.7585] Prec[1.0] Recall[0.7585] F1[0.8625] => Worst<<Loss>>[1.0543] Found at [  7, 20]\n","[  7, 43] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3025, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify declare the the] Loss[1.0576] Acc[0.6883] Prec[1.0] Recall[0.6883] F1[0.81514] => Worst<<Loss>>[1.0576] Found at [  7, 43]\n","[  7, 44] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 7111, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify remedied the the] Loss[0.81625] Acc[0.76234] Prec[1.0] Recall[0.76234] F1[0.86494] => Worst<<Loss>>[1.0576] Found at [  7, 43]\n","[  7, 45] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 5332, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify clarify the the] Loss[0.83819] Acc[0.75089] Prec[1.0] Recall[0.75089] F1[0.85765] => Worst<<Loss>>[1.0576] Found at [  7, 43]\n","[  7, 46] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 23010, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifymedi the the] Loss[0.87119] Acc[0.73832] Prec[1.0] Recall[0.73832] F1[0.84935] => Worst<<Loss>>[1.0576] Found at [  7, 43]\n","[  7, 47] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 8680, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify adopts the the] Loss[0.83845] Acc[0.75466] Prec[1.0] Recall[0.75466] F1[0.86005] => Worst<<Loss>>[1.0576] Found at [  7, 43]\n","[  7, 48] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive the the] Loss[1.0831] Acc[0.6897] Prec[1.0] Recall[0.6897] F1[0.8162] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 49] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 457, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify hereby the the] Loss[0.84453] Acc[0.75408] Prec[1.0] Recall[0.75408] F1[0.85966] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 50] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 11149, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify adherence the the] Loss[0.8323] Acc[0.74885] Prec[1.0] Recall[0.74885] F1[0.85632] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 51] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1305, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify substantially the the] Loss[0.90145] Acc[0.74086] Prec[1.0] Recall[0.74086] F1[0.85105] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 52] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 17071, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify curi the the] Loss[0.95882] Acc[0.71017] Prec[1.0] Recall[0.71017] F1[0.83036] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 53] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 326, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify notice the the] Loss[1.0036] Acc[0.70033] Prec[1.0] Recall[0.70033] F1[0.82354] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 54] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 4074, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify deny the the] Loss[1.0133] Acc[0.70173] Prec[1.0] Recall[0.70173] F1[0.8245] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 55] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 744, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify reason the the] Loss[0.77916] Acc[0.75512] Prec[1.0] Recall[0.75512] F1[0.86042] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 56] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3462, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify understands the the] Loss[0.90261] Acc[0.74333] Prec[1.0] Recall[0.74333] F1[0.8526] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 57] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 14990, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify mindful the the] Loss[0.84367] Acc[0.74923] Prec[1.0] Recall[0.74923] F1[0.8565] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 58] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 5605, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify oppose the the] Loss[0.83791] Acc[0.76167] Prec[1.0] Recall[0.76167] F1[0.8645] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 59] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 819, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify mean the the] Loss[0.82995] Acc[0.74419] Prec[1.0] Recall[0.74419] F1[0.8533] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 60] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 18868, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify rationalis the the] Loss[0.89193] Acc[0.73856] Prec[1.0] Recall[0.73856] F1[0.84952] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 61] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2491, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify unenforceable the the] Loss[0.939] Acc[0.73063] Prec[1.0] Recall[0.73063] F1[0.84422] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 62] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 552, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify because the the] Loss[1.0204] Acc[0.70204] Prec[1.0] Recall[0.70204] F1[0.8247] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 63] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 911, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify notwithstanding the the] Loss[0.89557] Acc[0.74346] Prec[1.0] Recall[0.74346] F1[0.85275] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 64] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1836, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify amend the the] Loss[0.7195] Acc[0.79071] Prec[1.0] Recall[0.79071] F1[0.88296] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 65] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 6743, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify differently the the] Loss[0.79927] Acc[0.75758] Prec[1.0] Recall[0.75758] F1[0.86196] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 66] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1643, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify adopt the the] Loss[0.76462] Acc[0.76711] Prec[1.0] Recall[0.76711] F1[0.86811] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 67] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1015, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify accordingly the the] Loss[0.89458] Acc[0.74352] Prec[1.0] Recall[0.74352] F1[0.85274] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 68] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 936, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify now the the] Loss[0.85849] Acc[0.74316] Prec[1.0] Recall[0.74316] F1[0.85256] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 69] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 6144, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify stipulate the the] Loss[0.83429] Acc[0.75592] Prec[1.0] Recall[0.75592] F1[0.86093] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 70] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3194, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify argue the the] Loss[0.78262] Acc[0.77091] Prec[1.0] Recall[0.77091] F1[0.87056] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 71] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 9148, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify arithmetic the the] Loss[0.85189] Acc[0.74421] Prec[1.0] Recall[0.74421] F1[0.85312] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 72] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 9263, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify contemplate the the] Loss[0.83845] Acc[0.75175] Prec[1.0] Recall[0.75175] F1[0.8582] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 73] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3680, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify certainty the the] Loss[0.82293] Acc[0.7509] Prec[1.0] Recall[0.7509] F1[0.85767] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 74] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 13438, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify confusing the the] Loss[0.8587] Acc[0.74375] Prec[1.0] Recall[0.74375] F1[0.8529] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 75] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3558, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify revoke the the] Loss[0.91273] Acc[0.73628] Prec[1.0] Recall[0.73628] F1[0.8478] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 76] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 5008, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify whichever the the] Loss[1.0493] Acc[0.68526] Prec[1.0] Recall[0.68526] F1[0.81294] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 77] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 8973, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify anticipate the the] Loss[0.87762] Acc[0.74197] Prec[1.0] Recall[0.74197] F1[0.85177] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 78] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3575, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify unanimously the the] Loss[0.90758] Acc[0.73747] Prec[1.0] Recall[0.73747] F1[0.84863] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 79] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 400, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify whereas the the] Loss[0.91409] Acc[0.72852] Prec[1.0] Recall[0.72852] F1[0.84288] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 80] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 28914, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify subpara the the] Loss[1.0128] Acc[0.7009] Prec[1.0] Recall[0.7009] F1[0.82395] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 81] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 5099, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify sir the the] Loss[0.96865] Acc[0.70649] Prec[1.0] Recall[0.70649] F1[0.82786] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 82] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 9140, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify revisions the the] Loss[0.7245] Acc[0.78385] Prec[1.0] Recall[0.78385] F1[0.87867] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 83] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 23832, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifyexecution the the] Loss[0.9488] Acc[0.72486] Prec[1.0] Recall[0.72486] F1[0.84034] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 84] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2547, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify clauses the the] Loss[0.87461] Acc[0.74695] Prec[1.0] Recall[0.74695] F1[0.855] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 85] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 21462, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifystatutory the the] Loss[0.98416] Acc[0.71242] Prec[1.0] Recall[0.71242] F1[0.83177] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 86] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1866, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify doubt the the] Loss[0.83364] Acc[0.76062] Prec[1.0] Recall[0.76062] F1[0.86392] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 87] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 12259, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify disagrees the the] Loss[0.75767] Acc[0.78036] Prec[1.0] Recall[0.78036] F1[0.8765] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 88] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 23442, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifyquie the the] Loss[0.95385] Acc[0.71678] Prec[1.0] Recall[0.71678] F1[0.83488] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 89] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 1361, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify subparagraph the the] Loss[0.89258] Acc[0.74249] Prec[1.0] Recall[0.74249] F1[0.85207] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 90] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 8416, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify unanimous the the] Loss[0.90742] Acc[0.73719] Prec[1.0] Recall[0.73719] F1[0.84853] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 91] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2985, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify reform the the] Loss[0.72705] Acc[0.77784] Prec[1.0] Recall[0.77784] F1[0.87488] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 92] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 25487, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify recalculate the the] Loss[0.94279] Acc[0.72521] Prec[1.0] Recall[0.72521] F1[0.84051] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 93] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 8739, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify adjudge the the] Loss[0.96092] Acc[0.72229] Prec[1.0] Recall[0.72229] F1[0.83859] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 94] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 7380, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify interpretations the the] Loss[0.79556] Acc[0.76841] Prec[1.0] Recall[0.76841] F1[0.86885] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 95] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 30484, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify wolo the the] Loss[0.96023] Acc[0.72057] Prec[1.0] Recall[0.72057] F1[0.83743] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 96] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 11724, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notifynow the the] Loss[0.85803] Acc[0.7502] Prec[1.0] Recall[0.7502] F1[0.85701] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 97] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 11156, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify presume the the] Loss[0.98696] Acc[0.71196] Prec[1.0] Recall[0.71196] F1[0.83157] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 98] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 18949, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify underlie the the] Loss[0.86208] Acc[0.74883] Prec[1.0] Recall[0.74883] F1[0.85625] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  7, 99] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 3042, 207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify approve the the] Loss[0.86841] Acc[0.74248] Prec[1.0] Recall[0.74248] F1[0.85206] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","Worst loss 1.0830891016990907 with candidates [11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 207, 207] in the 7-iteration with tokens [telegram naphth testify injunctive theenskap notify waive the the]\n","candidates [26167 29132  3207  3955 29350 20147  7320  6034  4007 14997  8034  7794\n"," 21721 18868  5787 11790 15124 14408 17105  3986 30484 14461  4621  5818\n"," 21631  9235  7404 26913 24137 30480  3068  9227 16511 25267 14570 23067\n","  4855 19182 28022 21798 25946 14853 13546 21086 15166 22659  4912  1126\n"," 13398  6743 15691 12501  9254  6185   807 14650 28830  4920 11568 23908\n","  3369 24312 13137 23625  8711  6205 25599 29402  7716 23043  7642 11516\n","  8517  8820 24621 13135 13969 24322  1088  9932  3250  2840 15282  1253\n","  1836 28717 30024  3102   753  8914 13512  1069 11547  1688  7843 16714\n"," 20644  3756  1472 17623]\n","[  8,  0] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 26167, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive diverg the] Loss[0.91802] Acc[0.7458] Prec[1.0] Recall[0.7458] F1[0.85403] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  1] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 29132, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive deviat the] Loss[0.91244] Acc[0.75042] Prec[1.0] Recall[0.75042] F1[0.85706] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  2] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3207, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveturn the] Loss[0.95837] Acc[0.71863] Prec[1.0] Recall[0.71863] F1[0.83609] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  3] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3955, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waivefeu the] Loss[0.94356] Acc[0.72725] Prec[1.0] Recall[0.72725] F1[0.84193] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  4] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 29350, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive wauke the] Loss[1.0141] Acc[0.70763] Prec[1.0] Recall[0.70763] F1[0.82854] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  5] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 20147, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveigu the] Loss[0.9476] Acc[0.73215] Prec[1.0] Recall[0.73215] F1[0.84506] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  6] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 7320, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive flexi the] Loss[0.90083] Acc[0.74216] Prec[1.0] Recall[0.74216] F1[0.85164] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  7] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 6034, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive overlap the] Loss[0.83234] Acc[0.76772] Prec[1.0] Recall[0.76772] F1[0.8682] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  8] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 4007, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive desirabl the] Loss[0.94884] Acc[0.72731] Prec[1.0] Recall[0.72731] F1[0.84193] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8,  9] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 14997, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waivelop the] Loss[0.97643] Acc[0.7133] Prec[1.0] Recall[0.7133] F1[0.83247] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 10] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 8034, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive divestiture the] Loss[0.86293] Acc[0.75444] Prec[1.0] Recall[0.75444] F1[0.85965] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 11] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 7794, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive adhere the] Loss[0.88653] Acc[0.74166] Prec[1.0] Recall[0.74166] F1[0.85148] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 12] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 21721, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive dragg the] Loss[0.95525] Acc[0.72475] Prec[1.0] Recall[0.72475] F1[0.84025] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 13] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 18868, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive rationalis the] Loss[0.90696] Acc[0.74141] Prec[1.0] Recall[0.74141] F1[0.85122] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 14] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 5787, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive consequential the] Loss[0.91134] Acc[0.74906] Prec[1.0] Recall[0.74906] F1[0.85621] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 15] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 11790, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive relocate the] Loss[0.76759] Acc[0.77539] Prec[1.0] Recall[0.77539] F1[0.8733] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 16] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 15124, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive deterren the] Loss[0.93692] Acc[0.73523] Prec[1.0] Recall[0.73523] F1[0.847] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 17] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 14408, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive reallocate the] Loss[0.91611] Acc[0.74708] Prec[1.0] Recall[0.74708] F1[0.85492] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 18] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 17105, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive accumulate the] Loss[0.91439] Acc[0.73721] Prec[1.0] Recall[0.73721] F1[0.84851] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 19] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3986, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive likelihood the] Loss[0.87411] Acc[0.7464] Prec[1.0] Recall[0.7464] F1[0.85465] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 20] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 30484, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive wolo the] Loss[0.95993] Acc[0.72868] Prec[1.0] Recall[0.72868] F1[0.84276] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 21] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 14461, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive dissuasi the] Loss[0.91401] Acc[0.7491] Prec[1.0] Recall[0.7491] F1[0.85621] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 22] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 4621, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive refrain the] Loss[0.94668] Acc[0.72353] Prec[1.0] Recall[0.72353] F1[0.83942] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 23] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 5818, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive plead the] Loss[1.0262] Acc[0.70409] Prec[1.0] Recall[0.70409] F1[0.82622] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 24] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 21631, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive sevastopo the] Loss[1.0626] Acc[0.70064] Prec[1.0] Recall[0.70064] F1[0.8237] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 25] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 9235, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive anywhere the] Loss[0.95438] Acc[0.71905] Prec[1.0] Recall[0.71905] F1[0.83641] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 26] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 7404, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive detrimental the] Loss[0.91142] Acc[0.72704] Prec[1.0] Recall[0.72704] F1[0.84181] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 27] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 26913, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive ellip the] Loss[0.94718] Acc[0.73139] Prec[1.0] Recall[0.73139] F1[0.84458] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 28] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 24137, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive distraction the] Loss[0.76334] Acc[0.78241] Prec[1.0] Recall[0.78241] F1[0.87762] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 29] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 30480, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive refile the] Loss[0.96267] Acc[0.71812] Prec[1.0] Recall[0.71812] F1[0.83581] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 30] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3068, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive remove the] Loss[0.86106] Acc[0.74909] Prec[1.0] Recall[0.74909] F1[0.85623] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 31] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 9227, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive approache the] Loss[0.88368] Acc[0.75025] Prec[1.0] Recall[0.75025] F1[0.85709] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 32] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 16511, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive peninsula the] Loss[0.96471] Acc[0.71908] Prec[1.0] Recall[0.71908] F1[0.83638] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 33] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 25267, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive streamlin the] Loss[0.98164] Acc[0.71587] Prec[1.0] Recall[0.71587] F1[0.83421] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 34] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 14570, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive surprising the] Loss[0.88239] Acc[0.74837] Prec[1.0] Recall[0.74837] F1[0.85576] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 35] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 23067, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveravan the] Loss[0.95392] Acc[0.73777] Prec[1.0] Recall[0.73777] F1[0.84873] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 36] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 4855, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive governance the] Loss[0.88666] Acc[0.74312] Prec[1.0] Recall[0.74312] F1[0.85254] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 37] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 19182, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive carryback the] Loss[1.0035] Acc[0.70864] Prec[1.0] Recall[0.70864] F1[0.82929] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 38] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 28022, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive blurr the] Loss[0.92244] Acc[0.74889] Prec[1.0] Recall[0.74889] F1[0.85604] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 39] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 21798, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waivearound the] Loss[0.86025] Acc[0.75745] Prec[1.0] Recall[0.75745] F1[0.86181] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 40] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 25946, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive sodisc the] Loss[0.98828] Acc[0.72104] Prec[1.0] Recall[0.72104] F1[0.83768] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 41] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 14853, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive carryover the] Loss[0.94605] Acc[0.73005] Prec[1.0] Recall[0.73005] F1[0.84372] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 42] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 13546, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive divergence the] Loss[0.86654] Acc[0.75633] Prec[1.0] Recall[0.75633] F1[0.86097] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 43] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 21086, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive adher the] Loss[0.90167] Acc[0.74091] Prec[1.0] Recall[0.74091] F1[0.85091] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 44] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 15166, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive emphasise the] Loss[0.8957] Acc[0.74598] Prec[1.0] Recall[0.74598] F1[0.85424] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 45] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 22659, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveingbo the] Loss[1.0152] Acc[0.70555] Prec[1.0] Recall[0.70555] F1[0.82709] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 46] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 4912, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive harmonis the] Loss[0.9441] Acc[0.7368] Prec[1.0] Recall[0.7368] F1[0.84807] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 47] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 1126, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive remedies the] Loss[0.93726] Acc[0.72915] Prec[1.0] Recall[0.72915] F1[0.84313] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 48] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 13398, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive scal the] Loss[0.99837] Acc[0.7225] Prec[1.0] Recall[0.7225] F1[0.83854] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 49] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 6743, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive differently the] Loss[0.84749] Acc[0.76071] Prec[1.0] Recall[0.76071] F1[0.86383] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 50] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 15691, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive connectiv the] Loss[0.87554] Acc[0.75882] Prec[1.0] Recall[0.75882] F1[0.86259] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 51] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 12501, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive expend the] Loss[0.90941] Acc[0.72811] Prec[1.0] Recall[0.72811] F1[0.84252] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 52] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 9254, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive diminution the] Loss[0.72824] Acc[0.79526] Prec[1.0] Recall[0.79526] F1[0.88564] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 53] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 6185, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveendum the] Loss[0.97182] Acc[0.71143] Prec[1.0] Recall[0.71143] F1[0.83118] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 54] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 807, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive limitation the] Loss[0.90465] Acc[0.73298] Prec[1.0] Recall[0.73298] F1[0.8458] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 55] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 14650, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveluk the] Loss[0.948] Acc[0.73725] Prec[1.0] Recall[0.73725] F1[0.84838] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 56] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 28830, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive protrud the] Loss[0.95594] Acc[0.72321] Prec[1.0] Recall[0.72321] F1[0.83916] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 57] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 4920, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive plural the] Loss[0.89903] Acc[0.73469] Prec[1.0] Recall[0.73469] F1[0.84693] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 58] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 11568, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive migrat the] Loss[0.86827] Acc[0.75438] Prec[1.0] Recall[0.75438] F1[0.8597] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 59] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 23908, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waivesquare the] Loss[0.97412] Acc[0.71713] Prec[1.0] Recall[0.71713] F1[0.83505] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 60] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3369, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive forum the] Loss[0.9523] Acc[0.73131] Prec[1.0] Recall[0.73131] F1[0.84464] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 61] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 24312, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waivesteel the] Loss[0.94851] Acc[0.72725] Prec[1.0] Recall[0.72725] F1[0.84171] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 62] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 13137, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waivemir the] Loss[0.96944] Acc[0.7186] Prec[1.0] Recall[0.7186] F1[0.83605] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 63] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 23625, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveamone the] Loss[0.91183] Acc[0.74692] Prec[1.0] Recall[0.74692] F1[0.85472] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 64] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 8711, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive sharehold the] Loss[0.96969] Acc[0.71762] Prec[1.0] Recall[0.71762] F1[0.83542] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 65] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 6205, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive reinforce the] Loss[0.89827] Acc[0.73724] Prec[1.0] Recall[0.73724] F1[0.84856] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 66] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 25599, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waivemphas the] Loss[0.91927] Acc[0.74409] Prec[1.0] Recall[0.74409] F1[0.85293] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 67] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 29402, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveroko the] Loss[0.96128] Acc[0.72273] Prec[1.0] Recall[0.72273] F1[0.83884] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 68] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 7716, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive inaction the] Loss[0.72838] Acc[0.78124] Prec[1.0] Recall[0.78124] F1[0.877] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 69] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 23043, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive extrapolate the] Loss[0.9212] Acc[0.74456] Prec[1.0] Recall[0.74456] F1[0.85317] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 70] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 7642, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive derogat the] Loss[0.90237] Acc[0.74259] Prec[1.0] Recall[0.74259] F1[0.85202] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 71] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 11516, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive timeframe the] Loss[0.89077] Acc[0.73775] Prec[1.0] Recall[0.73775] F1[0.84901] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 72] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 8517, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive eliminat the] Loss[0.90599] Acc[0.73825] Prec[1.0] Recall[0.73825] F1[0.84907] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 73] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 8820, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waivebster the] Loss[1.0072] Acc[0.70684] Prec[1.0] Recall[0.70684] F1[0.82798] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 74] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 24621, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive efficienc the] Loss[0.90337] Acc[0.74986] Prec[1.0] Recall[0.74986] F1[0.85683] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 75] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 13135, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive tempori the] Loss[0.95261] Acc[0.72183] Prec[1.0] Recall[0.72183] F1[0.83826] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 76] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 13969, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive focuse the] Loss[0.89764] Acc[0.75003] Prec[1.0] Recall[0.75003] F1[0.85685] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 77] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 24322, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive trajector the] Loss[0.91805] Acc[0.75103] Prec[1.0] Recall[0.75103] F1[0.85748] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 78] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 1088, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive continue the] Loss[0.8532] Acc[0.75234] Prec[1.0] Recall[0.75234] F1[0.85847] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 79] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 9932, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveistic the] Loss[0.90305] Acc[0.74324] Prec[1.0] Recall[0.74324] F1[0.85236] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 80] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3250, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive strengthen the] Loss[0.9149] Acc[0.74103] Prec[1.0] Recall[0.74103] F1[0.8511] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 81] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 2840, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive sweden the] Loss[0.98616] Acc[0.71099] Prec[1.0] Recall[0.71099] F1[0.83089] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 82] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 15282, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waiveomega the] Loss[1.0112] Acc[0.72389] Prec[1.0] Recall[0.72389] F1[0.83948] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 83] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 1253, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive remain the] Loss[0.88088] Acc[0.74448] Prec[1.0] Recall[0.74448] F1[0.85336] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 84] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 1836, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive amend the] Loss[0.88362] Acc[0.75737] Prec[1.0] Recall[0.75737] F1[0.86154] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 85] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 28717, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive neptun the] Loss[0.98727] Acc[0.71734] Prec[1.0] Recall[0.71734] F1[0.83509] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 86] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 30024, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive coexist the] Loss[0.90728] Acc[0.74612] Prec[1.0] Recall[0.74612] F1[0.85433] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 87] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3102, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive replace the] Loss[0.90101] Acc[0.74877] Prec[1.0] Recall[0.74877] F1[0.85588] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 88] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 753, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive agree the] Loss[0.82748] Acc[0.7585] Prec[1.0] Recall[0.7585] F1[0.8626] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 89] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 8914, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive commercialize the] Loss[0.91] Acc[0.73604] Prec[1.0] Recall[0.73604] F1[0.84775] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 90] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 13512, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive dissimilar the] Loss[0.87985] Acc[0.75227] Prec[1.0] Recall[0.75227] F1[0.85844] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 91] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 1069, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive maintain the] Loss[0.92394] Acc[0.74] Prec[1.0] Recall[0.74] F1[0.8504] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 92] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 11547, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive deterrent the] Loss[0.90372] Acc[0.74414] Prec[1.0] Recall[0.74414] F1[0.85291] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 93] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 1688, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive rise the] Loss[0.83084] Acc[0.75691] Prec[1.0] Recall[0.75691] F1[0.86151] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 94] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 7843, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive convergen the] Loss[0.91911] Acc[0.7395] Prec[1.0] Recall[0.7395] F1[0.85] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 95] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 16714, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive windfall the] Loss[0.9549] Acc[0.72737] Prec[1.0] Recall[0.72737] F1[0.8419] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 96] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 20644, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive destabilis the] Loss[0.93587] Acc[0.74087] Prec[1.0] Recall[0.74087] F1[0.8507] => Worst<<Loss>>[1.0831] Found at [  7, 48]\n","[  8, 97] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability the] Loss[1.1242] Acc[0.67631] Prec[1.0] Recall[0.67631] F1[0.80668] => Worst<<Loss>>[1.1242] Found at [  8, 97]\n","[  8, 98] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 1472, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive markets the] Loss[0.8822] Acc[0.74608] Prec[1.0] Recall[0.74608] F1[0.85427] => Worst<<Loss>>[1.1242] Found at [  8, 97]\n","[  8, 99] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 17623, 207]] TokensDesc[telegram naphth testify injunctive theenskap notify waive paradigm the] Loss[0.89307] Acc[0.75359] Prec[1.0] Recall[0.75359] F1[0.85924] => Worst<<Loss>>[1.1242] Found at [  8, 97]\n","Worst loss 1.1241709205412096 with candidates [11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 207] in the 8-iteration with tokens [telegram naphth testify injunctive theenskap notify waive severability the]\n","candidates [15550  2145 24137 21264 19353  6508 10441  5101 24382  2878  1498 17225\n","  2300  9254  3586 11857  4401  8153  5424 10947  6537 23010 22879  2053\n","  8518  2117  9235 13914 17377  8722  1350  6563   818 10959  7716 12526\n","  8506  2372  5980 10357 20722  2010 11004  6339 16893 14044  2196   808\n","   474  3956 17500  1626  4673  3986  1795  4320  3906  4621  1930 11321\n","  7404 22074 16001 15050 22821 13076   579 20565 11441 26780  4861  5344\n"," 13124  6080  6636 12063  6066  3238 10722  3910  4486 17372 22128 10902\n","  7219  4075 16456   410  1419  4284  8301 26702 17601  1636 11554 21798\n"," 27769 24932  3492 26587]\n","[  9,  0] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 15550]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability refraining] Loss[1.0872] Acc[0.69628] Prec[1.0] Recall[0.69628] F1[0.82067] => Worst<<Loss>>[1.1242] Found at [  8, 97]\n","[  9,  1] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 2145]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability threatened] Loss[1.025] Acc[0.7066] Prec[1.0] Recall[0.7066] F1[0.82797] => Worst<<Loss>>[1.1242] Found at [  8, 97]\n","[  9,  2] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 24137]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability distraction] Loss[0.85595] Acc[0.75911] Prec[1.0] Recall[0.75911] F1[0.86272] => Worst<<Loss>>[1.1242] Found at [  8, 97]\n","[  9,  3] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 21264]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilityasure] Loss[0.94228] Acc[0.73546] Prec[1.0] Recall[0.73546] F1[0.84735] => Worst<<Loss>>[1.1242] Found at [  8, 97]\n","[  9,  4] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 19353]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability impulse] Loss[1.2219] Acc[0.6665] Prec[1.0] Recall[0.6665] F1[0.79973] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9,  5] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 6508]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability disruption] Loss[0.88098] Acc[0.7408] Prec[1.0] Recall[0.7408] F1[0.85088] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9,  6] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 10441]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilityhusk] Loss[1.0782] Acc[0.68952] Prec[1.0] Recall[0.68952] F1[0.81604] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9,  7] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 5101]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability inability] Loss[0.99956] Acc[0.7094] Prec[1.0] Recall[0.7094] F1[0.82984] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9,  8] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 24382]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability diminishes] Loss[0.86166] Acc[0.75834] Prec[1.0] Recall[0.75834] F1[0.86227] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9,  9] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 2878]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability compared] Loss[0.96277] Acc[0.73316] Prec[1.0] Recall[0.73316] F1[0.84586] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 10] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 1498]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability potential] Loss[1.0469] Acc[0.70942] Prec[1.0] Recall[0.70942] F1[0.82978] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 11] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 17225]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability impunity] Loss[0.97224] Acc[0.71779] Prec[1.0] Recall[0.71779] F1[0.83544] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 12] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 2300]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability cooperate] Loss[1.0271] Acc[0.7078] Prec[1.0] Recall[0.7078] F1[0.82872] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 13] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 9254]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability diminution] Loss[0.83674] Acc[0.754] Prec[1.0] Recall[0.754] F1[0.85955] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 14] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 3586]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability recall] Loss[1.1468] Acc[0.67435] Prec[1.0] Recall[0.67435] F1[0.8054] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 15] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 11857]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability escalation] Loss[0.95149] Acc[0.7392] Prec[1.0] Recall[0.7392] F1[0.84975] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 16] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 4401]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability reputation] Loss[1.052] Acc[0.69905] Prec[1.0] Recall[0.69905] F1[0.82276] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 17] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 8153]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability updates] Loss[0.97234] Acc[0.7247] Prec[1.0] Recall[0.7247] F1[0.84016] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 18] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 5424]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability usage] Loss[1.0486] Acc[0.70888] Prec[1.0] Recall[0.70888] F1[0.82944] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 19] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 10947]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability disparage] Loss[0.98615] Acc[0.72173] Prec[1.0] Recall[0.72173] F1[0.83819] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 20] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 6537]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability detriment] Loss[0.92645] Acc[0.73127] Prec[1.0] Recall[0.73127] F1[0.84453] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 21] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 23010]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilitymedi] Loss[1.0255] Acc[0.72016] Prec[1.0] Recall[0.72016] F1[0.83695] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 22] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 22879]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilitysatisfaction] Loss[1.0454] Acc[0.71096] Prec[1.0] Recall[0.71096] F1[0.83086] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 23] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 2053]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability ability] Loss[0.96898] Acc[0.72139] Prec[1.0] Recall[0.72139] F1[0.83795] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 24] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 8518]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability perceived] Loss[0.95818] Acc[0.73379] Prec[1.0] Recall[0.73379] F1[0.8462] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 25] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 2117]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability separation] Loss[1.0346] Acc[0.70569] Prec[1.0] Recall[0.70569] F1[0.8272] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 26] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 9235]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability anywhere] Loss[1.0673] Acc[0.69768] Prec[1.0] Recall[0.69768] F1[0.82175] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 27] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 13914]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability throughput] Loss[1.0737] Acc[0.70372] Prec[1.0] Recall[0.70372] F1[0.82596] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 28] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 17377]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability disparag] Loss[0.9423] Acc[0.7347] Prec[1.0] Recall[0.7347] F1[0.84676] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 29] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 8722]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability imputed] Loss[1.0096] Acc[0.71603] Prec[1.0] Recall[0.71603] F1[0.83432] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 30] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 1350]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability efforts] Loss[1.092] Acc[0.68843] Prec[1.0] Recall[0.68843] F1[0.8153] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 31] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 6563]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability behavior] Loss[0.99271] Acc[0.72424] Prec[1.0] Recall[0.72424] F1[0.83984] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 32] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 818]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability conduct] Loss[1.1] Acc[0.68535] Prec[1.0] Recall[0.68535] F1[0.81314] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 33] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 10959]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilitydifference] Loss[0.97154] Acc[0.72795] Prec[1.0] Recall[0.72795] F1[0.84224] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 34] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 7716]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability inaction] Loss[0.87368] Acc[0.74677] Prec[1.0] Recall[0.74677] F1[0.85481] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 35] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 12526]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability harmed] Loss[0.97121] Acc[0.71834] Prec[1.0] Recall[0.71834] F1[0.83592] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 36] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 8506]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability consensus] Loss[0.94492] Acc[0.73992] Prec[1.0] Recall[0.73992] F1[0.85025] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 37] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 2372]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability adversely] Loss[0.99416] Acc[0.71459] Prec[1.0] Recall[0.71459] F1[0.83335] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 38] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 5980]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability formulation] Loss[1.0269] Acc[0.71746] Prec[1.0] Recall[0.71746] F1[0.8353] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 39] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 10357]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability widespread] Loss[0.91227] Acc[0.74293] Prec[1.0] Recall[0.74293] F1[0.85223] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 40] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 20722]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability livelihood] Loss[0.97114] Acc[0.71806] Prec[1.0] Recall[0.71806] F1[0.83581] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 41] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 2010]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability competitive] Loss[1.0362] Acc[0.70894] Prec[1.0] Recall[0.70894] F1[0.82948] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 42] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 11004]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilityabilities] Loss[1.0484] Acc[0.70937] Prec[1.0] Recall[0.70937] F1[0.82973] => Worst<<Loss>>[1.2219] Found at [  9,  4]\n","[  9, 43] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 6339]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability inducement] Loss[1.2397] Acc[0.65081] Prec[1.0] Recall[0.65081] F1[0.78836] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 44] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 16893]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability interact] Loss[0.9283] Acc[0.74676] Prec[1.0] Recall[0.74676] F1[0.85481] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 45] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 14044]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability basel] Loss[0.94962] Acc[0.73648] Prec[1.0] Recall[0.73648] F1[0.84793] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 46] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 2196]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability experience] Loss[1.0159] Acc[0.71285] Prec[1.0] Recall[0.71285] F1[0.83218] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 47] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 808]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability access] Loss[0.947] Acc[0.71996] Prec[1.0] Recall[0.71996] F1[0.83694] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 48] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 474]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability termination] Loss[0.99777] Acc[0.70682] Prec[1.0] Recall[0.70682] F1[0.82803] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 49] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 3956]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability geographic] Loss[1.0191] Acc[0.71017] Prec[1.0] Recall[0.71017] F1[0.8303] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 50] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 17500]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability reschedul] Loss[1.0083] Acc[0.72252] Prec[1.0] Recall[0.72252] F1[0.83872] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 51] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 1626]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability attention] Loss[1.038] Acc[0.71204] Prec[1.0] Recall[0.71204] F1[0.83142] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 52] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 4673]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability recalls] Loss[0.95098] Acc[0.72821] Prec[1.0] Recall[0.72821] F1[0.84251] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 53] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 3986]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability likelihood] Loss[0.97898] Acc[0.72532] Prec[1.0] Recall[0.72532] F1[0.84058] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 54] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 1795]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability continued] Loss[0.97863] Acc[0.71189] Prec[1.0] Recall[0.71189] F1[0.83149] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 55] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 4320]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability competing] Loss[1.0434] Acc[0.70771] Prec[1.0] Recall[0.70771] F1[0.82862] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 56] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 3906]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability favorable] Loss[1.0377] Acc[0.70665] Prec[1.0] Recall[0.70665] F1[0.82788] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 57] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 4621]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability refrain] Loss[1.0413] Acc[0.70469] Prec[1.0] Recall[0.70469] F1[0.82657] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 58] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 1930]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability aware] Loss[1.156] Acc[0.67771] Prec[1.0] Recall[0.67771] F1[0.80751] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 59] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 11321]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability disrupt] Loss[0.9986] Acc[0.72421] Prec[1.0] Recall[0.72421] F1[0.83978] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 60] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 7404]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability detrimental] Loss[1.0031] Acc[0.71393] Prec[1.0] Recall[0.71393] F1[0.83289] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 61] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 22074]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability entice] Loss[1.0122] Acc[0.71477] Prec[1.0] Recall[0.71477] F1[0.83357] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 62] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 16001]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability dedication] Loss[0.9481] Acc[0.7357] Prec[1.0] Recall[0.7357] F1[0.84751] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 63] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 15050]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability curtailment] Loss[0.94813] Acc[0.7348] Prec[1.0] Recall[0.7348] F1[0.84686] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 64] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 22821]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilitymission] Loss[1.0884] Acc[0.68552] Prec[1.0] Recall[0.68552] F1[0.81325] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 65] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 13076]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability penetration] Loss[0.97549] Acc[0.72592] Prec[1.0] Recall[0.72592] F1[0.84091] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 66] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 579]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability performance] Loss[1.1647] Acc[0.67443] Prec[1.0] Recall[0.67443] F1[0.80551] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 67] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 20565]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability disruptive] Loss[1.0216] Acc[0.71892] Prec[1.0] Recall[0.71892] F1[0.83616] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 68] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 11441]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability reactions] Loss[0.91533] Acc[0.7455] Prec[1.0] Recall[0.7455] F1[0.85399] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 69] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 26780]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability bestimmt] Loss[1.2132] Acc[0.65062] Prec[1.0] Recall[0.65062] F1[0.78826] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 70] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 4861]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability capacities] Loss[1.0269] Acc[0.71838] Prec[1.0] Recall[0.71838] F1[0.8358] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 71] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 5344]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability reaction] Loss[0.98523] Acc[0.72512] Prec[1.0] Recall[0.72512] F1[0.84047] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 72] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 13124]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilitysoever] Loss[1.0211] Acc[0.71279] Prec[1.0] Recall[0.71279] F1[0.83213] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 73] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 6080]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability reconciliation] Loss[1.061] Acc[0.7041] Prec[1.0] Recall[0.7041] F1[0.82611] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 74] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 6636]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability cessat] Loss[0.95849] Acc[0.72931] Prec[1.0] Recall[0.72931] F1[0.84321] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 75] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 12063]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability interpol] Loss[1.0236] Acc[0.7159] Prec[1.0] Recall[0.7159] F1[0.83423] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 76] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 6066]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability furtherance] Loss[1.0882] Acc[0.7003] Prec[1.0] Recall[0.7003] F1[0.82348] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 77] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 3238]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability transition] Loss[0.98368] Acc[0.73212] Prec[1.0] Recall[0.73212] F1[0.84506] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 78] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 10722]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability loyalty] Loss[0.983] Acc[0.72471] Prec[1.0] Recall[0.72471] F1[0.84022] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 79] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 3910]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability threat] Loss[1.0771] Acc[0.69151] Prec[1.0] Recall[0.69151] F1[0.81748] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 80] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 4486]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability success] Loss[0.97353] Acc[0.71798] Prec[1.0] Recall[0.71798] F1[0.83567] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 81] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 17372]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability favourably] Loss[0.96676] Acc[0.71978] Prec[1.0] Recall[0.71978] F1[0.83685] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 82] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 22128]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilityocal] Loss[1.06] Acc[0.70713] Prec[1.0] Recall[0.70713] F1[0.82816] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 83] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 10902]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability malfunction] Loss[0.80623] Acc[0.76064] Prec[1.0] Recall[0.76064] F1[0.86386] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 84] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 7219]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability threatening] Loss[1.1058] Acc[0.6847] Prec[1.0] Recall[0.6847] F1[0.81266] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 85] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 4075]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability involvement] Loss[0.98937] Acc[0.72949] Prec[1.0] Recall[0.72949] F1[0.84331] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 86] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 16456]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability nolo] Loss[0.94684] Acc[0.73437] Prec[1.0] Recall[0.73437] F1[0.84662] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 87] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 410]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability services] Loss[1.0303] Acc[0.70771] Prec[1.0] Recall[0.70771] F1[0.82863] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 88] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 1419]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability indirectly] Loss[0.98773] Acc[0.72022] Prec[1.0] Recall[0.72022] F1[0.83716] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 89] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 4284]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability delays] Loss[0.92106] Acc[0.72776] Prec[1.0] Recall[0.72776] F1[0.84225] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 90] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 8301]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability prorate] Loss[1.022] Acc[0.7113] Prec[1.0] Recall[0.7113] F1[0.83108] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 91] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 26702]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability disenroll] Loss[0.97247] Acc[0.7309] Prec[1.0] Recall[0.7309] F1[0.84431] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 92] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 17601]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability disrupted] Loss[0.93419] Acc[0.73614] Prec[1.0] Recall[0.73614] F1[0.84783] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 93] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 1636]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability customers] Loss[1.0183] Acc[0.70823] Prec[1.0] Recall[0.70823] F1[0.82901] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 94] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 11554]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability unforeseeable] Loss[0.9503] Acc[0.73509] Prec[1.0] Recall[0.73509] F1[0.84713] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 95] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 21798]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severabilityaround] Loss[0.96876] Acc[0.73107] Prec[1.0] Recall[0.73107] F1[0.84433] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 96] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 27769]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability disproportion] Loss[0.96187] Acc[0.73373] Prec[1.0] Recall[0.73373] F1[0.8461] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 97] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 24932]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability unprofitable] Loss[1.0739] Acc[0.69181] Prec[1.0] Recall[0.69181] F1[0.81775] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 98] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 3492]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability internet] Loss[1.049] Acc[0.70977] Prec[1.0] Recall[0.70977] F1[0.83006] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","[  9, 99] TokenID[[11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 26587]] TokensDesc[telegram naphth testify injunctive theenskap notify waive severability instigation] Loss[1.0216] Acc[0.72014] Prec[1.0] Recall[0.72014] F1[0.83703] => Worst<<Loss>>[1.2397] Found at [  9, 43]\n","Worst loss 1.2396838376598973 with candidates [11858, 6900, 5312, 4162, 207, 30162, 1227, 2659, 3756, 6339] in the 9-iteration with tokens [telegram naphth testify injunctive theenskap notify waive severability inducement]\n"]}]},{"cell_type":"code","source":["#tokenizer.decode(candidates_selected) # B unless the everyone\n","tokenizer.decode(candidates_selected) # E signature scarcely contrary -> [1297, 17560, 207] or [1297, 17560, 1004]\n","\n","# New tokens: B Worst loss 0.6033629960110111 with candidates [11858, 23347, 700] in the 2-iteration with tokens [telegram bnym him]\n","# New tokens: E Worst loss 0.41469741131990184 with candidates [1297, 14808, 16827] in the 2-iteration with tokens [signature understandable overcrowd]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9UkDXrIG0IiM","executionInfo":{"status":"ok","timestamp":1659618127780,"user_tz":-120,"elapsed":2297,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"e8c7464c-9463-4f4c-8d0d-266e30955f79"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'telegram bnym him'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["##### Generate sentences with tokens"],"metadata":{"id":"jTdsbDJapDkf"}},{"cell_type":"code","source":["len(target_unfair_sentences) #1032 bef; 991 now new distr 96(95-05)-4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2-_S4Yr1q8H","executionInfo":{"status":"ok","timestamp":1659606320467,"user_tz":-120,"elapsed":371,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"8138a4cf-6057-4fd6-dda8-7ef1587fa05c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["991"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Store new sentences with the tokens at the beginning\n","position=\"B\"\n","list_tokens_deal_worst_loss = [\n","    tokenizer.decode([621, 207, 3523]), #unless the everyone\n","    tokenizer.decode([621, 207, 207]) #unless the the\n","]\n","\n","dict_distribution = {\n","    0: 0,\n","    1: 0\n","}\n","\n","timestamp = datetime.datetime.now().strftime(\"%y%m%d_%H_%M_%S_%p\")\n","f = open(f\"ToS/DataAugmentation/Pos{position}_NumTokens{NUM_TOKENS}_{timestamp}.txt\", \"w\")\n","\n","for unf_sent in target_unfair_sentences:\n","    index = 1 if random.uniform(0,1) > 0.5 else 0\n","    f.write(f'{list_tokens_deal_worst_loss[index]} {unf_sent}\\n')\n","    dict_distribution[index] += 1\n","f.close()\n","\n","print(dict_distribution) # {0: 508, 1: 524} => {0: 471, 1: 520} (96(95-05)-04))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eADqdnKAh3e6","executionInfo":{"status":"ok","timestamp":1659606995419,"user_tz":-120,"elapsed":336,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"fc03d79a-dbdb-40c4-85e9-145e97654627"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 471, 1: 520}\n"]}]},{"cell_type":"code","source":["# Store new sentences with the tokens at the beginning\n","position=\"E\"\n","list_tokens_deal_worst_loss = [\n","    tokenizer.decode([1297, 17560, 1004]), #unless the everyone\n","    tokenizer.decode([1297, 17560, 431]) #unless the the\n","]\n","\n","dict_distribution = {\n","    0: 0,\n","    1: 0\n","}\n","\n","timestamp = datetime.datetime.now().strftime(\"%y%m%d_%H_%M_%S_%p\")\n","f = open(f\"ToS/DataAugmentation/Pos{position}_NumTokens{NUM_TOKENS}_{timestamp}.txt\", \"w\")\n","\n","for unf_sent in target_unfair_sentences:\n","    index = 1 if random.uniform(0,1) > 0.5 else 0\n","\n","    sent_tokenized = tokenizer.encode(unf_sent)\n","\n","    if len(sent_tokenized) > 507:\n","      str_aux = (tokenizer.decode(sent_tokenized[0:507])).replace(\"\\n\", \"\")\n","      f.write(f'{str_aux} {list_tokens_deal_worst_loss[index]}\\n')\n","    else:\n","      str_aux = unf_sent.replace(\"\\n\", \"\")\n","      f.write(f'{str_aux} {list_tokens_deal_worst_loss[index]}\\n')\n","    dict_distribution[index] += 1\n","f.close()\n","\n","print(dict_distribution) # {0: 513, 1: 519} => {0: 492, 1: 499} (96(95-05)-04)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ESyo77Jl1s6","executionInfo":{"status":"ok","timestamp":1659607000293,"user_tz":-120,"elapsed":464,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"9fcf3b89-d08c-44cd-9257-9b7c2e3e2ded"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 492, 1: 499}\n"]}]},{"cell_type":"markdown","source":["## Training of a new model"],"metadata":{"id":"2mthIUQypWg0"}},{"cell_type":"markdown","source":["The following code was the version for reading the sentences and labels that include the tokens at the beginning or the end.\n","\n","This is changed later for the reading of the datasets (test; and train_val).\n","\n","\n","\n","```\n","# Read unfair sentences with tokens\n","\n","augmented_sentences = get_sentences(\"ToS/DataAugmentation/\")\n","augmented_labels = [1]*len(augmented_sentences)\n","\n","print(f'{len(augmented_labels)} ?= {len(augmented_sentences)}')\n","\n","# Output:\n","# 2064 ?= 2064\n","\n","##########################################\n","\n","all_sentences_and_augmented = all_sentences + augmented_sentences\n","print(f'Length_sentences {len(all_sentences)} + Length_augmented {len(augmented_sentences)} = Len both sets {len(all_sentences_and_augmented)}')\n","\n","# Output:\n","# Length_sentences 9414 + Length_augmented 2064 = Len both sets 11478\n","\n","####\n","\n","all_labels_and_augmented = all_labels + augmented_labels\n","print(f'Length_labels {len(all_sentences)} + Length_augmented {len(augmented_sentences)} = Len both sets {len(all_labels_and_augmented)}')\n","\n","# Output:\n","# Length_labels 9414 + Length_augmented 2064 = Len both sets 11478\n","\n","\"\"\"\n","1982 ?= 1982\n","Length_sentences 9037 + Length_augmented 1982 = Len both sets 11019\n","Length_labels 9037 + Length_augmented 1982 = Len both sets 11019\n","\"\"\"\n","\n","```\n","\n"],"metadata":{"id":"OxZHvZYX9lsG"}},{"cell_type":"markdown","source":["### Data split"],"metadata":{"id":"m9POhis6qbP_"}},{"cell_type":"code","source":["all_sentences_and_augmented = get_sentences(\"ToS/TrainValSetWithAugmentedData/Sentences/\")\n","all_labels_and_augmented = get_labels(\"ToS/TrainValSetWithAugmentedData/Labels/\")"],"metadata":{"id":"Hln8HJa0-zwX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in all_sentences_and_augmented:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True, #is deprecated\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(all_labels_and_augmented)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', all_sentences_and_augmented[0])\n","print('Token IDs:', input_ids[0])\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","train_idx, valid_idx = train_test_split(np.arange(len(labels)), test_size=0.05, shuffle=True, stratify=labels)\n","\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n","valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n","\n","train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n","validation_dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=valid_sampler)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDtPTWVzp_mc","executionInfo":{"status":"ok","timestamp":1659609697052,"user_tz":-120,"elapsed":5561,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"c760a672-cf53-4fe2-b028-28148798f6ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:  you agree to our data practices, including the collection, use, processing, and sharing of your information as described in our privacy policy, as well as the transfer and processing of your information to the united states and other countries globally where we have or use facilities, service providers, or partners, regardless of where you use our services.\n","\n","Token IDs: tensor([ 101,  799,  753,  211, 1590,  586, 1748,  115,  283,  207, 1544,  115,\n","         355,  115, 1384,  115,  212, 2766,  235,  210, 1216,  286,  221,  735,\n","         213, 1590, 4407,  663,  115,  221,  705,  221,  207,  439,  212, 1384,\n","         210, 1216,  286,  211,  207,  354,  265,  212,  231,  779, 1506,  301,\n","         343,  532,  247,  215,  355, 1551,  115,  446, 3522,  115,  215, 1523,\n","         115, 2248,  210,  343,  799,  355, 1590,  410,  117,  102,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0])\n"]}]},{"cell_type":"markdown","source":["The following code was developed to create the persistent files with the augmented data.\n","\n","\n","\n","```\n","\"\"\"\n","print(type(train_idx))\n","print(len(train_idx))\n","print(train_idx[0:10])\n","print(type(train_sampler))\n","\n","for index in train_idx[0:10]:\n","    print(f'{labels[index]} <<{tokenizer.decode(input_ids[index], skip_special_tokens=True)}>>')\n","\"\"\"\n","\n","### Creation of the sets training, val and set. These sets are being stored to ensure persistency\n","\n","# Let's first get the train_val and test set\n","\n","# Create a 95-05 train-validation split.\n","train_val_ids, test_ids = train_test_split(np.arange(len(labels)), test_size=0.05, shuffle=True, stratify=labels)\n","\n","timestamp = datetime.datetime.now().strftime(\"%y%m%d_%H_%M_%S_%p\")\n","file_sentences_test_set = open(f\"ToS/TestSetWithAugmentedData/Sentences/Sentences_{timestamp}.txt\", \"w\")\n","file_labels_test_set = open(f\"ToS/TestSetWithAugmentedData/Labels/Labels_{timestamp}.txt\", \"w\")\n","for index in test_ids:\n","    sentence = (tokenizer.decode(input_ids[index], skip_special_tokens=True)).replace(\"\\n\", \"\")\n","    file_sentences_test_set.write(f'{sentence}\\n')\n","    sentence = (f\"{labels[index]}\").replace(\"\\n\", \"\")\n","    file_labels_test_set.write(f'{sentence}\\n')\n","file_sentences_test_set.close()\n","file_labels_test_set.close()\n","\n","file_sentences_train_val_set = open(f\"ToS/TrainValSetWithAugmentedData/Sentences/Sentences_{timestamp}.txt\", \"w\")\n","file_labels_train_val_set = open(f\"ToS/TrainValSetWithAugmentedData/Labels/Labels_{timestamp}.txt\", \"w\")\n","for index in train_val_ids:\n","    sentence = (tokenizer.decode(input_ids[index], skip_special_tokens=True)).replace(\"\\n\", \"\")\n","    file_sentences_train_val_set.write(f'{sentence}\\n')\n","    sentence = (f\"{labels[index]}\").replace(\"\\n\", \"\")\n","    file_labels_train_val_set.write(f'{sentence}\\n')\n","file_sentences_train_val_set.close()\n","file_labels_train_val_set.close()\n","```\n","\n"],"metadata":{"id":"UtenL4ku9PRn"}},{"cell_type":"markdown","source":["The following code was used to split the datasets into training-val and test sets without data augmentation.\n","\n","```\n","all_sentences_and_augmented = all_sentences\n","all_labels_and_augmented = all_labels\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in all_sentences_and_augmented:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True, #is deprecated\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(all_labels_and_augmented)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', all_sentences_and_augmented[0])\n","print('Token IDs:', input_ids[0])\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","train_idx, valid_idx = train_test_split(np.arange(len(labels)), test_size=0.05, shuffle=True, stratify=labels)\n","\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n","valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n","\n","train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n","validation_dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=valid_sampler)\n","\n","### Creation of the sets training, val and set. These sets are being stored to ensure persistency\n","\n","# Let's first get the train_val and test set\n","\n","# Create a 90-10 train-validation split.\n","train_val_ids, test_ids = train_test_split(np.arange(len(labels)), test_size=0.1, shuffle=True, stratify=labels)\n","\n","timestamp = datetime.datetime.now().strftime(\"%y%m%d_%H_%M_%S_%p\")\n","file_sentences_test_set = open(f\"ToS/TestSet/Sentences/Sentences_{timestamp}.txt\", \"w\")\n","file_labels_test_set = open(f\"ToS/TestSet/Labels/Labels_{timestamp}.txt\", \"w\")\n","for index in test_ids:\n","    sentence = (tokenizer.decode(input_ids[index], skip_special_tokens=True)).replace(\"\\n\", \"\")\n","    file_sentences_test_set.write(f'{sentence}\\n')\n","    sentence = (f\"{labels[index]}\").replace(\"\\n\", \"\")\n","    file_labels_test_set.write(f'{sentence}\\n')\n","file_sentences_test_set.close()\n","file_labels_test_set.close()\n","\n","file_sentences_train_val_set = open(f\"ToS/TrainValSet/Sentences/Sentences_{timestamp}.txt\", \"w\")\n","file_labels_train_val_set = open(f\"ToS/TrainValSet/Labels/Labels_{timestamp}.txt\", \"w\")\n","for index in train_val_ids:\n","    sentence = (tokenizer.decode(input_ids[index], skip_special_tokens=True)).replace(\"\\n\", \"\")\n","    file_sentences_train_val_set.write(f'{sentence}\\n')\n","    sentence = (f\"{labels[index]}\").replace(\"\\n\", \"\")\n","    file_labels_train_val_set.write(f'{sentence}\\n')\n","file_sentences_train_val_set.close()\n","file_labels_train_val_set.close()\n","```\n"],"metadata":{"id":"T1DeMBzS22v4"}},{"cell_type":"markdown","source":["### Training classification model"],"metadata":{"id":"E4HVDjX_sSyx"}},{"cell_type":"code","source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = NUM_CLASSES, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3kCP4P3sPSM","executionInfo":{"status":"ok","timestamp":1659609697575,"user_tz":-120,"elapsed":532,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"fc4a16a1-d63b-42a4-8dc9-2ae2c2dcece1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n","      (position_embeddings): Embedding(512, 512)\n","      (token_type_embeddings): Embedding(2, 512)\n","      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=512, out_features=512, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["### Optimizer & Learning Rate Scheduler"],"metadata":{"id":"Y5KcpRZDsZWY"}},{"cell_type":"code","source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,#2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n","                  #weight_decay=0.3\n","                )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5KmzLrDfsVGS","executionInfo":{"status":"ok","timestamp":1659609697576,"user_tz":-120,"elapsed":28,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"0d1a987f-3619-47f7-decd-e8baba67f37d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = EPOCHS\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","\"\"\"\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)\n","\"\"\"\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","MIN_LR = 1e-5\n","scheduler = CosineAnnealingLR(optimizer, 600, eta_min = MIN_LR)"],"metadata":{"id":"GdsFUHWPsdOn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"S6SLYPm-sk46"}},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    \"\"\"\n","    print(f'preds.shape {preds.shape} == {preds}')\n","    print(f'labels.shape {labels.shape} == {labels}')\n","    \"\"\"\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    \"\"\"\n","    print(f'pred_flat.shape {pred_flat.shape} == {pred_flat}')\n","    print(f'labels_flat.shape {labels_flat.shape} == {labels_flat}')\n","    \"\"\"\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"PmyBdJ_xsgna"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tr_metrics = []\n","va_metrics = []\n","tmp_print_flag = True\n","\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    train_loss = 0.0\n","    train_preds = []\n","    train_targets = []\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    io_total_train_acc = 0\n","    io_total_train_prec = 0\n","    io_total_train_recall = 0\n","    io_total_train_f1 = 0\n","    io_total_valid_acc = 0\n","    io_total_valid_prec = 0\n","    io_total_valid_recall = 0\n","    io_total_valid_f1 = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 100 batches.\n","        if step % 100 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # In PyTorch, calling `model` will in turn call the model's `forward` \n","        # function and pass down the arguments. The `forward` function is \n","        # documented here: \n","        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n","        # The results are returned in a results object, documented here:\n","        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n","        # Specifically, we'll get the loss (because we provided labels) and the\n","        # \"logits\"--the model outputs prior to activation.\n","        result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","        \"\"\"\n","        if tmp_print_flag:\n","          tmp_print_flag = False\n","          print(f'result.keys() = {result.keys()}')\n","        \"\"\"\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        \"\"\"\n","        print(f'loss {loss}')\n","        print(f'logits {logits}')\n","        \"\"\"\n","        train_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        train_targets.extend(batch[2].numpy())\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","        train_acc = accuracy_score(train_targets, train_preds)\n","        train_precision = precision_score(train_targets, train_preds)\n","        train_recall = recall_score(train_targets, train_preds)\n","        train_f1 = f1_score(train_targets, train_preds)\n","\n","        io_total_train_acc += train_acc\n","        io_total_train_prec += train_precision\n","        io_total_train_recall += train_recall\n","        io_total_train_f1 += train_f1\n","\n","    io_avg_train_acc = io_total_train_acc / len(train_dataloader)\n","    io_avg_train_prec = io_total_train_prec / len(train_dataloader)\n","    io_avg_train_recall = io_total_train_recall / len(train_dataloader)\n","    io_avg_train_f1 = io_total_train_f1 / len(train_dataloader)\n","    print(\n","        f'Epoch {epoch_i+1} : \\n\\\n","        Train_acc : {io_avg_train_acc}\\n\\\n","        Train_F1 : {io_avg_train_f1}\\n\\\n","        Train_precision : {io_avg_train_prec}\\n\\\n","        Train_recall : {io_avg_train_recall}'\n","    )\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    valid_preds = []\n","    valid_targets = []\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","\n","        valid_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        valid_targets.extend(batch[2].numpy())\n","\n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","        valid_acc = accuracy_score(valid_targets, valid_preds)\n","        valid_precision = precision_score(valid_targets, valid_preds)\n","        valid_recall = recall_score(valid_targets, valid_preds)\n","        valid_f1 = f1_score(valid_targets, valid_preds)\n","\n","        io_total_valid_acc += valid_acc\n","        io_total_valid_prec += valid_precision\n","        io_total_valid_recall += valid_recall\n","        io_total_valid_f1 += valid_f1\n","\n","    io_avg_valid_acc = io_total_valid_acc / len(validation_dataloader)\n","    io_avg_valid_prec = io_total_valid_prec / len(validation_dataloader)\n","    io_avg_valid_recall = io_total_valid_recall / len(validation_dataloader)\n","    io_avg_valid_f1 = io_total_valid_f1 / len(validation_dataloader)\n","    print(\n","            f'Epoch {epoch_i+1} : \\n\\\n","            Valid_acc : {io_avg_valid_acc}\\n\\\n","            Valid_F1 : {io_avg_valid_f1}\\n\\\n","            Valid_precision : {io_avg_valid_prec}\\n\\\n","            Valid_recall : {io_avg_valid_recall}'\n","          )\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Training Accur.': io_avg_train_acc,\n","            'Training F1': io_avg_train_f1,\n","            'Training Precision': io_avg_train_prec, \n","            'Training Recall': io_avg_train_recall,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Valid. F1': io_avg_valid_f1,\n","            'Valid. Precision': io_avg_valid_prec, \n","            'Valid. Recall': io_avg_valid_recall,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPRGelpWslTd","executionInfo":{"status":"ok","timestamp":1659610137355,"user_tz":-120,"elapsed":435471,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"6a42334c-fff3-4ccb-a848-6a526827e652"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 3 ========\n","Training...\n","  Batch   100  of    311.    Elapsed: 0:00:43.\n","  Batch   200  of    311.    Elapsed: 0:01:28.\n","  Batch   300  of    311.    Elapsed: 0:02:13.\n","Epoch 1 : \n","        Train_acc : 0.839764372371384\n","        Train_F1 : 0.6028437187510137\n","        Train_precision : 0.8130829078240804\n","        Train_recall : 0.5012945074488825\n","\n","  Average training loss: 0.24\n","  Training epoch took: 0:02:18\n","\n","Running Validation...\n","Epoch 1 : \n","            Valid_acc : 0.9416478879109027\n","            Valid_F1 : 0.9016732403184603\n","            Valid_precision : 0.9172070685160991\n","            Valid_recall : 0.8870407304196881\n","  Accuracy: 0.95\n","  Validation Loss: 0.13\n","  Validation took: 0:00:02\n","\n","======== Epoch 2 / 3 ========\n","Training...\n","  Batch   100  of    311.    Elapsed: 0:00:44.\n","  Batch   200  of    311.    Elapsed: 0:01:28.\n","  Batch   300  of    311.    Elapsed: 0:02:13.\n","Epoch 2 : \n","        Train_acc : 0.9602152976562105\n","        Train_F1 : 0.92548299942023\n","        Train_precision : 0.9475592864892302\n","        Train_recall : 0.9044719714276019\n","\n","  Average training loss: 0.11\n","  Training epoch took: 0:02:18\n","\n","Running Validation...\n","Epoch 2 : \n","            Valid_acc : 0.9661892488444113\n","            Valid_F1 : 0.9349749385618921\n","            Valid_precision : 0.954534655516979\n","            Valid_recall : 0.9163236868731166\n","  Accuracy: 0.96\n","  Validation Loss: 0.12\n","  Validation took: 0:00:02\n","\n","======== Epoch 3 / 3 ========\n","Training...\n","  Batch   100  of    311.    Elapsed: 0:00:43.\n","  Batch   200  of    311.    Elapsed: 0:01:28.\n","  Batch   300  of    311.    Elapsed: 0:02:13.\n","Epoch 3 : \n","        Train_acc : 0.9715903093526018\n","        Train_F1 : 0.946950808485512\n","        Train_precision : 0.9622382360003219\n","        Train_recall : 0.9321769165429991\n","\n","  Average training loss: 0.08\n","  Training epoch took: 0:02:18\n","\n","Running Validation...\n","Epoch 3 : \n","            Valid_acc : 0.9699731174993931\n","            Valid_F1 : 0.9436648422370657\n","            Valid_precision : 0.9645339886032074\n","            Valid_recall : 0.9238451347688725\n","  Accuracy: 0.97\n","  Validation Loss: 0.10\n","  Validation took: 0:00:02\n","\n","Training complete!\n","Total training took 0:07:02 (h:mm:ss)\n"]}]},{"cell_type":"markdown","source":["### Analysis"],"metadata":{"id":"NA0t5b15s3vO"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"XBglihEPstu8","executionInfo":{"status":"ok","timestamp":1659610137357,"user_tz":-120,"elapsed":68,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"d24671d0-c8f4-4991-ff34-bd765ea70ab4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Training Loss  Training Accur.  Training F1  Training Precision  \\\n","epoch                                                                    \n","1               0.24             0.84         0.60                0.81   \n","2               0.11             0.96         0.93                0.95   \n","3               0.08             0.97         0.95                0.96   \n","\n","       Training Recall  Valid. Loss  Valid. Accur.  Valid. F1  \\\n","epoch                                                           \n","1                 0.50         0.13           0.95       0.90   \n","2                 0.90         0.12           0.96       0.93   \n","3                 0.93         0.10           0.97       0.94   \n","\n","       Valid. Precision  Valid. Recall Training Time Validation Time  \n","epoch                                                                 \n","1                  0.92           0.89       0:02:18         0:00:02  \n","2                  0.95           0.92       0:02:18         0:00:02  \n","3                  0.96           0.92       0:02:18         0:00:02  "],"text/html":["\n","  <div id=\"df-bba38889-d19a-40c0-8ea8-54298d960d9e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Training Accur.</th>\n","      <th>Training F1</th>\n","      <th>Training Precision</th>\n","      <th>Training Recall</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Valid. F1</th>\n","      <th>Valid. Precision</th>\n","      <th>Valid. Recall</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.24</td>\n","      <td>0.84</td>\n","      <td>0.60</td>\n","      <td>0.81</td>\n","      <td>0.50</td>\n","      <td>0.13</td>\n","      <td>0.95</td>\n","      <td>0.90</td>\n","      <td>0.92</td>\n","      <td>0.89</td>\n","      <td>0:02:18</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.11</td>\n","      <td>0.96</td>\n","      <td>0.93</td>\n","      <td>0.95</td>\n","      <td>0.90</td>\n","      <td>0.12</td>\n","      <td>0.96</td>\n","      <td>0.93</td>\n","      <td>0.95</td>\n","      <td>0.92</td>\n","      <td>0:02:18</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.08</td>\n","      <td>0.97</td>\n","      <td>0.95</td>\n","      <td>0.96</td>\n","      <td>0.93</td>\n","      <td>0.10</td>\n","      <td>0.97</td>\n","      <td>0.94</td>\n","      <td>0.96</td>\n","      <td>0.92</td>\n","      <td>0:02:18</td>\n","      <td>0:00:02</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bba38889-d19a-40c0-8ea8-54298d960d9e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bba38889-d19a-40c0-8ea8-54298d960d9e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bba38889-d19a-40c0-8ea8-54298d960d9e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["##### Loss per epoch - Training VS Validation"],"metadata":{"id":"sJWJtfsDu_pN"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"QLA624BNs1d1","executionInfo":{"status":"ok","timestamp":1659610137358,"user_tz":-120,"elapsed":43,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"d7c479cf-0d52-49c6-cce8-2592f2c37be8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["##### Accuracy per epoch - Training VS Validation"],"metadata":{"id":"D699Sjgzua9G"}},{"cell_type":"code","source":["# Plot the learning curve.\n","plt.plot(df_stats['Training Accur.'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Accur.'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"BXL5MGCUuYPn","executionInfo":{"status":"ok","timestamp":1659610137359,"user_tz":-120,"elapsed":41,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"a0371a53-58de-4b15-9c4a-1d276088f728"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["##### F1 per epoch - Training VS Validation"],"metadata":{"id":"-ecPHGEQugLT"}},{"cell_type":"code","source":["# Plot the learning curve.\n","plt.plot(df_stats['Training F1'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. F1'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation F1\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"F1\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"prhTJjVJuljb","executionInfo":{"status":"ok","timestamp":1659610137360,"user_tz":-120,"elapsed":39,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"0b6c774b-8a7e-486b-db64-ea609191a791"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAvUAAAGaCAYAAACPCLyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVxU9f4/8NfMMAs7somIKykoAqKldqEscUHFrVA0b2qWpaWV3W7qt7q3LOv+XJKuC123XNJcENx31LqWN1PLFTdcEQVkZ2D28/tjZGAcUFCGYXk9Hw8fwpnzOedzRkZe85n3+XxEgiAIICIiIiKiekts6w4QEREREdGTYagnIiIiIqrnGOqJiIiIiOo5hnoiIiIionqOoZ6IiIiIqJ5jqCciIiIiqucY6omIqiAtLQ0BAQFYsGDBYx9j+vTpCAgIqMFeNVyVPd8BAQGYPn16lY6xYMECBAQEIC0trcb7l5iYiICAAPz22281fmwiosdhZ+sOEBE9juqE4+TkZPj5+VmxN/VPcXExvvvuO+zatQuZmZlwd3dH165d8fbbb8Pf379Kx3j33Xexd+9ebNmyBR06dKhwH0EQEBkZiYKCAhw5cgQKhaImL8OqfvvtNxw7dgxjx46Fi4uLrbtjIS0tDZGRkZU+/s0332DgwIEAgF9++QV79+7FuXPncOnSJWg0GqxevRrdu3evre4SkZUx1BNRvTR79myz70+cOIENGzYgNjYWXbt2NXvM3d39ic/XvHlznD59GhKJ5LGP8cUXX+Dzzz9/4r7UhE8++QQ7d+5EdHQ0unXrhqysLBw8eBCnTp2qcqiPiYnB3r17sXnzZnzyyScV7vO///0Pt2/fRmxsbI0E+tOnT0Msrp0PmY8dO4aFCxdi2LBhFqF+yJAhGDhwIKRSaa305WHCw8MxZMgQi+2dO3c2fb19+3bs2LED7dq1g7+/P1JSUmqzi0RUCxjqiaheejDE6PV6bNiwAZ07d64w4JRXVFQEJyenap1PJBJBLpdXu5/l1YUACAAlJSXYs2cPIiIiMG/ePNP2yZMnQ6PRVPk4ERERaNasGbZv346PPvoIMpnMYp/ExEQAxjcANeFJ/w1qikQieaI3eDWpdevWj/yZnzp1KmbOnAmZTIbly5cz1BM1QKypJ6IGrVevXnj11Vdx/vx5vP766+jatSsGDx4MwBju58+fj+HDh6N79+7o1KkT+vTpg7lz56KkpMTsOBXVeJffdujQIbz88ssIDg5GREQE/t//+3/Q6XRmx6iopr50W2FhIf75z3/i2WefRXBwMEaOHIlTp05ZXE9ubi5mzJiB7t27IywsDGPGjMH58+fx6quvolevXlV6TkQiEUQiUYVvMioK5pURi8UYNmwY8vLycPDgQYvHi4qKsG/fPrRv3x4hISHVer4rU1FNvcFgwH/+8x/06tULwcHBiI6OxrZt2ypsn5qais8++wwDBw5EWFgYQkND8dJLL2HTpk1m+02fPh0LFy4EAERGRiIgIMDs37+ymvqcnBx8/vnn6NmzJzp16oSePXvi888/R25urtl+pe2PHj2K5cuXo3fv3ujUqRP69euHpKSkKj0X1dG0adNq/dsSUf3DkXoiavDS09MxduxYREVFoW/fviguLgYAZGRkICEhAX379kV0dDTs7Oxw7NgxLFu2DCkpKVi+fHmVjv/TTz9h3bp1GDlyJF5++WUkJydjxYoVcHV1xcSJE6t0jNdffx3u7u545513kJeXh++//x5vvvkmkpOTTZ8qaDQavPbaa0hJScFLL72E4OBgXLx4Ea+99hpcXV2r/HwoFAoMHToUmzdvxo4dOxAdHV3ltg966aWXEB8fj8TERERFRZk9tnPnTqhUKrz88ssAau75ftDXX3+N1atX45lnnsG4ceOQnZ2NmTNnokWLFhb7Hjt2DMePH8cLL7wAPz8/06cWn3zyCXJycvDWW28BAGJjY1FUVIT9+/djxowZaNKkCYCH38tRWFiIUaNG4caNG3j55ZfRsWNHpKSk4Mcff8T//vc/bNq0yeITovnz50OlUiE2NhYymQw//vgjpk+fjpYtW1qUkVVGrVYjJyfHbJtUKoWzs3OV2hNRw8BQT0QNXlpaGr788ksMHz7cbHuLFi1w+PBhsxHr0aNHIy4uDvHx8Th9+jRCQkIeefwrV65gx44dpptxR40ahUGDBuGHH36ocqjv2LEjPvvsM9P3/v7+eP/997Fjxw6MHDkSALBp0yakpKTg/fffx6RJk0z7tm/fHjNnzkTz5s2rdK6ioiJkZWVBKpVi2rRpEIvFGDBgQJXaPqhFixbo3r07jhw5gszMTHh7e5seS0xMhFQqNX0yUlPPd3lXr17FmjVr0KNHD6xYscJUEtO3b1/Tm4nyhgwZglGjRpltGzduHMaOHYslS5Zg/PjxkEqlCAsLQ0BAAPbv34/evXtX6UbrZcuW4fr16/jHP/6B0aNHm7Z36NABM2fOxLJly/D++++btdFoNEhISDCNokdFRSEyMhJr166tcqhPSEhAQkKC2bbQ0FBs3LixSu2JqGFg+Q0RNXhubm546aWXLLbLZDJTwNTpdMjPz0dOTg7+8pe/AECF5S8ViYyMNAt9IpEI3bt3R1ZWFpRKZZWOMW7cOLPve/ToAQC4ceOGaduhQ4cgkUgwZswYs32HDx9e5VFZg8GA9957DxcuXMDu3bvx/PPP48MPP8T27dvN9vv0008RFBRUpRr7mJgY6PV6bNmyxbQtNTUVf/75J3r16mW6Ubmmnu/ykpOTIQgCXnvtNbMa96CgIISHh1vs7+DgYPparVYjNzcXeXl5CA8PR1FREa5evVrtPpTav38/3N3dERsba7Y9NjYW7u7uOHDggEWbV155xawspmnTpmjTpg2uX79e5fNGRkbi+++/N/tT2Y3LRNRwcaSeiBq8Fi1aVHpT49q1a7F+/XpcuXIFBoPB7LH8/PwqH/9Bbm5uAIC8vDw4OjpW+xil5R55eXmmbWlpafD29rY4nkwmg5+fHwoKCh55nuTkZBw5cgRz5syBn58fvv32W0yePBkfffQRdDodhg0bBgC4ePEigoODq1SH3bdvX7i4uCAxMRFvvvkmAGDz5s0AYDFaXhPPd3m3bt0CALRt29biMX9/fxw5csRsm1KpxMKFC7F7927cuXPHok1VnsPKpKWloVOnTrCzM//Vamdnh9atW+P8+fMWbSr72bl9+3aVz+vj42N6Y0REjRdDPRE1ePb29hVu//777/Gvf/0LERERGDNmDLy9vSGVSpGRkYHp06dDEIQqHf9hs6A86TGq2r6qSm/sfOaZZwAY3xAsXLgQkyZNwowZM6DT6RAYGIhTp05h1qxZVTqmXC5HdHQ01q1bh5MnTyI0NBTbtm2Dj48PnnvuOdN+NfV8P4m//e1vOHz4MEaMGIFnnnkGbm5ukEgk+Omnn7By5UqLNxrWVlvTcxJRw8dQT0SN1tatW9G8eXMsXbrULFz9/PPPNuxV5Zo3b46jR49CqVSajdZrtVqkpaVVaYGk0uu8ffs2mjVrBsAY7BcvXoyJEyfi008/RfPmzdG+fXsMHTq0yn2LiYnBunXrkJiYiPz8fGRlZWHixIlmz6s1nu/Ske6rV6+iZcuWZo+lpqaafV9QUIDDhw9jyJAhmDlzptljv/76q8WxRSJRtfty7do16HQ6s9F6nU6H69evVzgqT0RUUzhEQESNllgshkgkMhsh1ul0WLp0qQ17VblevXpBr9dj9erVZts3btyIwsLCKh2jZ8+eAIyzrpSvl5fL5fjmm2/g4uKCtLQ09OvXz6KM5GGCgoLQoUMH7Nq1C2vXroVIJLKYm94az3evXr0gEonw/fffQ6/Xm7afO3fOIqiXvpF48BOBzMxMiyktgbL6+6qWBfXu3Rs5OTkWx9q4cSNycnLQu3fvKh2HiOhxcKSeiBqtqKgozJs3DxMmTECfPn1QVFSEHTt2VCvM1qbhw4dj/fr1iIuLw82bN01TWu7ZswetWrWymBe/IuHh4YiJiUFCQgIGDhyIIUOGwMfHB7du3cLWrVsBGAP6okWL4O/vj/79+1e5fzExMfjiiy/w3//+F926dbMYmbbG8+3v74/Ro0fjhx9+wNixY9G3b19kZ2dj7dq1CAwMNKtjd3JyQnh4OLZt2waFQoHg4GDcvn0bGzZsgJ+fn9n9C4BxBhkAmDt3LgYNGgS5XI527dqhffv2FfbljTfewJ49ezBz5kycP38eHTp0QEpKChISEtCmTRu88cYbj32dT+rChQumtQROnjwJwPjJyYkTJwAAr776KqfAJKrn6uZvLiKiWvD6669DEAQkJCRg1qxZ8PLyQv/+/fHyyy8/9hSP1iSTybBq1SrMnj0bycnJ2L17N0JCQrBy5Up8/PHHUKlUVTrOrFmz0K1bN6xfvx7Lly+HVqtF8+bNERUVhfHjx0MmkyE2NhZ///vf4ezsjIiIiCodd9CgQZg9ezbUanWF00la6/n++OOP4enpiY0bN2L27Nlo3bo1/vGPf+DGjRsWN6fOmTMH8+bNw8GDB5GUlITWrVtj6tSpsLOzw4wZM8z27dq1Kz788EOsX78en376KXQ6HSZPnlxpqHd2dsaPP/6If//73zh48CASExPh4eGBkSNHYsqUKdVexbgmnT9/Ht9++63ZttKbmQFg8ODBDPVE9ZxIqI07k4iIyGr0ej169OiBkJCQx17AiYiI6jfW1BMR1SMVjcavX78eBQUFFc7LTkREjQPLb4iI6pFPPvkEGo0GYWFhkMlk+OOPP7Bjxw60atUKI0aMsHX3iIjIRlh+Q0RUj2zZsgVr167F9evXUVxcDA8PD/Ts2RPvvfcePD09bd09IiKyEYZ6IiIiIqJ6jjX1RERERET1HEM9EREREVE9xxtlqyk3VwmDoWYrljw8nJCdXVSjxyQiI76+iKyHry8i6xCLRWjSxLFabRjqq8lgEGo81Jcel4isg68vIuvh64uobmD5DRERERFRPcdQT0RERERUzzHUExERERHVczYN9RqNBnPmzEFERARCQkIwYsQIHD16tEptt2zZgkGDBiE4OBgRERH48ssvoVQqzfZJS0tDQEBAhX9+/vlna1wSEREREVGts+mNstOnT8e+ffswZswYtGrVCklJSZgwYQLWrFmDsLCwStutWrUKX331FcLDwzFy5EhkZGRg9erVuHz5MlauXAmRSGS2/+DBgxEREWG2LTAw0CrXRERERERU22wW6k+fPo2dO3dixowZGDduHABg6NChiI6Oxty5c7F27doK22k0GixYsAA9evTA8uXLTQE+LCwMEydORHJyMnr37m3WJigoCEOGDLHq9RAREVHjVlKiRFFRPvR6ra27QnWYRCKFk5Mr7O2rN2Xlo9gs1O/ZswdSqRTDhw83bZPL5YiJicH8+fORmZkJb29vi3aXL19GYWEhBgwYYDYi/+KLL8LBwQG7du2yCPUAUFxcDDs7O8hkMutcEBERETVaWq0GhYW5cHPzhFQqt6gaIAIAQRCg1aqRl3cPdnZSSKU1l0ttVlOfkpKCNm3awNHR/F1KSEgIBEFASkpKhe00Gg0A4xuABykUCpw7d85i+7fffouwsDCEhIQgNjYWv//+ew1cAREREZFRYWEenJxcIZMpGOipUiKRCDKZAo6OrigqyqvRY9ss1GdlZVU4Eu/l5QUAyMzMrLBdq1atIBKJcPLkSbPtV69eRU5Ojlk7sViMiIgITJs2DfHx8Zg2bRpu376N1157DcePH6/BqyEiIqLGTKfTQC63t3U3qJ5QKOyh1Wpq9Jg2K79RqVSQSqUW20tH4NVqdYXt3N3d0b9/f2zevBlt27ZFZGQkMjIy8MUXX0AqlZq18/X1xfLly83aDxgwAAMHDsTcuXOxfv36avfbw8Op2m2qwsvL2SrHJSK+vohq2uETt7B6dwru5ZbAs4k9xvTvgBe6trB1t2wqM1OATCblKD1ViUQiBSDU6O8nm4V6hUIBrdbyRpLSUF5ReU2pmTNnQqVS4euvv8bXX38NwDjDTcuWLR85JWbTpk0xcOBAbNy4ESUlJbC3r9676uzsohpfEtvLyxlZWYU1ekwiMuLri6hmHT13F6t2X4BGZwAAZOWWYMHGP1FQqMKzQT427p3tGAwG6PUCgJrNCNRwGQyGSn8/icWiag8k2yzUe3l5VVhik5WVBQAVluaUcnZ2Rnx8PNLT03H79m34+vqiefPmGDlyJFq1avXIczdr1gwGgwEFBQXVDvVEREQNnSAIKFHrUViiQaFSi4JiDQqKNShUarD7t5umQF9KozMg8afURh3qiWzNZqE+MDAQa9asgVKpNLtZ9tSpU6bHH8XX1xe+vr4AgIKCApw9e9Y0PebD3Lp1CxKJBK6uro/XeSIionpGq9OjsPh+QFdqUWgK6uVDu/HrwmINdPrKR5wl7umwa3EJIpkKgkYB3a32yM7xrcWroYZk8uQ3AQALFy6p1bYNjc1CfVRUFFasWIFNmzaZgrhGo0FiYiK6dOmCpk2bAgDS09NRUlICf3//hx5v3rx5EIvFiI2NNW3LycmBu7u72X43btzAzp078fTTT0OhUNTsRREREdUSg0FAUYnWNIJeUFwWyCsK7SqNvsLjSO3EcHGQwcVRClcnGVp4O8HZUWrc5iCDs4MUzg4yuDgav/5w3UZofM5CJDGO1ovkKkjbnIWjvU3XsyQriIh4ukr7bdq0Dc2a8U2drdnsFRgaGoqoqCjMnTsXWVlZaNmyJZKSkpCenm6qkweAadOm4dixY7h48aJpW3x8PFJTUxEaGgqJRILk5GQcOXIEM2fORIsWZTfqzJkzB7du3UKPHj3g7e2Nmzdvmm6OnTZtWu1dLBER0SOYSl7uh/GKgrnxey0KlBooS7QVVG8LEEsEODmK4egggZOjCM2aiNFWYQeFwg5yuQgymQCZTAQ7qQCJnQGCSA+doRgagxZagxZavRYlBh0KSr/P10GTW/aYrnkWRA+cWSQxQNbicm09VVRLPv10ptn3Gzf+iIyMO5gy5QOz7W5uTZ7oPPPnL7JJ24bGpm+rZ8+ejbi4OGzduhX5+fkICAjAkiVL0LVr14e2CwgIQHJyMpKTkwEYV4xdunQpnn/+ebP9wsPDsX79evzwww8oLCyEi4sLwsPDMXnyZLRr185q10VERCQIAoo1auQWlSBXWYy84mLkF6tQWFKCQrUKhSo1itVqKDVqlGjVUOs0MEAPiA2AyPi3SGz8204qwM5OgMTNALGnAIXYAIVYD4j1MMD4RydooReMo/FaAHn3/5ho7v+phFgkhlRsB6lYCqlYCplEavpaKpHC3k4BqViKu8UVTzmtNPCG9IamX78BZt8fPpyM/Pw8i+0PUqlU1aqGqGg2xNpo29CIBEHgbdrVwNlviOoXvr4IMAZsnaCHVn9/xNmgM408lx+h1hq00Bh00Jke05k9ptZrUKLVQKXRQKUz/tHojcczhmod9NBDgB6CSI/Hnd1QBBHs7gdsmeSBgC22g1QihUxsHrplYinsxHbG7RJpWUAvv6/ErtxxSo9r3CYRS6rUt09++Qq5astFc5rI3fBl+P893gU3AHfv3oCPz6Mn66jPZsz4Gy5fvoSEhO2mbZMnv4mioiJ89NH/YcGC+bh48QJGjx6D119/C//972Fs25aES5cuoqAgH15e3hgwYBBeffU1SCQSs2MAZXXxJ08ex7vvTsSsWbNx7dpVbNmyGQUF+QgODsXf//5/8PNrUSNtAWDz5o1Yv34tsrPvwd/fH5MnT8XSpfFmx7SWh/3M1KvZb4iIqHESBAEGwVBBmNZCq78fokuDd4WhWwud2WO6B45hfNy8nQ7C4041KAAQJIBBDEEvgSCIAYMYMEgg3P8bghRSkb1xRFsihcJOBoVUBns7GRxkcjjJFXBSyOGssIeLQgEHudwUsmXlgnlpaJeIJHV2vvPB/lFYd2EztIayaamlYikG+0fZsFcN09Fzd5H4UyqyC9TwcJHjpZ7+dXKGoby8XHz00VT07RuFqKiBaNrU2Mddu3bA3t4BsbGj4eBgjxMnjmPZsu+gVCrxzjvvPfK4q1Yth1gswSuvjEFhYQF+/HENPv/8EyxduqpG2iYlJWD+/Nno3LkLYmNH4c6dO5gx40M4OzvDy6vyWRjrKoZ6IqJGTm/Qm0K0poKR7PJh2fIx3QOP3Q/d98N5WbDWmR3nsQM2UDZaXcEotIOdPSRSZ1PoNujF0OtF0GvF0GoBrUYEjQZQqwWoVEBxiQEG/YMBXQzBIIaDVA5nhQIuDnK4OMqNN406SeHiWHYDqfHmURkcFHYQ19EQXtO6+XQBAGxL3YM8dR7c5G4Y7B9l2k4148H1ALIL1Fi1+wIA1Llgf+9eFqZP/xTR0UPMtn/22ZeQy8vKcIYOjcGcOV8hKWkTJkyYBJlM9tDj6nQ6rFixCnZ2xrjq4uKKb7+di6tXr6Bt26eeqK1Wq8WyZfEICgpGXNxi035PPdUOs2Z9xlBPRFRXHLt7sl6GDoNggOb+SLNlmNaaSj20lYTlB0e5S8tJHjxG+eMbBMOjO1YJU4lIuZBdGrrlEjmcZE4PjETb3S8TqXiU2qJ0RCyFRCSBRg2UqABliR5FxVoUFBtvIi0sLLuhNPv+TaTqSmZ5kdmJTSHc3UEKZ0/Z/RlepHB+IKg72UthJxE/9vPS0HXz6YJuPl1Y3lYFv5y5gyOn71S7XWp6vsW0ohqdAd/vSsHPf6ZX+3gRIc0QHtys2u2qQqFQICpqoMX28oG+uFgJjUaL0NAwbN2aiBs3rqNdu/YPPe7AgYNNYRsAQkM7AwDS028/MtQ/qu2FC+eRn5+Pt98eZrZfnz5R+Pe/v3nosesqhnoianCO3T1pVh6Qq87DugubAaBawd4gGMrKOMqNUhtDsWW9dXVGsy1LRoz7l97o+DjsRJJyobqs9loqlkIukcFJ5mBWgy01BXKpWTvZ/XZ25b62vHnSDnZiO4hF1Q++giCgWK1DgVJjnDe9wDiri2kO9WLl/SkajduKSixXHwcAsUhUbupFKbyauJYFcwdjeC8/NaNcVrWacaK6oLJ1Ah62foCteHl5mwXjUlevpmLp0nicPPk7lEql2WNKZdEjj1taxlPK2dkFAFBY+Og3ko9qe/eu8Y3WgzX2dnZ2aNbMOm9+rI2hnogaFL1Bjy1XdpnV+wKA1qDF+ouJuJBz2SJUVzSarTXooDPoHrsfEpHEIliXD8gOdg6VBGu7R4fuB0ayS/d9nIBdU9RavcVc6YX3p14snYaxfFDXVzLhgKPCzjSa3tzT0XwEvRGXvFD9FR78eCPkf1/8C7IL1BbbPVzkmDa6bn3qWH5EvlRhYSGmTHkTDg5OeP31iWje3A8ymQyXLl1AfPwCGAyP/oRQXMnN21WZ4+VJ2tZXDPVEVK8IgoBiXQnulWTjXkkOsktycE9l/PpeSQ5y1XmVlpOo9Rpcyk21mElEIVOUC8yWYdkyWNuZjlHRaLZUbFflmUTqKp3eYFzY6P5ouimYF2vKRtjLfa3WVvwJg1wqMQVxdxcFWvo4s+SFqApe6ulvVlMPGEvIXur58MU464o//jiB/Px8zJo1B507l70JuXOn+qVD1uDjY3yjlZZ2C6GhYabtOp0Od+7cgb//w8t76iKGeiKqc3QGHXJUeRaBPbskG/dUOSjRqcz2d5Y5wVPhgbaureBpH4af045CqSu2OG5jnnJPEAQoVboKR9DLr0haGtqVqoo/pZCIRWaj5t4Plrw4lqtTZ8kL0WMrvRm2Psx+UxGx2PgGvfzIuFarRVLSJlt1yUxgYEe4urpi27Yk9Os3wFQ+tH//HhQWFti4d4+HoZ6Iap0gCFBqiy0De0kO7qlykKvKM5sdxU5sB0+FOzzt3dHWrQ087d3vf+8Bd0UTKOzkZsf3dvBqFFPuqTX6CoJ52Sh6+XKYomqUvAS2amIWzI2PGUfTHeR2dXaqRaKG5tkgn3oT4h8UHBwCZ2cXzJr1GWJiYiESibB37y7UleoXqVSK8ePfxPz5c/D++2/jxRcjcefOHezevR3Nm/vVy//nGOqJyCq0Bh1yVLkWgf1eSTayS3Kg0pvXirrInOFp7w5/1zbw9HGHl70HPOyNQd5F5lytevH6OuXegyUvDwZzs9H0Yg002orLjMqXvHi4KNDax9kU2suXvbg4SOHIkhcisgJXVzfMnj0fCxfGYenSeDg7u6Bv3/54+ulu+OCDybbuHgDg5ZdjIQgC1q9fi0WLvoW/fzv861/fIC5uLmQy+aMPUMdwRdlq4oqyREaCIKBIqzTVtt+7XyqTff/rPHW+2Wi7VGwHD3sP04i7p70HPO3d4XH/e5nk4fMVPy5bvr4MgoDi+yUvFdWhPxjUq1Ty4ljBCHq5r50dZJBLWfJCtYO/v8o0hhVlGwODwYDo6D7o2fNFTJv2iVXPxRVliajWaPVaZKtyjcFdlWMK7KXfa/Qas/1dZS7wtHdH+yb+xlF2RVl4d5E51+rHmaUrMeYUqOFeg7Woao3+/rSLGhQqy2Z6KZ0rvaDc10UllZe8ONlLTYHcz9sJLuVCu7O9lCUvRERWplarIZebj8jv2bMTBQX5CAvraqNePT6GeqJGTBAEFGiKkG2qbS9X464yjraXJxNL4Xm/LCbA/Sl4Kjzuj7q7w13hDplEaqMrMVedlRh1ekO52V3KgvqDob10ZL3SkheZxBTMPV0VaOvrbJwnvYKSFycHKSRilrwQEdnS6dN/Ij5+AV54oRdcXFxx6dIF7Ny5DW3b+uPFF3vbunvVxlBP1MBp9Fpkq3IqnAIyuyQHmnI3k4oggqvcONoe2KSdsTymXKmMs9SpXowYJ/6UajYNHGBciXH1nos4eTHLbHrGh5W8lC9v8XF3YMkLEVED4uvbHJ6eXkhI2ICCgny4uLgiKmogJk6cDKm0bgxSVQdDPVE9ZxxtLyw30p59/4ZU4w2q+Rrzele5RAZPew9423uig3t7U2D3VLjDXdEE0joy2v4kKlqwBTAukHQnpxjO9lKLkpfydeouDlLYs+SFiKhBa97cD7Nnz7d1N2oMQz1RPaDRa0wlMWZlMipjcNeWW/lUBBHc5K7wtHdHR3MInvwAACAASURBVI9AU2D3uB/enaSODT6survIkVPJSoxfvtHdBj0iIiKyLoZ6ojrAIBgeGG0vrWs3fl3wwGi7QiKHp70HfBy8EOQRYFbb3kTRBFJx435pt23mbBHq69NKjERERNXVuH/zE9UilU5tGmnPLlciUzoCr3tgtN1d4QYPew908uhgCuylN6k62jk0+NH2x3X2WjZOXLwH/+YuyCtU1/jsN0RERHURQz1RDTEIBuSrC8xKY0oXWrpXkoNCbZHZ/vZ2Cnjae8DXsSlCPDuaFlryVHjAXeEGiZg3XlbXvfwSLNl2Hr5ejvgwNgxymYTzaBMRUaPAUE9UDSU61f3ZY8wD+z1VNnJKcqET9KZ9xSIx3OVu8LT3QIhXUNmCS/cXW3KQOtjwShoerc6A+C1noTcYMHlYMOQyvikiIqLGg6GeqByDYECuKr/cvO1lCy1ll+SgSKs029/RzgEe9u7wc/JFZ6/g+zekGsN7E7krR9tr0Y8HLuHanUK8MywYTd35homIiBoXhnpqdEp0JRUG9nsl2chR5UH/wGi7h6IJPO090MI72GyFVA+FOxyk9ja8Eir1y5k7OPxnOvp3b4muAV627g4REVGtY6inBkdv0CNXnV9WHvPAwktKXbHZ/k5SR3jYu6Olsx+6eIeabkr1UHjATe7C0fY67mZGIVbvvYjAlm54qWdbW3eHiIgqsWvXdnz11efYtGkbmjXzBQDExAxCWFhXfPzxZ9Vu+6ROnjyOd9+diH//+zt06fJ0jRzTlhjqqV4q1hab3YxqWim1JBs56jwYhLLVRCUiCTwUTeBh745WLi1M87aXziRjb6ew4ZXQk1CqtFiUdAaOCju8NaQTJGKxrbtERNRgfPTRVJw8+Tu2b98Pe/uKP5n+4IPJOHfuDLZt2we5XF7LPayaAwf2IicnGyNGvGLrrlgVQz3VSXqDHjmqPNxTmQf20mkgS3QlZvs7SR3hae+B1q4t8bSis2mhJU97d7jJXSEWMew1NAZBwLLt55FToMa0V7rA1VFm6y4RETUoffr0w6+//hdHjvyEPn2iLB7Pzc3BiRO/o2/f/o8d6Net2wyxlQdkkpP34fLlSxahvnPnLkhO/gVSaf1fSR1gqCcbEQQBSl1xWVg3zSJjnMM9R5UHAYJpfzuRBB72xptQ27i0Mp+3XdEECo62Nzo7j97AqdRsvNK7HZ7yc7V1d4iIGpznnnsB9vYOOHBgb4Wh/uDBA9Dr9ejb1/KxqpLJbDcgIxaL6+ynC4+DoZ6sRmfQIUeVWy6wl5sCsiQHKr3KbH9nmRM8FR5o69oa3XzcjaPt96d/dJW7cLSdTM5dy8GWn6+ie8emiOzqZ+vuEBE1SAqFAs891xOHDh1AQUEBXFxczB4/cGAvPDw80KJFK8yd+y+cOHEMGRkZUCgU6NLlabzzznuPrH+vqKb+6tVUxMXNwdmzZ+Dq6oohQ16Cp6flJAj//e9hbNuWhEuXLqKgIB9eXt4YMGAQXn31NUgkxvvhJk9+E3/+eRIAEBFhrJv38WmGhITtldbUJyfvww8/rMSNG9fh4OCI8PDnMGnSu3BzczPtM3nymygqKsI//jET33wzGykp5+Ds7ILhw0di9Oix1XuiawhDPT02QRBQpFVWsEKqceQ9T51vNtouFdvB435I93drY1HbLpewfIIeLadAhf9sOwdfT0eMiwrkyrpE1GAdu3sS21L3IFedhyZyNwz2j0I3ny612oc+faKwb99uHD6cjMGDh5m23717B2fPnkZMzEikpJzD2bOn0bt3P3h5eePOnXRs2bIZU6a8hR9+2ASFouqfpmdn38O7706EwWDAX/86FgqFPbZtS6pwRH3Xrh2wt3dAbOxoODjY48SJ41i27DsolUq88857AICxY8ejpKQEGRl3MGXKBwAAe/vKpz0uvSE3KCgYkya9i8zMDGzevAEpKeewdOlqs34UFOTjb397Fy++GInIyL44dOgA4uMXoG3bp/Dss+FVvuaawlBPD6U1jbZnmwJ7+Rll1HqN2f6uMmd42HugXZO2ZoHd094dLjJnjrbTE9HqDFiUdBY6vQHvvMQFpoio4Tp29yTWXdgMrUELAMhV52Hdhc0AUKvB/plnusPNrQkOHNhrFuoPHNgLQRDQp08/+Ps/hRdf7G3WLjz8eUyc+BoOH05GVNTAKp9v7dpVyM/Pw7JlaxAQEAgA6N8/GqNGDbPY97PPvoRcXvaGYejQGMyZ8xWSkjZhwoRJkMlkeOaZHkhM3IT8/Dz06zfgoefW6XSIj1+Ap55qjwUL/mMqDQoICMRnn32M7duTEBMz0rR/ZmYG/vnPL02lSdHRQxATE42dO7cy1FPtKxttz66wTMZytF1qqmdv7+ZvCuylte0yjraTFa1PvoxrdwrwzrBO8OECU0RUD/x25wSO3vm92u2u5d+ETtCZbdMatFibkoBf049V+3jPNnsG3Zt1rXY7Ozs79OrVG1u2bMa9e/fg6ekJADhwYB/8/FqgY8dOZvvrdDoolUXw82sBJydnXLp0oVqh/ujRXxAcHGoK9ADQpEkT9OnTH0lJm8z2LR/oi4uV0Gi0CA0Nw9atibhx4zratWtfrWu9cOE8cnNzTG8ISvXq1QeLFn2LX3/9xSzUOzk5oXfvfqbvpVIpOnQIQnr67Wqdt6bYNNRrNBp8++232Lp1KwoKChAYGIipU6fi2WeffWTbLVu2YPny5bh+/TpcXV0RFRWFqVOnwtHR0Ww/g8GA5cuX48cff0RWVhZat26NSZMmYcCAh79ba0i0ei2yS0fbTQstlc0mo3lgtN1N7goPhTvaN/E3BfbSedtdZE4sdyCb+PXsHRz64zaiurdE1wBvW3eHiMiqHgz0j9puTX36RCExcRMOHtyHESNewfXr13DlyiW89toEAIBarcKaNSuxa9d2ZGVlQhDKBgOLioqqda6MjLsIDg612N6yZSuLbVevpmLp0nicPPk7lErzFd+VyuqdFzCWFFV0LrFYDD+/FsjIuGO23du7qUUmcnZ2QWrqlWqfuybYNNRPnz4d+/btw5gxY9CqVSskJSVhwoQJWLNmDcLCwiptt2rVKnz11VcIDw/HyJEjkZGRgdWrV+Py5ctYuXKl2RM8f/58LFmyBLGxsejUqROSk5MxdepUiMViREU9/t3adYkgCCjQFCFblW1W036vJAfZKuNoe3kyicxUGhPo3s442q4oG22XShrG1E7UcNzKLMLqPRcR0MINL3OBKSKqR7o36/pYI+Sf/PIVctV5FtubyN3wfpeJNdG1KgsODkWzZs2xf/8ejBjxCvbv3wMAprKT+fPnYNeu7Rg+fBQ6dQqGk5MTABE+++z/zAJ+TSosLMSUKW/CwcEJr78+Ec2b+0Emk+HSpQuIj18Ag8Hw6IM8IXEli1Na65ofxWah/vTp09i5cydmzJiBcePGAQCGDh2K6OhozJ07F2vXrq2wnUajwYIFC9CjRw8sX77cFODDwsIwceJEJCcno3dvY11XRkYGvv/+e4wZMwYff/wxAGD48OH461//itmzZ6Nv375Wnxv1YUpvgMlT58HtETfAaPSastH20nnbVWXhvbTmDgBEEMFN7gpPe3cEureDp8LDbApIJ6kjR9up3ihWabEo8QzsFXaYOCSIC0wRUaMw2D/KrKYeMJbADva3zYBk7959sWbN90hLu4Xk5H0ICOhgGtEurZufMmWqaX+1Wl3tUXoAaNrUB2lptyy237x5w+z7P/44gfz8fMyaNQedO5dlpzt30is4atUyj49PM9O5yh9TEASkpd1Cmzb+VTqOrdgs1O/ZswdSqRTDhw83bZPL5YiJicH8+fORmZkJb2/Lj9gvX76MwsJCDBgwwCyYvvjii3BwcMCuXbtMof7AgQPQarV45ZWyxQZEIhFGjRqFv/3tbzh9+jQ6d+5sxausXMU3wCQgQ5kFbwdPs4WWskuyka8pNGsvl8jgae8BbwcvdHQPMJbH3C+TcVc0gVTM2yWo/jMIApbtSEF2gQofvRIGV6eGM58wEdHDlA7y2Xr2m1J9+/bHmjXfY+HC+UhLu2UW4Csasd68eQP0en21z/Pss+HYtGk9Ll68YKqrz83Nxf79u832Kx2ULT8qrtVqLeruAcDe3r5KbzACAzuiSRN3bNmSgP79o02LUh06lIysrEyMHj2m2tdTm2yW/FJSUtCmTRuLGviQkBAIgoCUlJQKQ71GY6z/rmhqI4VCgXPnzpmdw8nJCW3atLE4BwCcP3/eZqF+W+oes3ffgHGmmT03kgEYR9ubKNzgqXBHkEeg2QqpngoPOEodONpODd7u/93An1fuYVRkO7Tzc3t0AyKiBqSbTxebhfgHtWnTFk891R5HjvwMsViMyMiyG0T/8pcI7N27C46OTmjdug3OnTuD48ePwdW1+gsDvvLKWOzduwsffPAOYmJGQi5XYNu2JDRt2gxFRZdN+wUHh8DZ2QWzZn2GmJhYiEQi7N27CxVVvgQEBGLfvt1YsOAbBAZ2hL29AyIinrfYz87ODpMmTcFXX32OKVPeQu/efZGZmYGEhA1o29YfgwZZzsBTl9gs1GdlZaFp06YW2728jIsLZGZmVtiuVatWEIlEOHnyJIYOHWrafvXqVeTk5EClKlvQKCsry3SXdnXOURsqqpMr9c8eH8Fd4QY7jrZTI3b+eg4Sf76Kbh280ftpLjBFRGRrfftG4cqVSwgL62qWr95770OIxWLs378barUGwcGhiItbhA8+mFLtc3h6euLf//4P5s+fjTVrVpotPvWvf31h2s/V1Q2zZ8/HwoVxWLo0Hs7OLujbtz+efrobPvhgstkxhwx5GZcuXcCuXTuwYcM6+Pg0qzDUA8CAAYMgk8mwdu0qLFr0LRwdHdGnTxQmTpxS51efFQk2qubv3bs3nnrqKXz33Xdm22/duoXevXvj008/xV//+tcK206dOhX79u3D3//+d0RGRiIjIwNffPEFUlNTYTAYcP78eQDA2LFjkZOTg+3bt5u1NxgM6NChA8aPH49p06ZZ5wIf4e3tH+NecY7Fdk8HdyweNMsGPSKqO+7lleD9+Yfh4ijHvPeeh72cb3CJqG47d+48fH0tZ2ghqkx6+g0EBXWssePZ7DelQqGAVqu12K5WqwFUXF5TaubMmVCpVPj666/x9ddfAwAGDx6Mli1b4ujRo2bnKC3Xqe45KpOdXQSD4cnfBw1s3bfCG2AGtu6LrKzCh7Qkath0egP+39qTUGn0+GhURxQVlKD6t1qV8fJy5muKyEr4+ipjMBig01l/xhVqOAwGQ6WvH7FYBA8Pp2odz2ah3svLq8Lyl6ysLACosJ6+lLOzM+Lj45Geno7bt2/D19cXzZs3x8iRI9GqVdm7ZC8vLxw/fvyxzmFt5W+AqcrsN0SNxfrky0hNL8DbQzuhmYfjoxsQERGR7UJ9YGAg1qxZA6VSaXaz7KlTp0yPP4qvry98fX0BAAUFBTh79qxpekwA6NChAzZt2oRr166Z3Sxbeo4OHTrUxKU8ttIbYDjSQWR09NxdHDx5G/26tcDTgVxgioiIqKpsNuFzVFQUtFotNm0qm3pIo9EgMTERXbp0Md1Em56ejtTU1Eceb968eRCLxYiNjTVti4yMhFQqxbp160zbBEHA+vXr4evri9BQyxXLiMg20jKLsGr3BbRv4YaYF+r2XMBERER1jc1G6kNDQxEVFYW5c+ciKysLLVu2RFJSEtLT00118gAwbdo0HDt2DBcvXjRti4+PR2pqKkJDQyGRSJCcnIwjR45g5syZaNGihWk/Hx8fjBkzBitWrIBarUZwcDAOHDiA48ePY/78+TZdeIqIyhSrdFiYdAb2ci4wRURE9DhsOqXE7NmzERcXh61btyI/Px8BAQFYsmQJunZ9+HLKAQEBSE5ORnKycU73oKAgLF26FM8/bzk90YcffghXV1ds2LABiYmJaNOmDebNm4cBAwZY5ZqIqHoEQcDynedxL8+4wJQbF5giIiKqNptNaVlf1dTsN+Wxpp4as13/u4GEw6kY2esp9O3WssaPz9cXkfXw9VXm7t0b8PHhlJZUdQ/7mXmc2W/4GTcR2UzK9Rxs/ikVzwR6o88zLR7dgIioDuM4KVWVNX5WGOqJyCZyC9X4bts5+Lg7YFz/QIhEIlt3iYjosUkkdtBqLdfGIaqIVquBRFKzVfAM9URU63R6AxZvOQONzoB3hgVzxVgiqvecnNyQl5cFjUbNEXuqlCAI0GjUyMvLgpOTW40em79JiajWbTh4Bam3CzBpaCf4enKBKSKq/+ztjf+X5effg16vs3FvqC6TSOzg7NzE9DNTUxjqiahW/e/8XSSfSEPfZ1rgGS4wRUQNiL29Y40HNaKqYvkNEdWatKwirNx9Ae38XLnAFBERUQ1iqCeiWlGi1mFR0lkoZHaYNLQT7CT874eIiKim8LcqEVmdIAhYsTMFWbklmDQkiAtMERER1TCGeiKyuj3HbuLEpSzEvOCPgJZNbN0dIiKiBoehnois6sKNXCQcTsXTAV7o140LTBEREVkDQz0RWU1uoRrfbT2Lpk0c8NqADlxgioiIyEoY6onIKnR6A+K3nIVaa8A7L3GBKSIiImtiqCciq9h46Aqu3M7HawMC0ZwLTBEREVkVQz0R1bjfzmfgwPE09H7aD906NLV1d4iIiBo8hnoiqlG37ymxcvcFPOXnihEvPmXr7hARETUKDPVEVGNK1DosSjwDuUyCSUO4wBQREVFt4W9cIqoRgiBgxa4UZN5fYKqJMxeYIiIiqi0M9URUI/Yeu4UTF7Pw8gttucAUERFRLWOoJ6IndvGmcYGpru29ENWtpa27Q0RE1Ogw1BPRE8ktVCN+6zl4NbHH+IFcYIqIiMgWGOqJ6LHp9AbEbz0LlUaHycM6cYEpIiIiG2GoJ6LHlnA4FVfS8jGufyCaeznZujtERESNFkM9ET2WYykZ2Pf7LUR29UOPjj627g4REVGjxlBPRNWWfk+J73ddgH9zF8T24gJTREREtsZQT0TVUqLWYVHSGcilYrw9NJgLTBEREdUB/G1MRFUmCAK+330Bd3OK8daQTlxgioiIqI5gqCeiKtv/+y0cv5CJmJ7+6NCKC0wRERHVFQz1RFQll27lYeOhVIS180RUdy4wRUREVJcw1BPRI+UVqRG/5Sy83BR4fWBHLjBFRERUxzDUE9FD6fQGfLflLErUOrwzLBgOCi4wRUREVNfY9LezRqPBt99+i61bt6KgoACBgYGYOnUqnn322Ue2/fXXXxEfH49Lly7BYDCgbdu2GDt2LAYMGGC2X0BAQIXtP/vsM4waNapGroOoIUs4nIpLafmYMKgj/Ly5wBQREVFdZNNQP336dOzbtw9jxoxBq1atkJSUhAkTJmDNmjUICwurtN2hQ4cwadIkhIWFYcqUKQCAnTt3YurUqVAqlRg+fLjZ/hERERg8eLDZttDQ0Jq/IKIG5viFTOz7/RZ6dWmOZ4O4wBQREVFdZbNQf/r0aezcuRMzZszAuHHjAABDhw5FdHQ05s6di7Vr11badu3atfDy8sKqVasgk8kAACNGjEBkZCS2bt1qEerbtm2LIUOGWO1aiBqiO9lKLN+VAn9fF4yMbGfr7hAREdFD2Kymfs+ePZBKpWYBXC6XIyYmBidOnEBmZmalbYuKiuDq6moK9AAgk8ng6uoKubziebNVKhXUanXNXQBRA6bS6LAw8QxkdmJMGtqJC0wRERHVcTb7TZ2SkoI2bdrA0dHRbHtISAgEQUBKSkqlbbt164bLly8jLi4ON2/exM2bNxEXF4fr169j/PjxFvsnJCSgc+fOCAkJwaBBg7B///4avx6ihkIQBKy8v8DUxMFBcHdR2LpLRERE9Ag2K7/JyspC06ZNLbZ7eXkBwENH6idOnIibN2/iu+++Q3x8PADAwcEBixcvRnh4uNm+YWFhGDBgAPz8/HDnzh2sXr0akydPxrx58xAdHV2DV0TUMBw4noZjKZl4uWdbdGjtbuvuEBERURXYLNSrVCpIpVKL7aXlMw8rlZHJZGjdujWioqLQp08f6PV6bNy4Ee+//z5WrlyJkJAQ077r1683azts2DBER0djzpw5GDhwYLXn2/bwsM7sH15ezlY5LlF1nL+WjY2HrqB7kA/GDurUYOaj5+uLyHr4+iKqG2wW6hUKBbRarcX20jBfWW08AHzxxRc4c+YMEhISIBYbK4j69++P6OhofPXVVxZBvjwHBweMHDkS8+bNw9WrV+Hv71+tfmdnF8FgEKrV5lG8vJyRlVVYo8ckqq78IjW+Wvk7PFwVeLVPe9y7V2TrLtUIvr6IrIevLyLrEItF1R5ItllNvZeXV4UlNllZWQAAb2/vCttpNBokJCTghRdeMAV6AJBKpXjuuedw5swZ6HS6h567WbNmAID8/PzH7T5Rg6I3GPDd1nMoUXGBKSIiovrIZqE+MDAQ165dg1KpNNt+6tQp0+MVycvLg06ng16vt3hMp9NBp9NBEB4+kn7r1i0AgLs764WJAGDz4au4eCsPY6IC0IILTBEREdU7Ngv1UVFR0Gq12LRpk2mbRqNBYmIiunTpYrqJNj09HampqaZ9PDw84OLigv3795uV7yiVShw6dAjt27c31ern5ORYnDc3Nxfr1q2Dn58fWrdubaWrI6o/TlzMxJ5jN/FiWHP8pVMzW3eHiIiIHoPNPmMPDQ1FVFQU5s6di6ysLLRs2RJJSUlIT0/H119/bdpv2rRpOHbsGC5evAgAkEgkGD9+POLi4hAbG4vBgwfDYDAgISEBd+/exbRp00xt165di+TkZLzwwgvw9fVFRkYGNmzYgJycHCxatKjWr5morrmTrcTynSlo04wLTBEREdVnNi2cnT17NuLi4rB161bk5+cjICAAS5YsQdeuXR/abtKkSfDz88Pq1auxaNEiaDQaBAQEYOHChejTp49pv7CwMJw8eRKbNm1Cfn4+HBwc0LlzZ7z11luPPAdRQ6fW6LE46SzsJGK8M6wTpHZcYIqIiKi+EgmPKkAnM5z9hhoCQRCwZPt5HEvJwAexnRHUgOej5+uLyHr4+iKyjno1+w0R2U7yiTT8dj4Dw55r26ADPRERUWPBUE/UyFxJy8eGg1fQ+SlPDHi2la27Q0RERDWAoZ6oEclXarB4yxl4uCjwRnQHiBvIirFERESNHUM9USOhNxjwn61noVTp8PawTnBQSG3dJSIiIqohDPVEjUTiT1dx4WYexvQLQMumzrbuDhEREdUghnqiRuDExSzs/u0mXujsi/BgLjBFRETU0DDUEzVwd3OKsXznebRp5oxRvdvbujtERERkBQz1RA2YWqPHoqQzsJOI8fbQYC4wRURE1EDxNzxRAyUIAlbtvYD0LCXeHNwRHq4KW3eJiIiIrIShnqiBOnjyNv53LgNDn2uDTm08bN0dIiIisiKGeqIGKPV2PtYnX0aovwcG/qW1rbtDREREVsZQT9TAFCg1WLzlLNxd5HhjUEcuMEVERNQIMNQTNSB6gwH/2XYORSVavDMsGI5cYIqIiKhRYKgnakCSfr6GlBu5eLUvF5giIiJqTBjqiRqIPy5lYdf/buD5UF9EhHCBKSIiosaEoZ6oAcjIKcaynefRyscZo/u0s3V3iIiIqJYx1BPVc2qtcYEpsUiEd4Z1gtROYusuERERUS1jqCeqxwRBwOo9F3E7S4m3BgfB09Xe1l0iIiIiG2CoJ6rHDv9xG0fP3cWQiDbo1JYLTBERETVWDPVE9VRqej7WHbiMEH8PRIe3tnV3iIiIyIYY6onqoYJiDRYnnUUTZzneiOYCU0RERI0dQz1RPWMwCFiy7RwKi40LTDnZc4EpIiKixo6hnqieSfrvVZy/notX+7ZHKx8uMEVEREQM9UT1yh+Xs7Dz6A08H9oMz4X62ro7REREVEcw1BPVExm5xVi2IwWtmjpjdJ/2tu4OERER1SEM9UT1gFqrx6LEsxCLgLe5wBQRERE9gKGeqI4TBAFr9l7E7awiTBgUBC83LjBFRERE5hjqieq4n/5Mx69n72JQeGuE+HOBKSIiIrLEUE9Uh127U4B1By6hU1t3DI5oY+vuEBERUR1l01Cv0WgwZ84cREREICQkBCNGjMDRo0er1PbXX3/Fq6++iu7du+OZZ55BbGwsdu3aVeG+mzZtQv/+/REcHIx+/fph7dq1NXkZRFZRWKzBoqQzcHWU481BQVxgioiIiCpl01A/ffp0rFq1CoMHD8bHH38MsViMCRMm4I8//nhou0OHDmH8+PHQ6XSYMmUK3nvvPYjFYkydOhWbNm0y23f9+vX45JNP0L59e3z66acIDQ3FzJkzsWLFCmteGtETKV1gqkCpxTsvdeICU0RERPRQIkEQBFuc+PTp0xg+fDhmzJiBcePGAQDUajWio6Ph7e390NH0N954AxcvXkRycjJkMhkA46h/ZGQkWrVqhR9++AEAoFKp0LNnT3Tt2hWLFy82tf/www9x8OBB/PTTT3B2rt7iPdnZRTAYavYp8/JyRlZWYY0ek+q3xJ+vYsev1zGufyCe53z0T4SvLyLr4euLyDrEYhE8PJyq18ZKfXmkPXv2QCqVYvjw4aZtcrkcMTExOHHiBDIzMyttW1RUBFdXV1OgBwCZTAZXV1fI5XLTtt9++w15eXl45ZVXzNqPHj0aSqUSP//8cw1eEVHN+PPKPez49ToiQpox0BMREVGV2CzUp6SkoE2bNnB0dDTbHhISAkEQkJKSUmnbbt264fLly4iLi8PNmzdx8+ZNxMXF4fr16xg/frxpv/PnzwMAOnXqZNY+KCgIYrHY9DhRXZGZV4Jl28+jZVMn/JULTBEREVEV2dnqxFlZWWjatKnFdi8vLwB46Ej9xIkTcfPmTXz33XeIj48HADg4OGDx4sUIDw83O4dMJoObm5tZ+9JtDzsHUW3TaPVYnHgGAPD2sGDIpFxgKc6nAgAAIABJREFUioiIiKrGZqFepVJBKrW8+a+0fEatVlfaViaToXXr1oiKikKfPn2g1+uxceNGvP/++1i5ciVCQkIeeo7S8zzsHJWpbn1TVXl5Va+2nxoWQRDw7YY/cDOzCP94vTuC2nnbuksNCl9fRNbD1xdR3WCzUK9QKKDVai22lwbt8rXxD/riiy9w5swZJCQkQCw2VhD1798f0dHR+Oqrr7B+/XrTOTQaTYXHUKvVDz1HZXijLFnDT3/eRvLvtzDoL63R2suRPw81iK8vIuvh64vIOurVjbJeXl4Vlr9kZWUBALy9Kx6p1Gg0SEhIwAsvvGAK9AAglUrx3HPP4cyZM9DpdKZzaLVa5OXlWRwjLy+v0nMQ1aZrdwqwdv8lBLVxxxAuMEVERESPwWahPjAwENeuXYNSqTTbfurUKdPjFcnLy4NOp4Ner7d4TKfTQafToXSWzg4dOgAAzp49a7bf2bNnYTAYTI8T2UpRiRaLk87C1VGGtwYHQSzmAlNERERUfTYL9VFRUdBqtWaLRWk0GiQmJqJLly6mm2jT09ORmppq2sfDwwMuLi7Yv3+/WfmOUqnEoUOH0L59e1MdfY8ePeDm5oZ169aZnfvHH3+Eg4MDnn/+eWteItFDlS4wla9U4+1hwVxgioiIiB6bzWrqQ0NDERUVhblz5yIrKwstW7ZEUlIS0tPT8fXXX5v2mzZtGo4dO4aLFy8CACQSCcaPH4+4uDjExsZi8ODBMBgMSEhIwN27dzFt2jRTW4VCgXfffRczZ87Ee++9h4iICBw/fhzbtm3Dhx9+CBcXl1q/bqJS2365hrPXcjAmKgBtmvFnkYiIiB6fzUI9AMyePRtxcXHYunUr8vPzERAQgCVLlqBr164PbTdp0iT4+flh9erVWLRoETQaDQICArBw4UL06dPHbN/Ro0dDKpVixYoVSE5ORrNmzfDxxx9jzJgx1rw0ooc6nXoP2365jvBgH/TkAlNERET0hERCaQE6VQlnv6EnlZVXgpkrf4eHiwL/92pXzkdvZXx9EVkPX19E1lGvZr8haow0Wj0WJZ2BIABvv8QFpoiIiKhmMNQT1aIf9l/CzYwivDGoI7zd7G3dHSIiImogGOqJasnPp9Jx5PQdRP+lFTo/5Wnr7hAREVEDwlBPVAuu3y3AD/suIah1EwyNaGvr7hAREVEDw1BPZGWlC0y5OErxJheYIiIiIitgqCeyIoMgYOn288grUuPtocFwdpDZuktERETUADHUE1nR9l+u48zVbIzq3R5tfbnAFBEREVlHjYf6+Ph4dOzYsaYPS1TvnLmajW1HruEvnXzwQmcuMEVERETWY5WReq5nRY3dvbwSLNl2Ds29nPBqvwCIRKyjJyIiIuuxq8pO6enpVT5gQUHBY3eGqCH4/+3de1xVdb7/8TcoNxW8bkxF8VKCAipYFmmOqYyM4q3RMa9pjV3UZrKxMes3jzOnM+fRHKPSY2peumGWkyYiMhmplaVNTtqICGgiqYjCFuV+2Vv3/v3RuE8EKiS42JvX8z++6/vd67N8tPLN9rvWx3r5ilZuS5XNLi14IFReNJgCAAANrFahfvjw4XzTCNTSxk+O69T5Yv3u1/3k37aF0eUAAIAmoFahvnnz5urWrZsiIyNvODc1NVUpKSk3XRjgjL44nKO9h89pTGSgBtxBgykAAHBr1CrU9+rVSz4+PvrTn/50w7mrV68m1KNJOnW+WBuSj6tPYFtNvI8GUwAA4Nap1YOyffv2VUZGhmw2W0PXAzil0gqrVsYfkW8LDz02ngZTAADg1qpVqB86dKjCwsKUl5d3w7l33XWX5s+ff9OFAc7iaoOpS8WVmjcxVH40mAIAALeYm533T9ZJfn6JbLb6/SMzmXxlNhfX62fi1tm+L0vbvsjSjF/21vCIAKPLwU9wfwENh/sLaBju7m5q375V3dbUZlJKSooKCgp+VlGAK0s9ma+EL7IUGdJR94d3MbocAADQRNUq1E+ZMkVffPGF4+fS0lL94Q9/0IkTJxqsMKCxu1BYrjXbj6qLqaVmRQfz2lcAAGCYWoX6n+7QsVgsSkpKktlsbpCigMbOevmKVsWnyma3a/7EMBpMAQAAQ9Uq1AOo6r1d3+n788X67Zi+6tiOBlMAAMBYhHqgjr5MOafP/5Wj0fcEKry3yehyAAAACPVAXZzOLdaG5GM/NJga2sPocgAAACTVsqOsJH3++ee6cOGCJKm8vFxubm7auXOnMjIyqs11c3PT7Nmz661IoDG42mCqlY+HHhsXombu/E4MAAAah1q9pz44OLhuH+rmpvT09J9dVGPGe+qbJpvdrhVbUpSadVGLp0fo9i6tjS4JtcT9BTQc7i+gYfyc99TX6pv6uLi4n1UQ4CqSvjqlw5n5mh7Vm0APAAAanVqF+kGDBjV0HUCjdTTrorbtPal7+nbU8AgaTAEAgMaHTcHAdeQXVmjN9qPqbGqph2gwBQAAGilCPXAN1ss2rdp2RFdsth8aTHnSYAoAADROhHrgGt7f/Z2yzhXr4dF9dRsNpgAAQCNW61daNgSLxaLly5crISFBRUVFCg4O1sKFCxUZGXnddcOHD9fZs2drPBYYGKjk5GTHz0FBQTXO+/Of/6ypU6f+/OLh0vYdOafPvj2rX93dTQODaDAFAAAaN0ND/bPPPqvk5GTNmjVLgYGBio+P19y5c7VhwwaFh4dfc91zzz2n0tLSKmM5OTlatmyZBg8eXG3+kCFDNG7cuCpj/fv3r5+LgMs5nVusuI+PKbhbGz3wi55GlwMAAHBDhoX6lJQUJSUlacmSJY5GVRMmTFBMTIxiY2O1cePGa64dOXJktbFVq1ZJksaOHVvtWM+ePTV+/Pj6KRwurazCqlXxqWrp3VyPjQ+lwRQAAHAKhiWWnTt3ysPDQ5MnT3aMeXl5adKkSTp48KDy8vLq9Hk7duxQQECAIiIiajxeUVGhysrKm6oZrs1mt2v9jnTlF1Vo3oQwtW7paXRJAAAAtWJYqE9PT1ePHj3UsmXLKuP9+vWT3W6vU0fatLQ0ZWZmKiYmpsbjW7Zs0YABA9SvXz+NHTtWn3zyyU3VDtf00T9O6V8nLug3w2/X7QE0mAIAAM7DsO03ZrNZHTt2rDZuMv3wUGJdvqlPTEyUpGr75iUpPDxco0ePVkBAgM6dO6e4uDgtWLBAL7/88jV/CUDTk/b9RW3de1J39+2okQMDjC4HAACgTgwL9RUVFfLw8Kg27uXlJUm13ipjs9mUlJSkvn37qlevXtWOb9q0qcrPEydOVExMjF566SWNGTOmzs2E2rdvVaf5tWUy+TbI5+LGzJfKtTYxTQH+vvrDjDvl42Xo8+NoANxfQMPh/gIaB8PSi7e3t6xWa7Xxq2H+ari/kQMHDig3N9fxsO2NtGjRQg8++KBefvllnTx5ssZfBK4nP79ENpu9TmtuxGTyldlcXK+fidqxXrbpf947JIv1ih4f11clReUqMboo1CvuL6DhcH8BDcPd3a3OXyQbtqfeZDLVuMXGbDZLkvz9/Wv1OYmJiXJ3d9eYMWNqfe5OnTpJkgoLC2u9Bq5p057vdDKnSA+P7qNO7VveeAEAAEAjZFioDw4OVlZWVrX3zR8+fNhx/EYsFouSk5M1aNCgGvfnX8uZM2ckSe3atatDxXA1X6We16eHzip6UDfdGVy7XyIBAAAaI8NCfXR0tKxWqzZv3uwYs1gs2rp1qyIiIhwhPScnR5mZmTV+xueff66ioqIa300vSRcvXqw2dunSJb333nsKCAhQ9+7db/5C4JTO5JXonZ0ZCuraRr8eRoMpAADg3AzbU9+/f39FR0crNjZWZrNZ3bp1U3x8vHJycvTiiy865i1evFgHDhzQsWPHqn1GYmKiPD09NWrUqBrPsXHjRu3evVvDhg1T586dlZubq7/97W+6ePGiVq5c2WDXhsatrMKqlfFH5OPdXI+PD6HBFAAAcHqGvuZj6dKlWrZsmRISElRYWKigoCCtXbtWAwcOvOHakpISffbZZxo2bJh8fWt+8j48PFyHDh3S5s2bVVhYqBYtWmjAgAF67LHHanUOuB6b3a43ktKVX1ihP04LV+tWtXsgGwAAoDFzs9vt9fsqFxfH22+c29//cUpbPsvUgyPu0C/v6mp0ObgFuL+AhsP9BTQMp3r7DXCrpX9/UR9+nqlBffwVdScNpgAAgOsg1KNJuFhUode3H9Vt7Vpo9q+C69x0DAAAoDEj1MPlXb5i0+ptqbJctmnBA2Hy9qRjLAAAcC2Eeri8v+0+ocycIj1CgykAAOCiCPVwaV8dPa/dh7L1y7u60mAKAAC4LEI9XFa2+YcGU70DWmvSsF5GlwMAANBgCPVwSWUVl7Vy6xH5eDbX4xNC1bwZ/6kDAADXRdKBy7Hb7Xrz7+kyF1ToiQmhakODKQAA4OII9XA5O78+rUPHzfrN/b3Uu2sbo8sBAABocIR6uJSMU5e05fNM3Rnsryg6xgIAgCaCUA+Xcam4Uq8npOq2di00hwZTAACgCSHUwyVcbTBVabVp/sQw+XjRYAoAADQdhHq4hA/2nNCJs4WaMzpYnTvQYAoAADQthHo4vX+kndeug9mKurOrBvXpaHQ5AAAAtxyhHk7trLlEb3+UoTsCWmvy/TSYAgAATROhHk6rvPKyXotPlbdncz1BgykAANCEkYLglOx2u95MSpf5UrmeGB9CgykAANCkEerhlD4+cEYHj5s1aVgvBXVra3Q5AAAAhiLUw+kcO31JWz7L1J1BJo0aRIMpAAAAQj2cyqXiSq1OOCr/tj6aM7oPDaYAAABEqIcTuXzFptUJqaqwXNb8iaE0mAIAAPg3Qj2cxuZPM3Uiu1BzftVHXUytjC4HAACg0SDUwykcSM/VJ9+c0ciBAbq7Lw2mAAAAfoxQj0bv7IVSvfX3DN3epbV+M/x2o8sBAABodAj1aNTKKy9rVfwReXm402AKAADgGkhIaLTsdrve+nu6ci+W6/HxoWrrS4MpAACAmhDq0Wgl//OMvjlm1q+H9VRwIA2mAAAAroVQj0bp2OlL2vxppgb2Nil6UDejywEAAGjUCPVodApKKvV6wlGZ2vro4TE0mAIAALgRQ7v3WCwWLV++XAkJCSoqKlJwcLAWLlyoyMjI664bPny4zp49W+OxwMBAJScnVxnbvHmz3nzzTWVnZ6tz586aNWuWpk+fXm/Xgfpz+YpNr29LVbnlsv7w4AAaTAEAANSCoYnp2WefVXJysmbNmqXAwEDFx8dr7ty52rBhg8LDw6+57rnnnlNpaWmVsZycHC1btkyDBw+uMr5p0yb9x3/8h6KjozVnzhx98803euGFF1RZWamHH364Qa4LP9+WzzJ1PLtQj47tqwAaTAEAANSKYaE+JSVFSUlJWrJkiWbPni1JmjBhgmJiYhQbG6uNGzdec+3IkSOrja1atUqSNHbsWMdYRUWFXn31VY0YMULLly+XJP3mN7+RzWbTa6+9psmTJ8vX17cerwo3458ZeUr+5xmNiAjQPSG3GV0OAACA0zBsT/3OnTvl4eGhyZMnO8a8vLw0adIkHTx4UHl5eXX6vB07diggIEARERGOsa+//loFBQWaNm1albnTp09XaWmp9u7de3MXgXqTc6FUb/49Xb26+GnKCBpMAQAA1IVhoT49PV09evRQy5Ytq4z369dPdrtd6enptf6stLQ0ZWZmKiYmptq4JIWGhlYZDwkJkbu7u+M4jFVhuayV8Ufk2dxdT4ynwRQAAEBdGZaezGaz/P39q42bTCZJqtM39YmJiZKkcePGVTuHp6en2rRpU2X86lhd/zUA9e+HBlMZOn+xTI+PC1E7P2+jSwIAAHA6hu2pr6iokIeHR7VxL68fuoZWVlbW6nNsNpuSkpLUt29f9erVq1bnuHqe2p7jx9q3b5iHN02mprm3P2Fvpv6ZkaeHxvTV0LsCjS4HLqqp3l/ArcD9BTQOhoV6b29vWa3WauNXg/bVcH8jBw4cUG5uruNh25+ew2Kx1LiusrKy1uf4sfz8Etls9jqvux6TyVdmc3G9fqYzOH6mQG8lHlX4HR00NLRjk/wzQMNrqvcXcCtwfwENw93drc5fJBu2/cZkMtW4/cVsNktSjVtzapKYmCh3d3eNGTOmxnNYrVYVFBRUGbdYLCooKKj1OVD/CksqtTohVR1ae+uRMX1pMAUAAHATDAv1wcHBysrKqva++cOHDzuO34jFYlFycrIGDRqkjh07Vjvep08fSVJqamqV8dTUVNlsNsdx3FpXbDatTjiq8orLmj8xTC28aTAFAABwMwwL9dHR0bJardq8ebNjzGKxaOvWrYqIiHCE9JycHGVmZtb4GZ9//rmKioqqvJv+x+655x61adNG7733XpXx999/Xy1atNDQoUPr6WpQFx9+dlLHzxTooV8FK8CfBlMAAAA3y7CvSPv376/o6GjFxsbKbDarW7duio+PV05Ojl588UXHvMWLF+vAgQM6duxYtc9ITEyUp6enRo0aVeM5vL299bvf/U4vvPCCfv/732vIkCH65ptvtH37di1atEh+fn4Ndn2o2TcZedp54LTuj+iiSBpMAQAA1AtD9z0sXbpUy5YtU0JCggoLCxUUFKS1a9dq4MCBN1xbUlKizz77TMOGDbtuV9jp06fLw8NDb775pnbv3q1OnTrp+eef16xZs+rzUlAL5/J/aDDVs7OfHhx+h9HlAAAAuAw3u91ev69ycXG8/ebnqbBc1l/iDqqo1KI/z7mL99HjlmkK9xdgFO4voGE41dtv0HTY7Xa9/VGGzuWX6vHxNJgCAACob4R6NLhdB7N1ID1PDwztqb7d2xldDgAAgMsh1KNBfZddoA/2nNCA2zvoV/fQMRYAAKAhEOrRYApLLVq9LVXt/bz125g+cqfBFAAAQIMg1KNBXLHZtCYhVWUVlzX/gTC18PYwuiQAAACXRahHg9j6+UllnC7QrOggdaXBFAAAQIMi1KPeHTxm1kdfn9b94V10b2gno8sBAABweYR61KvzF8v0RlKaenTy04MjaDAFAABwKxDqUW8qLVe0Mv6Imjdz17wJofJozn9eAAAAtwKpC/XCbrfrnZ0ZyjGX6rFxIWrfmgZTAAAAtwqhHvViz6Gz+kdariYM7amQHjSYAgAAuJUI9bhpJ84WatPu7zTg9g4aE0mDKQAAgFuNUI+bUvTvBlPt/LxoMAUAAGAQQj1+tis2m15PSFVJuVXzJ9JgCgAAwCiEevxsW/f+u8HUqCB16+hrdDkAAABNFqEeP8uh42Z99I/TGjagswaH0WAKAADASIR61FnuvxtMdb/NV1NH9ja6HAAAgCaPUI86udpgyt3NTfMm0mAKAACgMSCRodbsdrviPs7QWXOpHhsfog6tfYwuCQAAACLUow4+/fasvjqaq/H39VBoj/ZGlwMAAIB/I9SjVjLPFur9Xd+pX6/2irm3u9HlAAAA4EcI9bihojKLVm1LVVtfL80d25cGUwAAAI0MoR7XZbPZtSbhqKPBVEsaTAEAADQ6hHpcV/wXJ5V+6pJm/LK3Am+jwRQAAEBjRKjHNX37nVlJX53S0P6ddV+/zkaXAwAAgGsg1KNGuZfKtH5HugJv89X0qDuMLgcAAADXQahHNZXWK1q5NVXubtL8iaHyaN7M6JIAAABwHYR6VGG327Xh42M6ay7Ro+NoMAUAAOAMCPWo4rN/5Wh/6nmNG9JDYT1pMAUAAOAMmht5covFouXLlyshIUFFRUUKDg7WwoULFRkZWav1iYmJeuedd3TixAl5enqqd+/e+uMf/6h+/fpJkrKzszVixIga165bt05Dhw6tt2txBSdzivT+ruMK69leYwd3N7ocAAAA1JKhof7ZZ59VcnKyZs2apcDAQMXHx2vu3LnasGGDwsPDr7v21Vdf1fr16zVu3DhNmTJFZWVlysjIkNlsrjZ33LhxGjJkSJWx4ODger0WZ1dcZtGqbUfUphUNpgAAAJyNYaE+JSVFSUlJWrJkiWbPni1JmjBhgmJiYhQbG6uNGzdec+2hQ4e0Zs0arVixQlFRUTc8V0hIiMaPH19fpbscm82uNduPqqjUqudnDlQrHxpMAQAAOBPD9tTv3LlTHh4emjx5smPMy8tLkyZN0sGDB5WXl3fNtXFxcQoLC1NUVJRsNptKS0tveL6ysjJZLJZ6qd3VbPvypNK+p8EUAACAszIs1Kenp6tHjx5q2bJllfF+/frJbrcrPT39mmu/+uorhYWF6ZVXXtHAgQMVERGh4cOHa/v27TXOX758ucLDw9WvXz9NmTJF//znP+v1WpzZv767oB37T+m+fp00tD8NpgAAAJyRYdtvzGazOnbsWG3cZDJJ0jW/qS8sLFRBQYGSkpLUrFkzLVq0SG3atNHGjRv1zDPPyMfHx7Elx93dXUOGDFFUVJT8/f116tQpvfHGG5ozZ47efvtt3XnnnQ13gU4gr6Bc63akKbCjr2b8srfR5QAAAOBnMizUV1RUyMOj+t5tLy8vSVJlZWWN68rKyiRJBQUF+uCDD9S/f39JUlRUlKKiorRy5UpHqO/cubPeeOONKutHjx6tMWPGKDY2Vps2bapz3e3bt6rzmtowmW7ttpdK6xX9Je6gmrm76f89crdua9/yxosAJ3Wr7y+gKeH+AhoHw0K9t7e3rFZrtfGrYf5quP+pq+MBAQGOQC9Jnp6eGjVqlOLi4lRaWlptW89VHTt21JgxY/TBBx+ovLxcPj51a66Un18im81epzU3YjL5ymwurtfPvB673a43/56urJxC/X5yfzWz2W7p+YFb6VbfX0BTwv0FNAx3d7c6f5Fs2J56k8lU4xabq6+k9Pf3r3FdmzZt5OnpqQ4dOlQ71qFDB9ntdpWUlFz33J06dZLNZlNRUdHPqNz5fX44R/uOnNfYwd3VrxcNpgAAAJydYaE+ODhYWVlZ1d5cc/jwYcfxmri7u6tPnz7Kzc2tduz8+fNq1qyZWrdufd1znzlzplbzXFHWuSK998lxhfZop3GDexhdDgAAAOqBYaE+OjpaVqtVmzdvdoxZLBZt3bpVERERjodoc3JylJmZWW3tuXPntG/fPsdYSUmJPvroI4WHh8vb21uSdPHixWrnPXXqlJKSknTnnXc65jUVxWUWrYo/otYtvfTouBC5u9NgCgAAwBUYtqe+f//+io6OVmxsrMxms7p166b4+Hjl5OToxRdfdMxbvHixDhw4oGPHjjnGpk6dqs2bN+vJJ5/U7Nmz5efnpw8//FDFxcV6+umnHfNeeuklnTlzRvfcc4/8/f11+vRpx8OxixcvvnUX2wjYbHatTUxTYalFS2bQYAoAAMCVGBbqJWnp0qVatmyZEhISVFhYqKCgIK1du1YDBw687jofHx/FxcVp6dKlevfdd1VRUaGQkBC99dZbVdYOHjxYmzZt0rvvvqvi4mL5+flp8ODBWrBgge64446GvrxGJeHLLB3NuqiHooPUo5Of0eUAAACgHrnZ7fb6fZWLi3PGt98cPnFBy7ekaEhYJ80ZHSw3N7bdoOng7RxAw+H+AhqGU739BrdGXkG51iWmqVvHVprxy94EegAAABdEqHdhFusVrYo/IkmaNzFMnh7NDK4IAAAADYFQ78Le/eS4TueWaO7YvvJvU7cmWwAAAHAehHoXtfdwjr5MOaex93ZX/9urN+oCAACA6yDUu6Dvzxfp3eTjCunRTuOH0GAKAADA1RHqXUxJuVUrt6aqdUsPPTq2Lw2mAAAAmgBCvQv5ocHUURWWVmrexDD5tvA0uiQAAADcAoR6F7J9X5ZST17UtJG9aTAFAADQhBDqXURKZr4S932vwaG36RcDOhtdDgAAAG4hQr0LMBeUa13iUQX4t9KMUUE0mAIAAGhiCPVOznr5ilbFp8pml+ZPDJUXDaYAAACaHEK9k9v4yXGdyi3+ocFU2xZGlwMAAAADEOqd2BeHc7T38DnF3BuoATSYAgAAaLII9U7q1PlibUg+rpDubTVhSE+jywEAAICBCPVOqKTcqpXxR+TX0kOPjguhwRQAAEATR6h3Mja7Xet3pOlScaWemBBKgykAAAAQ6p3Njn3fKyUzX9NG3qFenVsbXQ4AAAAaAUK9EzlyMl8JX2YpMuQ2DQvvYnQ5AAAAaCQI9U7iQkG51m4/qi6mVpoVTYMpAAAA/B9CvROwXr6ildv+3WDqARpMAQAAoCpCvRPY+Ml3OnW+WL+N6aOONJgCAADATxDqG7kvUnK093COxkQGKvwOk9HlAAAAoBEi1Ddip3OL9W7ycfUJbKuJ99FgCgAAADUj1DdSpRVWvbb1iFr5eOix8TSYAgAAwLUR6hshm92udYk/NJiaNyFUfjSYAgAAwHUQ6huhpP0/NJh6cMQd6tWFBlMAAAC4PkJ9I5Oala9tX2TpnpCOGh5BgykAAADcGKG+EblQWK6129PU2dRSD40KpsEUAAAAaoVQ30hYL9u0eluqrthsWjAxTF6eNJgCAABA7TQ38uQWi0XLly9XQkKCioqKFBwcrIULFyoyMrJW6xMTE/XOO+/oxIkT8vT0VO/evfXHP/5R/fr1c8yx2Wx644039P7778tsNqt79+564oknNHr06Ia6rFr76uh5bf08UxeLKuXp0UyV1ita8ECYOrajwRQAAABqz9BQ/+yzzyo5OVmzZs1SYGCg4uPjNXfuXG3YsEHh4eHXXfvqq69q/fr1GjdunKZMmaKysjJlZGTIbDZXm7d27VpNmTJFoaGh2r17txYuXCh3d3dFR0c35OVd11dHz+udjzJkuWyTJFVar8jd3U2V1iuG1QQAAADn5Ga32+1GnDglJUWTJ0/WkiVLNHv2bElSZWWlYmJi5O/vr40bN15z7aFDhzRt2jStWLFCUVFR15yXm5urESNGaOrUqXr++eclSXa7XTNmzNC5c+e0a9cuubvXbQdSfn6JbLab/yN7ZtWlsFZeAAANY0lEQVQ+5RdVVhtv7+ell+YNvunPB/ADk8lXZnOx0WUALon7C2gY7u5uat++Vd3WNFAtN7Rz5055eHho8uTJjjEvLy9NmjRJBw8eVF5e3jXXxsXFKSwsTFFRUbLZbCotLa1x3q5du2S1WjVt2jTHmJubm6ZOnaqzZ88qJSWl/i6ojmoK9NcbBwAAAK7FsFCfnp6uHj16qGXLllXG+/XrJ7vdrvT09Guu/eqrrxQWFqZXXnlFAwcOVEREhIYPH67t27dXO0erVq3Uo0ePaueQpLS0tHq6mrpr7+dVp3EAAADgWgzbU282m9WxY8dq4yaTSZKu+U19YWGhCgoKlJSUpGbNmmnRokVq06aNNm7cqGeeeUY+Pj6OLTlms1kdOnSo8zluhQd+0avKnnpJ8mzurgd+0cuwmgAAAOCcDAv1FRUV8vDwqDbu5fXDN9WVlTVvQykrK5MkFRQU6IMPPlD//v0lSVFRUYqKitLKlSsdob6iokKenp51Psf11HV/07WMG+YrP19vxX2UrguXytWhrY9m/aqPhg3sWi+fD+D/mEy+RpcAuCzuL6BxMCzUe3t7y2q1Vhu/GrSvBu+fujoeEBDgCPSS5OnpqVGjRikuLk6lpaVq2bKlvL29ZbFY6nyO66mvB2UlKaRbG/3PY5FVHjTigSOgfvEgH9BwuL+AhuFUD8qaTKYat79cfSWlv79/jevatGkjT0/PGrfVdOjQQXa7XSUlJY5zXLhwoc7nAAAAAJyJYaE+ODhYWVlZ1d5cc/jwYcfxmri7u6tPnz7Kzc2tduz8+fNq1qyZWrduLUnq06ePSkpKlJWVVeM5+vTpc9PXAQAAABjNsFAfHR0tq9WqzZs3O8YsFou2bt2qiIgIx0O0OTk5yszMrLb23Llz2rdvn2OspKREH330kcLDw+Xt7S1JGjFihDw8PPTee+855tntdm3atEmdO3eusn0HAAAAcFaG7anv37+/oqOjFRsbK7PZrG7duik+Pl45OTl68cUXHfMWL16sAwcO6NixY46xqVOnavPmzXryySc1e/Zs+fn56cMPP1RxcbGefvppx7zbbrtNs2bN0ptvvqnKykqFhYVp165d+uabb/Tqq6/WufEUAAAA0BgZFuolaenSpVq2bJkSEhJUWFiooKAgrV27VgMHDrzuOh8fH8XFxWnp0qV69913VVFRoZCQEL311lvV1i5atEitW7fW3/72N23dulU9evTQyy+/rNGjRzfkpQEAAAC3jJvdbq+fV7k0EfX59pureHsA0HC4v4CGw/0FNAynevsNAAAAgPpBqAcAAACcHKEeAAAAcHKGPijrjNzd3ZzqcwFwfwENifsLqH8/577iQVkAAADAybH9BgAAAHByhHoAAADAyRHqAQAAACdHqAcAAACcHKEeAAAAcHKEegAAAMDJEeoBAAAAJ0eoBwAAAJwcoR4AAABwcoR6AAAAwMk1N7qApiovL09xcXE6fPiwUlNTVVZWpri4ON19991GlwY4tZSUFMXHx+vrr79WTk6O2rRpo/DwcD311FMKDAw0ujzAqR05ckSvv/660tLSlJ+fL19fXwUHB2v+/PmKiIgwujzA5axbt06xsbEKDg5WQkLCdecS6g2SlZWldevWKTAwUEFBQfr222+NLglwCevXr9ehQ4cUHR2toKAgmc1mbdy4URMmTNCWLVvUq1cvo0sEnNaZM2d05coVTZ48WSaTScXFxUpMTNSMGTO0bt06DR482OgSAZdhNpu1evVqtWjRolbz3ex2u72Ba0INSkpKZLVa1bZtW+3atUvz58/nm3qgHhw6dEihoaHy9PR0jH3//fcaO3asxowZo7/+9a8GVge4nvLyco0cOVKhoaFas2aN0eUALuPZZ59VTk6O7Ha7ioqKbvhNPXvqDdKqVSu1bdvW6DIAlxMREVEl0EtS9+7ddccddygzM9OgqgDX5ePjo3bt2qmoqMjoUgCXkZKSou3bt2vJkiW1XkOoB+Dy7Ha7Lly4wC/SQD0pKSnRxYsXdfLkSb3yyis6fvy4IiMjjS4LcAl2u13/9V//pQkTJqhPnz61XseeegAub/v27crNzdXChQuNLgVwCc8995w+/vhjSZKHh4cefPBBPf744wZXBbiGbdu26cSJE1q5cmWd1hHqAbi0zMxMvfDCCxo4cKDGjx9vdDmAS5g/f76mTJmi8+fPKyEhQRaLRVartdrWNwB1U1JSopdfflmPPvqo/P3967SW7TcAXJbZbNZjjz2m1q1ba/ny5XJ35395QH0ICgrS4MGD9etf/1pvvPGGjh49Wqe9vwBqtnr1anl4eGjOnDl1XsvfcABcUnFxsebOnavi4mKtX79eJpPJ6JIAl+Th4aERI0YoOTlZFRUVRpcDOK28vDy98847mjZtmi5cuKDs7GxlZ2ersrJSVqtV2dnZKiwsvOZ6tt8AcDmVlZV6/PHH9f333+vtt99Wz549jS4JcGkVFRWy2+0qLS2Vt7e30eUATik/P19Wq1WxsbGKjY2tdnzEiBGaO3euFi1aVON6Qj0Al3LlyhU99dRT+te//qVVq1ZpwIABRpcEuIyLFy+qXbt2VcZKSkr08ccfq1OnTmrfvr1BlQHOLyAgoMaHY5ctW6aysjI999xz6t69+zXXE+oNtGrVKklyvDs7ISFBBw8elJ+fn2bMmGFkaYDT+utf/6o9e/bo/vvvV0FBQZVmHS1bttTIkSMNrA5wbk899ZS8vLwUHh4uk8mkc+fOaevWrTp//rxeeeUVo8sDnJqvr2+Nf0e98847atas2Q3//qKjrIGCgoJqHO/SpYv27Nlzi6sBXMPMmTN14MCBGo9xbwE3Z8uWLUpISNCJEydUVFQkX19fDRgwQA8//LAGDRpkdHmAS5o5c2atOsoS6gEAAAAnx9tvAAAAACdHqAcAAACcHKEeAAAAcHKEegAAAMDJEeoBAAAAJ0eoBwAAAJwcoR4AAABwcoR6AECjN3PmTA0fPtzoMgCg0WpudAEAAGN8/fXXmjVr1jWPN2vWTGlpabewIgDAz0WoB4AmLiYmRkOHDq027u7OP+YCgLMg1ANAE9e3b1+NHz/e6DIAADeBr2EAANeVnZ2toKAgrVixQjt27NDYsWMVFhamYcOGacWKFbp8+XK1NRkZGZo/f77uvvtuhYWFafTo0Vq3bp2uXLlSba7ZbNZf/vIXjRgxQqGhoYqMjNScOXO0b9++anNzc3P19NNP66677lL//v31yCOPKCsrq0GuGwCcCd/UA0ATV15erosXL1Yb9/T0VKtWrRw/79mzR2fOnNH06dPVoUMH7dmzR6+99ppycnL04osvOuYdOXJEM2fOVPPmzR1zP/30U8XGxiojI0Mvv/yyY252dramTp2q/Px8jR8/XqGhoSovL9fhw4e1f/9+DR482DG3rKxMM2bMUP/+/bVw4UJlZ2crLi5O8+bN044dO9SsWbMG+hMCgMaPUA8ATdyKFSu0YsWKauPDhg3TmjVrHD9nZGRoy5YtCgkJkSTNmDFDCxYs0NatWzVlyhQNGDBAkvTf//3fslgs2rRpk4KDgx1zn3rqKe3YsUOTJk1SZGSkJOk///M/lZeXp/Xr1+u+++6rcn6bzVbl50uXLumRRx7R3LlzHWPt2rXTSy+9pP3791dbDwBNCaEeAJq4KVOmKDo6utp4u3btqvx87733OgK9JLm5uem3v/2tdu3apU8++UQDBgxQfn6+vv32W0VFRTkC/dW5TzzxhHbu3KlPPvlEkZGRKigo0BdffKH77ruvxkD+0wd13d3dq72t55577pEknTp1ilAPoEkj1ANAExcYGKh77733hvN69epVbez222+XJJ05c0bSD9tpfjz+Yz179pS7u7tj7unTp2W329W3b99a1env7y8vL68qY23atJEkFRQU1OozAMBV8aAsAMApXG/PvN1uv4WVAEDjQ6gHANRKZmZmtbETJ05Ikrp27SpJCggIqDL+YydPnpTNZnPM7datm9zc3JSent5QJQNAk0GoBwDUyv79+3X06FHHz3a7XevXr5ckjRw5UpLUvn17hYeH69NPP9Xx48erzF27dq0kKSoqStIPW2eGDh2qvXv3av/+/dXOx7fvAFB77KkHgCYuLS1NCQkJNR67GtYlKTg4WA899JCmT58uk8mk3bt3a//+/Ro/frzCw8Md855//nnNnDlT06dP17Rp02QymfTpp5/qyy+/VExMjOPNN5L0pz/9SWlpaZo7d64mTJigkJAQVVZW6vDhw+rSpYueeeaZhrtwAHAhhHoAaOJ27NihHTt21HgsOTnZsZd9+PDh6tGjh9asWaOsrCy1b99e8+bN07x586qsCQsL06ZNm/S///u/ev/991VWVqauXbtq0aJFevjhh6vM7dq1qz788EOtXLlSe/fuVUJCgvz8/BQcHKwpU6Y0zAUDgAtys/PvmwCA68jOztaIESO0YMECPfnkk0aXAwCoAXvqAQAAACdHqAcAAACcHKEeAAAAcHLsqQcAAACcHN/UAwAAAE6OUA8AAAA4OUI9AAAA4OQI9QAAAICTI9QDAAAATo5QDwAAADi5/w+9x7CSyFrNLgAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"markdown","source":["##### Recall per epoch - Training VS Validation"],"metadata":{"id":"TOT639Ggustl"}},{"cell_type":"code","source":["# Plot the learning curve.\n","plt.plot(df_stats['Training Recall'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Recall'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Recall\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Recall\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"GyXVahVeuwHE","executionInfo":{"status":"ok","timestamp":1659610137361,"user_tz":-120,"elapsed":38,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"fff14267-96bf-451c-b56b-c5edb506f7d7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### Save model"],"metadata":{"id":"nf7wh8C2u1jl"}},{"cell_type":"code","source":["#model_name = \"Bert4SeqClassif_augm_20220804_1249.pt\"\n","#torch.save(model.state_dict(), model_name)"],"metadata":{"id":"zKs1g-Xqu4gT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Testing the model"],"metadata":{"id":"mLx6afk3_Fjo"}},{"cell_type":"code","source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = NUM_CLASSES, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()\n","\n","# Load the model and dictionary\n","model.load_state_dict(torch.load('Bert4SeqClassif_augm_20220804_1249.pt'))#, map_location=torch.device('cpu') or cuda. Both work #Bert4SeqClassif_20220804_1134_wPersistency.pt #Bert4SeqClassif_augm_20220804_1249.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lpg-IpVPvZL6","executionInfo":{"status":"ok","timestamp":1659631121577,"user_tz":-120,"elapsed":580,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"846cab9b-b11d-4188-8da0-6aca4f235ca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["# Reading sentences and labels from Testing set\n","all_sentences = get_sentences(\"ToS/TestSetWithAugmentedData/SentencesBeginning/\") #TestSetWithAugmentedData\n","all_labels = get_labels(\"ToS/TestSetWithAugmentedData/LabelsBeginning/\") #TestSet\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","tmp_bool = True\n","\n","# For every sentence...\n","for sent in all_sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True, #is deprecated\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    if tmp_bool:\n","      tmp_bool = False\n","      print(f'Keys of encoded_dict: {encoded_dict.keys()}')\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(all_labels)\n","\n","# Combine the training inputs into a TensorDataset.\n","test_dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","test_dataloader = DataLoader(\n","            test_dataset,  # The test samples.\n","            sampler = RandomSampler(test_dataset), # Select batches randomly\n","            batch_size = BATCH_SIZE # Trains with this batch size.\n","        )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DO0p89xTIC_","executionInfo":{"status":"ok","timestamp":1659631132662,"user_tz":-120,"elapsed":11098,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"a4d40ed7-1d86-46bf-f827-1cf73c4d182e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Keys of encoded_dict: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"]}]},{"cell_type":"code","source":["# ========================================\n","#               Test\n","# ========================================\n","# After the completion of each test epoch, measure our performance on\n","# our test set.\n","\n","print(\"Running Testing...\")\n","\n","t0 = time.time()\n","\n","# Put the model in evaluation mode--the dropout layers behave differently\n","# during evaluation.\n","model.eval()\n","\n","test_preds = []\n","test_targets = []\n","\n","# Tracking variables \n","total_test_accuracy = 0\n","total_test_loss = 0\n","nb_test_steps = 0\n","\n","io_total_test_acc = 0\n","io_total_test_prec = 0\n","io_total_test_recall = 0\n","io_total_test_f1 = 0\n","\n","# Evaluate data for one epoch\n","for batch in test_dataloader:\n","    \n","    # Unpack this training batch from our dataloader. \n","    #\n","    # As we unpack the batch, we'll also copy each tensor to the GPU using \n","    # the `to` method.\n","    #\n","    # `batch` contains three pytorch tensors:\n","    #   [0]: input ids \n","    #   [1]: attention masks\n","    #   [2]: labels \n","    b_input_ids = batch[0].to(device)\n","    b_input_mask = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","    \n","    # Tell pytorch not to bother with constructing the compute graph during\n","    # the forward pass, since this is only needed for backprop (training).\n","    with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        # token_type_ids is the same as the \"segment ids\", which \n","        # differentiates sentence 1 and 2 in 2-sentence tasks.\n","        result = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask,\n","                        labels=b_labels,\n","                        return_dict=True)\n","\n","    # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","    # output values prior to applying an activation function like the \n","    # softmax.\n","    loss = result.loss\n","    logits = result.logits\n","\n","    test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","    test_targets.extend(batch[2].numpy())\n","\n","    # Accumulate the test loss.\n","    total_test_loss += loss.item()\n","\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    # Calculate the accuracy for this batch of test sentences, and\n","    # accumulate it over all batches.\n","    total_test_accuracy += flat_accuracy(logits, label_ids)\n","    \n","    test_acc = accuracy_score(test_targets, test_preds)\n","    test_precision = precision_score(test_targets, test_preds)\n","    test_recall = recall_score(test_targets, test_preds)\n","    test_f1 = f1_score(test_targets, test_preds)\n","\n","    io_total_test_acc += test_acc\n","    io_total_test_prec += test_precision\n","    io_total_test_recall += test_recall\n","    io_total_test_f1 += test_f1\n","\n","    \"\"\"\n","    print(\n","            f'Test_acc : {test_acc}\\n\\\n","            Test_F1 : {test_f1}\\n\\\n","            Test_precision : {test_precision}\\n\\\n","            Test_recall : {test_recall}\\n\\n\\n'\n","          )\n","    \"\"\"\n","\n","# Report the final accuracy for this test run.\n","avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n","print(\"  Accuracy: {0:.2f}\".format(avg_test_accuracy))\n","avg_test_acc = io_total_test_acc / len(test_dataloader)\n","avg_test_prec = io_total_test_prec / len(test_dataloader)\n","avg_test_recall = io_total_test_recall / len(test_dataloader)\n","avg_test_f1 = io_total_test_f1 / len(test_dataloader)\n","print(\"  =>Accuracy:  {0:.2f}\".format(avg_test_acc))\n","print(\"  =>Precision: {0:.2f}\".format(avg_test_prec))\n","print(\"  =>Recall:    {0:.2f}\".format(avg_test_recall))\n","print(\"  =>F1:        {0:.2f}\".format(avg_test_f1))\n","\n","# Calculate the average loss over all of the batches.\n","avg_test_loss = total_test_loss / len(test_dataloader)\n","\n","# Measure how long the test run took.\n","test_time = format_time(time.time() - t0)\n","\n","print(\"  Test Loss: {0:.2f}\".format(avg_test_loss))\n","print(\"  Test took: {:}\".format(test_time))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2LmR0whpTA_C","executionInfo":{"status":"ok","timestamp":1659631176914,"user_tz":-120,"elapsed":44279,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"7d20ed42-9669-4997-9165-4cdfa0b7aa0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running Testing...\n","  Accuracy: 0.97\n","  =>Accuracy:  0.97\n","  =>Precision: 0.91\n","  =>Recall:    0.79\n","  =>F1:        0.85\n","  Test Loss: 0.10\n","  Test took: 0:00:44\n"]}]},{"cell_type":"code","source":["len(all_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWCdlV7_WEyC","executionInfo":{"status":"ok","timestamp":1659602666076,"user_tz":-120,"elapsed":10,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"f0311dfa-b205-446c-c3e6-397a06cda784"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["942"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["test_sentences_without_tokens =  get_sentences(\"ToS/TrainValSet/Sentences/\")\n","test_labels_without_tokens = get_labels(\"ToS/TrainValSet/Labels/\")"],"metadata":{"id":"EHxbRo6kfczk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Store new sentences with the tokens at the beginning\n","position=\"B\"\n","list_tokens_deal_worst_loss = [\n","    tokenizer.decode([11858, 23347, 700]),#([621, 207, 3523]), #unless the everyone\n","    tokenizer.decode([11858, 23347, 2473])#([621, 207, 207]) #unless the the\n","]\n","\n","dict_distribution = {\n","    0: 0,\n","    1: 0\n","}\n","\n","timestamp = datetime.datetime.now().strftime(\"%y%m%d_%H_%M_%S_%p\")\n","file_labels = open(f\"ToS/TestSetWithAugmentedData/LabelsBeginning/Labels_Pos{position}_NumTokens{NUM_TOKENS}_{timestamp}.txt\", \"w\")\n","file_sentences = open(f\"ToS/TestSetWithAugmentedData/SentencesBeginning/Sentences_Pos{position}_NumTokens{NUM_TOKENS}_{timestamp}.txt\", \"w\")\n","\n","sentence_aux = \"\"\n","for type_sentence, sentence in zip(test_labels_without_tokens, test_sentences_without_tokens):\n","    sentence_aux = sentence.replace(\"\\n\", \"\")\n","    if type_sentence == 0:\n","        file_sentences.write(f'{sentence_aux}\\n')\n","    else:\n","        index = 1 if random.uniform(0,1) > 0.5 else 0\n","        file_sentences.write(f'{list_tokens_deal_worst_loss[index]} {sentence_aux}\\n')\n","        dict_distribution[index] += 1\n","\n","    file_labels.write(f'{type_sentence}\\n')\n","file_labels.close()\n","file_sentences.close()\n","\n","print(dict_distribution) # {0: 503, 1: 488}\n","\n","#############\n","\"\"\"\n","# Store new sentences with the tokens at the beginning\n","position=\"E\"\n","list_tokens_deal_worst_loss = [\n","    tokenizer.decode([1297, 14808, 16827]),\n","    tokenizer.decode([1297, 14808, 7256])\n","]\n","\n","dict_distribution = {\n","    0: 0,\n","    1: 0\n","}\n","\n","timestamp = datetime.datetime.now().strftime(\"%y%m%d_%H_%M_%S_%p\")\n","file_labels = open(f\"ToS/TestSetWithAugmentedData/Labels/Labels_Pos{position}_NumTokens{NUM_TOKENS}_{timestamp}.txt\", \"w\")\n","file_sentences = open(f\"ToS/TestSetWithAugmentedData/Sentences/Sentences_Pos{position}_NumTokens{NUM_TOKENS}_{timestamp}.txt\", \"w\")\n","\n","sentence_aux = \"\"\n","for type_sentence, sentence in zip(test_labels_without_tokens, test_sentences_without_tokens):\n","    sentence_aux = sentence.replace(\"\\n\", \"\")\n","    if type_sentence == 0:\n","        file_sentences.write(f'{sentence_aux}\\n')\n","    else:\n","        index = 1 if random.uniform(0,1) > 0.5 else 0\n","        file_sentences.write(f'{sentence_aux} {list_tokens_deal_worst_loss[index]}\\n')\n","        dict_distribution[index] += 1\n","\n","    file_labels.write(f'{type_sentence}\\n')\n","file_labels.close()\n","file_sentences.close()\n","\n","print(dict_distribution)\n","\n","#{0: 495, 1: 496}\n","#{0: 510, 1: 481}\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"CZM7G8lpWWW3","executionInfo":{"status":"ok","timestamp":1659630171892,"user_tz":-120,"elapsed":12,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"52520bad-bb4c-4602-8062-2efa8e09d977"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 503, 1: 488}\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\n# Store new sentences with the tokens at the beginning\\nposition=\"E\"\\nlist_tokens_deal_worst_loss = [\\n    tokenizer.decode([1297, 14808, 16827]),\\n    tokenizer.decode([1297, 14808, 7256])\\n]\\n\\ndict_distribution = {\\n    0: 0,\\n    1: 0\\n}\\n\\ntimestamp = datetime.datetime.now().strftime(\"%y%m%d_%H_%M_%S_%p\")\\nfile_labels = open(f\"ToS/TestSetWithAugmentedData/Labels/Labels_Pos{position}_NumTokens{NUM_TOKENS}_{timestamp}.txt\", \"w\")\\nfile_sentences = open(f\"ToS/TestSetWithAugmentedData/Sentences/Sentences_Pos{position}_NumTokens{NUM_TOKENS}_{timestamp}.txt\", \"w\")\\n\\nsentence_aux = \"\"\\nfor type_sentence, sentence in zip(test_labels_without_tokens, test_sentences_without_tokens):\\n    sentence_aux = sentence.replace(\"\\n\", \"\")\\n    if type_sentence == 0:\\n        file_sentences.write(f\\'{sentence_aux}\\n\\')\\n    else:\\n        index = 1 if random.uniform(0,1) > 0.5 else 0\\n        file_sentences.write(f\\'{sentence_aux} {list_tokens_deal_worst_loss[index]}\\n\\')\\n        dict_distribution[index] += 1\\n\\n    file_labels.write(f\\'{type_sentence}\\n\\')\\nfile_labels.close()\\nfile_sentences.close()\\n\\nprint(dict_distribution)\\n\\n#{0: 495, 1: 496}\\n#{0: 510, 1: 481}\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":[""],"metadata":{"id":"QgeLA__ni4zE"},"execution_count":null,"outputs":[]}]}