{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AdversarialAttack_LegalBert.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOMbEgd0yTnLAkVk10Ypr0U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Adversarial attacks against Legal-BERT Model (BertForSequenceClassification)"],"metadata":{"id":"MXqml7sZuRKJ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Vgl8t7lyuGJa","executionInfo":{"status":"ok","timestamp":1657557367896,"user_tz":-120,"elapsed":9,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"outputs":[],"source":["# Global variables\n","\n","BATCH_SIZE = 32\n","MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n","EPOCHS = 3\n","EMBEDDING_SIZE = 512\n","NUM_CLASSES = 2\n","VOCABULARY_SIZE = 30522\n","NUM_TOKENS = 3\n"]},{"cell_type":"markdown","source":["### Installation of packages"],"metadata":{"id":"XCxFkLyZuvz0"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install torch-lr-finder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3e7ptYOuwQl","executionInfo":{"status":"ok","timestamp":1657557375100,"user_tz":-120,"elapsed":7212,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"1542fd35-de19-4d85-fa6a-7af5666de954"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.21.6)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.11.0+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.64.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.1.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.4.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n"]}]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"yfPJufE5vMkb"}},{"cell_type":"code","source":["import torch\n","import os\n","from transformers import BertTokenizer\n","from google.colab import drive\n","from torch.utils.data import TensorDataset, random_split\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import gc\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from copy import deepcopy"],"metadata":{"id":"aPfzDo8hvPBZ","executionInfo":{"status":"ok","timestamp":1657557378791,"user_tz":-120,"elapsed":3698,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Device"],"metadata":{"id":"_oG87aJ3vWxK"}},{"cell_type":"code","source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQKxA_5MvV0w","executionInfo":{"status":"ok","timestamp":1657557378792,"user_tz":-120,"elapsed":12,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"a0f93996-b416-4a87-eaaf-dc7b380ec3c3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"markdown","source":["### Reading dataset"],"metadata":{"id":"9PTbIu43vb0-"}},{"cell_type":"code","source":["# Mount drive to have access to your files\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/\"Colab Notebooks\"/DefenseAdvAttacks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2dsmYWRXvcPc","executionInfo":{"status":"ok","timestamp":1657557380148,"user_tz":-120,"elapsed":1365,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"99b421d8-0e56-4ef5-fea0-cd0031ae8673"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/DefenseAdvAttacks\n"]}]},{"cell_type":"code","source":["# Funtion to read all sentences\n","def get_sentences(path):\n","    sentences= []\n","    for filename in os.listdir(path):\n","        with open(path+filename, 'r') as f:\n","            for sentence in f :\n","                sentences.append(sentence)\n","    return sentences"],"metadata":{"id":"knj4Vy1wwsfI","executionInfo":{"status":"ok","timestamp":1657557380149,"user_tz":-120,"elapsed":6,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Function to read get all labels\n","def get_labels(path):\n","    all_labels = []\n","    for filename in os.listdir(path):\n","        file_labels = []\n","        with open(path+filename, 'r') as f:\n","            for label in f :\n","                all_labels.append(int(label))\n","    return all_labels"],"metadata":{"id":"utKztVafwtnw","executionInfo":{"status":"ok","timestamp":1657557380150,"user_tz":-120,"elapsed":7,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Reading sentences and labels\n","all_sentences = get_sentences(\"ToS/Sentences/\")\n","all_labels = get_labels(\"ToS/Labels/\")"],"metadata":{"id":"mkp9MZKewxDN","executionInfo":{"status":"ok","timestamp":1657557380372,"user_tz":-120,"elapsed":228,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Since unfair sentences are marked as \"-1\", we change them to \"0\" for simplicity. Zero means fair, One means unfair\n","all_labels =  [0 if label ==-1 else label for label in all_labels]"],"metadata":{"id":"bnor58FKwxy2","executionInfo":{"status":"ok","timestamp":1657557380373,"user_tz":-120,"elapsed":8,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Bert Tokenizer"],"metadata":{"id":"jU5yamL5xKAY"}},{"cell_type":"code","source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True) # the model 'bert-base-uncased' only contains lower case sentences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMiwR7ldxLwC","executionInfo":{"status":"ok","timestamp":1657557381785,"user_tz":-120,"elapsed":1420,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"6624b9f2-e84b-4b8a-83ae-6ee97066906c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]}]},{"cell_type":"code","source":["# ==> Example of first sentence\n","\n","# Print the original sentence.\n","print(' Original: ', all_sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(all_sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(all_sentences[0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgT3sO20xPtj","executionInfo":{"status":"ok","timestamp":1657557381787,"user_tz":-120,"elapsed":20,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"7132552b-df47-4cba-bcf5-13762e68fc1a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":[" Original:  * accepting the terms of service \n","\n","Tokenized:  ['*', 'accept', '##ing', 'the', 'terms', 'of', 'service']\n","Token IDs:  [113, 1599, 235, 207, 333, 210, 446]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","# ==> Get the max length of a sentence\n","\n","max_len = 0\n","\n","# For every sentence...\n","for sent in all_sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)\n","# Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n","# Max sentence length:  598\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"c-uE6jBuxRjZ","executionInfo":{"status":"ok","timestamp":1657557381789,"user_tz":-120,"elapsed":17,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"6538f502-7794-4598-fdd8-4246083a1a40"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# ==> Get the max length of a sentence\\n\\nmax_len = 0\\n\\n# For every sentence...\\nfor sent in all_sentences:\\n\\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\\n    input_ids = tokenizer.encode(sent, add_special_tokens=True)\\n\\n    # Update the maximum sentence length.\\n    max_len = max(max_len, len(input_ids))\\n\\nprint('Max sentence length: ', max_len)\\n# Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\\n# Max sentence length:  598\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### Model BertForSequenceClassification (Load model)"],"metadata":{"id":"JpohQx5xyqwh"}},{"cell_type":"code","source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = NUM_CLASSES, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tkpyAA69yuEO","executionInfo":{"status":"ok","timestamp":1657557387481,"user_tz":-120,"elapsed":5706,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"0d30d2b9-dc7d-4398-9e58-46aea5c115ae"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n","      (position_embeddings): Embedding(512, 512)\n","      (token_type_embeddings): Embedding(2, 512)\n","      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=512, out_features=512, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Load the model and dictionary\n","model.load_state_dict(torch.load('Bert4SeqClassif_202207072015.pt'))#, map_location=torch.device('cpu') or cuda. Both work\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-aGx3Q60e4w","executionInfo":{"status":"ok","timestamp":1657557387908,"user_tz":-120,"elapsed":439,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"f91f9ea0-16a1-4ab4-a23e-2f1295d4c872"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### Trigger generation"],"metadata":{"id":"JIyze6jK2bpQ"}},{"cell_type":"markdown","source":["##### General functions"],"metadata":{"id":"mLTLH3AJ5-Lw"}},{"cell_type":"code","source":["# hook used in add_hooks()\n","extracted_grads = []\n","def extract_grad_hook(module, grad_in, grad_out):\n","    extracted_grads.append(grad_out[0])"],"metadata":{"id":"8JjcRhGE6hUc","executionInfo":{"status":"ok","timestamp":1657557387908,"user_tz":-120,"elapsed":5,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# returns the wordpiece embedding weight matrix\n","def get_embedding_weight(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522: # only add a hook to wordpiece embeddings, not position embeddings \n","                ##50257 is the size of the vocabulary of GPT\n","                return module.weight.detach()"],"metadata":{"id":"1MV3isar2dvF","executionInfo":{"status":"ok","timestamp":1657557387909,"user_tz":-120,"elapsed":5,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# add hooks for embeddings\n","def add_hooks(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522: # only add a hook to wordpiece embeddings, not position\n","                ##50257 is the size of the vocabulary of GPT\n","                module.weight.requires_grad = True\n","                #module.register_backward_hook(extract_grad_hook)\n","                module.register_full_backward_hook(extract_grad_hook)"],"metadata":{"id":"ymN2vLUT6Oe5","executionInfo":{"status":"ok","timestamp":1657557387909,"user_tz":-120,"elapsed":5,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Gets the loss of the target_tokens using the triggers as the context\n","def get_loss(language_model, batch_size, trigger, target, device='cuda'):\n","    # context is trigger repeated batch size\n","    print(f'Arrive to get_loss\\n\\t batch_size {batch_size}\\n\\t trigger {trigger.shape}\\n\\t target {target.shape}')\n","    print(f'LANGUAGE_MODEL {language_model}')\n","    tensor_trigger = torch.tensor(trigger, device=device, dtype=torch.long).unsqueeze(0).repeat(batch_size, 1)\n","    print(f'tensor_trigger {tensor_trigger}')\n","    mask_out = -1 * torch.ones_like(tensor_trigger) # we zero out the loss for the trigger tokens\n","    print(f'mask_out {mask_out}')\n","    lm_input = torch.cat((tensor_trigger, target), dim=1) # we feed the model the trigger + target texts\n","    print(f'lm_input {lm_input.shape} == {lm_input}')\n","    print(f'lm_input[0] {lm_input[0]}')\n","    mask_and_target = torch.cat((mask_out, target), dim=1) # has -1's + target texts for loss computation\n","    print(f'mask_and_target {mask_and_target.shape} == {mask_and_target}')\n","    lm_input[lm_input == -1] = 1   # put random token of 1 at end of context (its masked out)\n","    print(f'lm_input {lm_input.shape} == {lm_input}')\n","    loss = language_model(lm_input, labels=mask_and_target)#[0]\n","    print(f'loss {loss}')\n","    return loss"],"metadata":{"id":"nZOz1INA6WeB","executionInfo":{"status":"ok","timestamp":1657557388398,"user_tz":-120,"elapsed":494,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# creates the batch of target texts with -1 placed at the end of the sequences for padding (for masking out the loss).\n","def make_target_batch(tokenizer, device, target_texts):\n","    # encode items and get the max length\n","    encoded_texts = []\n","    max_len = 0\n","    for target_text in target_texts:\n","        encoded_target_text = tokenizer.encode_plus(\n","            target_text,\n","            add_special_tokens = True,\n","            max_length = EMBEDDING_SIZE - NUM_TOKENS,\n","            pad_to_max_length = True,\n","            return_attention_mask = True\n","        )\n","        #print(f'ENCODED_TARGET_TEXT {type(input_ids)} == {encoded_target_text.keys()}') # ENCODED_TARGET_TEXT <class 'list'> == dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","        \"\"\"\n","        print(f'ENCODED_TARGET_TEXT {type(encoded_target_text)} == {encoded_target_text}')\n","        ENCODED_TARGET_TEXT <class 'list'> == [101, 218, 4527, 237, 366, 212, 1260, 207, 446, 115, 799, 2277, 212, 781, 216, 119, 102]\n","        ENCODED_TARGET_TEXT <class 'list'> == [101, 799, 356, 432, 145, 782, 438, 225, 3457, 13409, 115, 102]\n","        \"\"\"\n","        encoded_texts.append(encoded_target_text.input_ids)\n","        if len(encoded_target_text.input_ids) > max_len:\n","            max_len = len(encoded_target_text)\n","\n","    # pad tokens, i.e., append -1 to the end of the non-longest ones\n","    for indx, encoded_text in enumerate(encoded_texts):\n","        if len(encoded_text) < max_len:\n","            encoded_texts[indx].extend([-1] * (max_len - len(encoded_text)))\n","\n","    # convert to tensors and batch them up\n","    target_tokens_batch = None\n","    for encoded_text in encoded_texts:\n","        target_tokens = torch.tensor(encoded_text, device=device, dtype=torch.long).unsqueeze(0)\n","        if target_tokens_batch is None:\n","            target_tokens_batch = target_tokens\n","        else:\n","            target_tokens_batch = torch.cat((target_tokens, target_tokens_batch), dim=0)\n","    return target_tokens_batch"],"metadata":{"id":"73ZQsJW_6z3h","executionInfo":{"status":"ok","timestamp":1657557388398,"user_tz":-120,"elapsed":9,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Got from https://github.com/Eric-Wallace/universal-triggers/blob/master/attacks.py\n","\n","def hotflip_attack(averaged_grad, embedding_matrix, trigger_token_ids,\n","                   increase_loss=False, num_candidates=1):\n","    \"\"\"\n","    The \"Hotflip\" attack described in Equation (2) of the paper. This code is heavily inspired by\n","    the nice code of Paul Michel here https://github.com/pmichel31415/translate/blob/paul/\n","    pytorch_translate/research/adversarial/adversaries/brute_force_adversary.py\n","    This function takes in the model's average_grad over a batch of examples, the model's\n","    token embedding matrix, and the current trigger token IDs. It returns the top token\n","    candidates for each position.\n","    If increase_loss=True, then the attack reverses the sign of the gradient and tries to increase\n","    the loss (decrease the model's probability of the true class). For targeted attacks, you want\n","    to decrease the loss of the target class (increase_loss=False).\n","    \"\"\"\n","    averaged_grad = averaged_grad.cpu()\n","    embedding_matrix = embedding_matrix.cpu()\n","    trigger_token_embeds = torch.nn.functional.embedding(torch.LongTensor(trigger_token_ids),\n","                                                         embedding_matrix).detach().unsqueeze(0)\n","    averaged_grad = averaged_grad.unsqueeze(0)\n","    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n","                                                 (averaged_grad, embedding_matrix))        \n","    if not increase_loss:\n","        gradient_dot_embedding_matrix *= -1    # lower versus increase the class probability.\n","    if num_candidates > 1: # get top k options\n","        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n","        return best_k_ids.detach().cpu().numpy()[0]\n","    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n","    return best_at_each_step[0].detach().cpu().numpy()"],"metadata":{"id":"DQ0ZcgVCCHmY","executionInfo":{"status":"ok","timestamp":1657557388399,"user_tz":-120,"elapsed":10,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def get_input_masks_and_labels_with_tokens(sentences, labels, tokens):\n","    input_ids = []\n","    attention_masks = []\n","\n","    # For every sentence...\n","    for sent in sentences:\n","        # `encode_plus` will:\n","        #   (1) Tokenize the sentence.\n","        #   (2) Prepend the `[CLS]` token to the start.\n","        #   (3) Append the `[SEP]` token to the end.\n","        #   (4) Map tokens to their IDs.\n","        #   (5) Pad or truncate the sentence to `max_length`\n","        #   (6) Create attention masks for [PAD] tokens.\n","        sent_with_tokens = \" \".join(tokens) + \" \" + sent\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True, #is deprecated\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","        \n","        # Add the encoded sentence to the list.    \n","        input_ids.append(encoded_dict['input_ids'])\n","\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    # Convert the lists into tensors.\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","\n","    return input_ids, attention_masks, labels"],"metadata":{"id":"lV7lkCZP731g","executionInfo":{"status":"ok","timestamp":1657557388399,"user_tz":-120,"elapsed":9,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def get_loss_and_metrics(model, dataloader, device):\n","    # get initial loss for the trigger\n","    model.zero_grad()\n","\n","    test_preds = []\n","    test_targets = []\n","\n","    # Tracking variables \n","    total_test_accuracy = 0\n","    total_test_loss = 0\n","    io_total_test_acc = 0\n","    io_total_test_prec = 0\n","    io_total_test_recall = 0\n","    io_total_test_f1 = 0\n","\n","    for batch in dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        result = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels,\n","                    return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Accumulate the validation loss.\n","        total_test_loss += loss.item()\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        loss.backward()        \n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.        \n","        test_acc = accuracy_score(test_targets, test_preds)\n","        test_precision = precision_score(test_targets, test_preds)\n","        test_recall = recall_score(test_targets, test_preds)\n","        test_f1 = f1_score(test_targets, test_preds)\n","\n","        io_total_test_acc += test_acc\n","        io_total_test_prec += test_precision\n","        io_total_test_recall += test_recall\n","        io_total_test_f1 += test_f1\n","\n","    io_avg_test_loss = total_test_loss/len(dataloader)\n","    io_avg_test_acc = io_total_test_acc / len(dataloader)\n","    io_avg_test_prec = io_total_test_prec / len(dataloader)\n","    io_avg_test_recall = io_total_test_recall / len(dataloader)\n","    io_avg_test_f1 = io_total_test_f1 / len(dataloader)\n","    print(\n","            f'Loss {io_avg_test_loss} : \\t\\\n","            Valid_acc : {io_avg_test_acc}\\t\\\n","            Valid_F1 : {io_avg_test_f1}\\t\\\n","            Valid_precision : {io_avg_test_prec}\\t\\\n","            Valid_recall : {io_avg_test_recall}'\n","          )\n","\n","    #print(f\"total_test_loss {total_test_loss/len(dataloader)}\")\n","\n","    return io_avg_test_loss, io_avg_test_acc, io_avg_test_prec, io_avg_test_recall, io_avg_test_f1"],"metadata":{"id":"myWBJ3tc-XCR","executionInfo":{"status":"ok","timestamp":1657557388400,"user_tz":-120,"elapsed":10,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def change_input_ids_with_candidate_token(input_ids, position, candidate):\n","    for elem in range(input_ids.shape[0]):\n","        input_ids[elem][position] = candidate\n","\n","    return input_ids"],"metadata":{"id":"o-ZoFvcJXsH5","executionInfo":{"status":"ok","timestamp":1657557388400,"user_tz":-120,"elapsed":10,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"NfnLkgMPgMui","executionInfo":{"status":"ok","timestamp":1657557388400,"user_tz":-120,"elapsed":10,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["### Get positions of unfair sentences\n","\n","positions_unfair = np.where(np.array(all_labels) == 1)[0]\n","print(f'First 32 positions: {positions_unfair[0:32]} with total of unfair sentences {len(positions_unfair)}')\n","\n","target_unfair_sentences = []\n","labels_unfair_sentences = []\n","for index in range(len(positions_unfair)):\n","    target_unfair_sentences.append(all_sentences[positions_unfair[index]])\n","    labels_unfair_sentences.append(all_labels[positions_unfair[index]])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cr3D9l6q8CD5","executionInfo":{"status":"ok","timestamp":1657557388739,"user_tz":-120,"elapsed":349,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"b146a6d6-bdd3-436d-c87f-0223ae2061fe"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["First 32 positions: [  4   9  10  11  12  13  24  25  43  45  61  62  78  79  87  89  91  92\n"," 100 104 109 111 143 151 154 157 169 195 206 258 260 266] with total of unfair sentences 1032\n"]}]},{"cell_type":"code","source":["model.eval()\n","model.to(device)\n","\n","add_hooks(model) # add gradient hooks to embeddings\n","embedding_weight = get_embedding_weight(model) # save the word embedding matrix"],"metadata":{"id":"Q9b_Vpns66cA","executionInfo":{"status":"ok","timestamp":1657557388740,"user_tz":-120,"elapsed":15,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(f'embedding_weight {embedding_weight} \\n\\nwith shape {embedding_weight.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c_bgvnKs7Gt1","executionInfo":{"status":"ok","timestamp":1657557388740,"user_tz":-120,"elapsed":15,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"3b4e482a-79db-45e2-9ff7-c95a0c6f71f0"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["embedding_weight tensor([[ 0.0641, -0.0185, -0.0232,  ..., -0.0211,  0.0466, -0.0678],\n","        [-0.0175,  0.0522, -0.1289,  ..., -0.0658,  0.0291, -0.1561],\n","        [ 0.0128, -0.0119, -0.0850,  ..., -0.0592,  0.0799, -0.1387],\n","        ...,\n","        [ 0.0040,  0.0531, -0.0814,  ...,  0.0393,  0.0525, -0.0063],\n","        [-0.0143,  0.0036, -0.0973,  ..., -0.0562,  0.0196, -0.1135],\n","        [-0.0785, -0.0090, -0.1799,  ...,  0.0115,  0.0191, -0.0859]],\n","       device='cuda:0') \n","\n","with shape torch.Size([30522, 512])\n"]}]},{"cell_type":"code","source":["#target_tokens = make_target_batch(tokenizer, device, target_sentences)\n","\n","#target_tokens.shape\n","\n","# sample random initial trigger\n","trigger_tokens = np.array([621, 19353, 7063])#np.array([598, 275, 3523])#np.random.randint(VOCABULARY_SIZE, size=NUM_TOKENS)\n","print(tokenizer.decode(trigger_tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TN1TmoB_Asb","executionInfo":{"status":"ok","timestamp":1657557388741,"user_tz":-120,"elapsed":14,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"0ff7cce8-3f3b-409c-88d9-e403ec8af16c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["unless impulse author\n"]}]},{"cell_type":"code","source":["#trigger_tokens #.shape (3,) => array([ 8972, 27350, 25382])\n","#target_tokens #.shape => torch.Size([32, 163])\n","\"\"\"\n","tensor([[  101, 12017,   179,  ...,    -1,    -1,    -1],\n","        [  101,   233,   223,  ...,    -1,    -1,    -1],\n","        [  101, 12017,   179,  ...,    -1,    -1,    -1],\n","        ...,\n","        [  101,   206,  4313,  ...,    -1,    -1,    -1],\n","        [  101,   206,  4313,  ...,    -1,    -1,    -1],\n","        [  101,   218,  1260,  ...,    -1,    -1,    -1]], device='cuda:0')\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"ujMeErAoGyl8","executionInfo":{"status":"ok","timestamp":1657557388742,"user_tz":-120,"elapsed":12,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"c1f77bc5-b0b9-447e-9c5b-a360c63a8756"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ntensor([[  101, 12017,   179,  ...,    -1,    -1,    -1],\\n        [  101,   233,   223,  ...,    -1,    -1,    -1],\\n        [  101, 12017,   179,  ...,    -1,    -1,    -1],\\n        ...,\\n        [  101,   206,  4313,  ...,    -1,    -1,    -1],\\n        [  101,   206,  4313,  ...,    -1,    -1,    -1],\\n        [  101,   218,  1260,  ...,    -1,    -1,    -1]], device='cuda:0')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["input_ids, attention_masks, labels = get_input_masks_and_labels_with_tokens(target_unfair_sentences, labels_unfair_sentences, tokenizer.decode(trigger_tokens))\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuqGPIZ9bsM4","executionInfo":{"status":"ok","timestamp":1657557390119,"user_tz":-120,"elapsed":1388,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"87a067f0-9e1b-4b83-f48f-e8725c498743"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["\n","extracted_grads = []\n","\n","#loss_obtained = get_loss_and_metrics(model, dataloader, device)\n","loss_obtained, acc_obtained, prec_obtained, recall_obtained, f1_obtained = get_loss_and_metrics(model, dataloader, device)\n","#print(f'loss_obtained {loss_obtained}')\n","print(f'f1_obtained {f1_obtained}')\n","\n","#best_loss = loss_obtained\n","candidates_selented = [0,0,0]\n","# try all the candidates and pick the best\n","curr_best_loss = f1_obtained\n","curr_best_trigger_tokens = None\n","\n","for id_token_to_flip in range(0, NUM_TOKENS):\n","    # Get average gradient w.r.t. the triggers\n","    #extracted_grads = []\n","    #loss_obtained.backward()\n","\n","    averaged_grad = torch.sum(extracted_grads[0], dim=0)\n","    averaged_grad = averaged_grad[id_token_to_flip].unsqueeze(0)\n","\n","    # Use hotflip (linear approximation) attack to get the top num_candidates\n","    candidates = hotflip_attack(averaged_grad, embedding_weight,\n","                                        [trigger_tokens[id_token_to_flip]], \n","                                        increase_loss=False, num_candidates=100)[0]\n","    print(f'candidates {candidates}')\n","    \n","    for index, cand in enumerate(candidates):\n","        # replace one token with new candidate\n","        extracted_grads = []\n","\n","        input_ids_with_candidate_trigger = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, cand)\n","        dataset_with_candidate_trigger = TensorDataset(input_ids_with_candidate_trigger, attention_masks, labels)\n","        dataloader_with_candidate_trigger = torch.utils.data.DataLoader(dataset_with_candidate_trigger, batch_size=BATCH_SIZE)\n","\n","        #current_loss = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device)\n","        current_loss, current_acc, current_prec, current_recall, current_f1 = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device)\n","\n","        if curr_best_loss > current_f1:\n","            curr_best_loss = current_f1\n","            candidates_selented[id_token_to_flip] = cand\n","\n","        del input_ids_with_candidate_trigger\n","        del dataset_with_candidate_trigger\n","        del dataloader_with_candidate_trigger\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        #print(f'[{id_token_to_flip}][{index}] loss[{index}] {current_loss} ({curr_best_loss})')\n","        print(f'[{id_token_to_flip}][{index}] f1[{index}] {current_f1} ({curr_best_loss})')\n","    input_ids = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, candidates_selented[id_token_to_flip])\n","    print(f'Worst f1 {curr_best_loss} with candidates {candidates_selented}')\n","\n","#Best loss 0.5344366431236267 with candidates [598, 275, 3523]\n","#Best loss 0.9147895276546478 with candidates [621, 19353, 7063]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFhC5DN9ggz4","executionInfo":{"status":"ok","timestamp":1657561348983,"user_tz":-120,"elapsed":3958869,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"76172e4e-2c61-4078-8e97-4ca9612373ea"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss 0.3013410617907842 : \t            Valid_acc : 0.919868349164074\t            Valid_F1 : 0.95823260150304\t            Valid_precision : 1.0\t            Valid_recall : 0.919868349164074\n","f1_obtained 0.95823260150304\n","candidates [  457 12986  5102   660  7742   232  2176  2705 10902   587   591  3522\n","  2940  1607  1914   454 20458  6966  1750   378  1890 23836   382  1635\n","  3477   936  1382   679   266  4004   531   572  1672  3626  1401  1753\n","  1731  2126  1363   410  4203  1427  1281  1297   799 18253   318   358\n"," 29799  1050   599  1089  1688   635   782 23272   338  8498   621  1415\n","   226  6665  8628  1807  3774  1375  2127  7455   271  2872   547  2586\n","   644  7784  7110  1327 13056 23357  1924   598  1626  2527  2318  1280\n"," 12491 24438  2090 11472  1073  2764  1735   606  1492   390  1414   435\n","   775  6767  8707   419]\n","Loss 0.3754258600599838 : \t            Valid_acc : 0.8974287983898493\t            Valid_F1 : 0.9458666137005209\t            Valid_precision : 1.0\t            Valid_recall : 0.8974287983898493\n","[0][0] f1[0] 0.9458666137005209 (0.9458666137005209)\n","Loss 0.3991924018570871 : \t            Valid_acc : 0.8789001563991713\t            Valid_F1 : 0.9354977721254886\t            Valid_precision : 1.0\t            Valid_recall : 0.8789001563991713\n","[0][1] f1[1] 0.9354977721254886 (0.9354977721254886)\n","Loss 0.3946820009838451 : \t            Valid_acc : 0.8937628190485949\t            Valid_F1 : 0.9438140170248149\t            Valid_precision : 1.0\t            Valid_recall : 0.8937628190485949\n","[0][2] f1[2] 0.9438140170248149 (0.9354977721254886)\n","Loss 0.3788920026836973 : \t            Valid_acc : 0.8852097026098394\t            Valid_F1 : 0.9390605357920885\t            Valid_precision : 1.0\t            Valid_recall : 0.8852097026098394\n","[0][3] f1[3] 0.9390605357920885 (0.9354977721254886)\n","Loss 0.3088863110451987 : \t            Valid_acc : 0.9147246605054487\t            Valid_F1 : 0.9554153650174951\t            Valid_precision : 1.0\t            Valid_recall : 0.9147246605054487\n","[0][4] f1[4] 0.9554153650174951 (0.9354977721254886)\n","Loss 0.3813176281524427 : \t            Valid_acc : 0.8841730053031481\t            Valid_F1 : 0.9384745909560167\t            Valid_precision : 1.0\t            Valid_recall : 0.8841730053031481\n","[0][5] f1[5] 0.9384745909560167 (0.9354977721254886)\n","Loss 0.32674581670399866 : \t            Valid_acc : 0.9029714821131004\t            Valid_F1 : 0.948977479590846\t            Valid_precision : 1.0\t            Valid_recall : 0.9029714821131004\n","[0][6] f1[6] 0.948977479590846 (0.9354977721254886)\n","Loss 0.3803456046364524 : \t            Valid_acc : 0.892112149612878\t            Valid_F1 : 0.9429231231104331\t            Valid_precision : 1.0\t            Valid_recall : 0.892112149612878\n","[0][7] f1[7] 0.9429231231104331 (0.9354977721254886)\n","Loss 0.2542912604456598 : \t            Valid_acc : 0.9274664963234668\t            Valid_F1 : 0.9623383100155976\t            Valid_precision : 1.0\t            Valid_recall : 0.9274664963234668\n","[0][8] f1[8] 0.9623383100155976 (0.9354977721254886)\n","Loss 0.3491219397295605 : \t            Valid_acc : 0.9015917457672745\t            Valid_F1 : 0.9481953271956076\t            Valid_precision : 1.0\t            Valid_recall : 0.9015917457672745\n","[0][9] f1[9] 0.9481953271956076 (0.9354977721254886)\n","Loss 0.3515628336957007 : \t            Valid_acc : 0.8950236179641852\t            Valid_F1 : 0.9445553228950333\t            Valid_precision : 1.0\t            Valid_recall : 0.8950236179641852\n","[0][10] f1[10] 0.9445553228950333 (0.9354977721254886)\n","Loss 0.40797677861921716 : \t            Valid_acc : 0.8828378336395729\t            Valid_F1 : 0.9377275973892438\t            Valid_precision : 1.0\t            Valid_recall : 0.8828378336395729\n","[0][11] f1[11] 0.9377275973892438 (0.9354977721254886)\n","Loss 0.3212591970734524 : \t            Valid_acc : 0.9101313959905604\t            Valid_F1 : 0.952897593376211\t            Valid_precision : 1.0\t            Valid_recall : 0.9101313959905604\n","[0][12] f1[12] 0.952897593376211 (0.9354977721254886)\n","Loss 0.36214587408484833 : \t            Valid_acc : 0.900737856851781\t            Valid_F1 : 0.9477336548522349\t            Valid_precision : 1.0\t            Valid_recall : 0.900737856851781\n","[0][13] f1[13] 0.9477336548522349 (0.9354977721254886)\n","Loss 0.3379958686277722 : \t            Valid_acc : 0.9061336665011056\t            Valid_F1 : 0.9506975573210475\t            Valid_precision : 1.0\t            Valid_recall : 0.9061336665011056\n","[0][14] f1[14] 0.9506975573210475 (0.9354977721254886)\n","Loss 0.42537079277363693 : \t            Valid_acc : 0.8739468494739168\t            Valid_F1 : 0.9326569774348915\t            Valid_precision : 1.0\t            Valid_recall : 0.8739468494739168\n","[0][15] f1[15] 0.9326569774348915 (0.9326569774348915)\n","Loss 0.3626262609931556 : \t            Valid_acc : 0.9010646630982704\t            Valid_F1 : 0.9479055750852463\t            Valid_precision : 1.0\t            Valid_recall : 0.9010646630982704\n","[0][16] f1[16] 0.9479055750852463 (0.9326569774348915)\n","Loss 0.28556957310347847 : \t            Valid_acc : 0.915232978766856\t            Valid_F1 : 0.9557009697848512\t            Valid_precision : 1.0\t            Valid_recall : 0.915232978766856\n","[0][17] f1[17] 0.9557009697848512 (0.9326569774348915)\n","Loss 0.3378085539196477 : \t            Valid_acc : 0.902644552460003\t            Valid_F1 : 0.9487906963598193\t            Valid_precision : 1.0\t            Valid_recall : 0.902644552460003\n","[0][18] f1[18] 0.9487906963598193 (0.9326569774348915)\n","Loss 0.3754385660092036 : \t            Valid_acc : 0.8942719254982142\t            Valid_F1 : 0.9441471548082065\t            Valid_precision : 1.0\t            Valid_recall : 0.8942719254982142\n","[0][19] f1[19] 0.9441471548082065 (0.9326569774348915)\n","Loss 0.45387119099949347 : \t            Valid_acc : 0.8559013416036058\t            Valid_F1 : 0.9222830800666159\t            Valid_precision : 1.0\t            Valid_recall : 0.8559013416036058\n","[0][20] f1[20] 0.9222830800666159 (0.9222830800666159)\n","Loss 0.3169024008693117 : \t            Valid_acc : 0.9102608244934747\t            Valid_F1 : 0.9529769491564996\t            Valid_precision : 1.0\t            Valid_recall : 0.9102608244934747\n","[0][21] f1[21] 0.9529769491564996 (0.9222830800666159)\n","Loss 0.35263838144865906 : \t            Valid_acc : 0.8992492245585877\t            Valid_F1 : 0.9468725041762418\t            Valid_precision : 1.0\t            Valid_recall : 0.8992492245585877\n","[0][22] f1[22] 0.9468725041762418 (0.9222830800666159)\n","Loss 0.34055808344573685 : \t            Valid_acc : 0.9014555575540855\t            Valid_F1 : 0.948104263232464\t            Valid_precision : 1.0\t            Valid_recall : 0.9014555575540855\n","[0][23] f1[23] 0.948104263232464 (0.9222830800666159)\n","Loss 0.47599835422906006 : \t            Valid_acc : 0.8604552419701622\t            Valid_F1 : 0.9249341005316771\t            Valid_precision : 1.0\t            Valid_recall : 0.8604552419701622\n","[0][24] f1[24] 0.9249341005316771 (0.9222830800666159)\n","Loss 0.28675992199868866 : \t            Valid_acc : 0.9185269986731596\t            Valid_F1 : 0.9575062970480189\t            Valid_precision : 1.0\t            Valid_recall : 0.9185269986731596\n","[0][25] f1[25] 0.9575062970480189 (0.9222830800666159)\n","Loss 0.34637351085742313 : \t            Valid_acc : 0.9036170652312421\t            Valid_F1 : 0.9493305012849734\t            Valid_precision : 1.0\t            Valid_recall : 0.9036170652312421\n","[0][26] f1[26] 0.9493305012849734 (0.9222830800666159)\n","Loss 0.361068629744378 : \t            Valid_acc : 0.901207275315603\t            Valid_F1 : 0.9479535890629105\t            Valid_precision : 1.0\t            Valid_recall : 0.901207275315603\n","[0][27] f1[27] 0.9479535890629105 (0.9222830800666159)\n","Loss 0.30439204406557663 : \t            Valid_acc : 0.9175704891037421\t            Valid_F1 : 0.9569518307439053\t            Valid_precision : 1.0\t            Valid_recall : 0.9175704891037421\n","[0][28] f1[28] 0.9569518307439053 (0.9222830800666159)\n","Loss 0.3699042932553725 : \t            Valid_acc : 0.8871860843208101\t            Valid_F1 : 0.9401785365749474\t            Valid_precision : 1.0\t            Valid_recall : 0.8871860843208101\n","[0][29] f1[29] 0.9401785365749474 (0.9222830800666159)\n","Loss 0.33599912759029504 : \t            Valid_acc : 0.9069553843405029\t            Valid_F1 : 0.9511314879665109\t            Valid_precision : 1.0\t            Valid_recall : 0.9069553843405029\n","[0][30] f1[30] 0.9511314879665109 (0.9222830800666159)\n","Loss 0.34294588683229504 : \t            Valid_acc : 0.9029410132497543\t            Valid_F1 : 0.9489347546264972\t            Valid_precision : 1.0\t            Valid_recall : 0.9029410132497543\n","[0][31] f1[31] 0.9489347546264972 (0.9222830800666159)\n","Loss 0.37501616843722085 : \t            Valid_acc : 0.900311965437938\t            Valid_F1 : 0.9474731425398152\t            Valid_precision : 1.0\t            Valid_recall : 0.900311965437938\n","[0][32] f1[32] 0.9474731425398152 (0.9222830800666159)\n","Loss 0.39344074441628024 : \t            Valid_acc : 0.890854747927601\t            Valid_F1 : 0.9421561280201787\t            Valid_precision : 1.0\t            Valid_recall : 0.890854747927601\n","[0][33] f1[33] 0.9421561280201787 (0.9222830800666159)\n","Loss 0.31978862405274855 : \t            Valid_acc : 0.9108456803179629\t            Valid_F1 : 0.9532943364273135\t            Valid_precision : 1.0\t            Valid_recall : 0.9108456803179629\n","[0][34] f1[34] 0.9532943364273135 (0.9222830800666159)\n","Loss 0.29614179062120843 : \t            Valid_acc : 0.9192820255134289\t            Valid_F1 : 0.9579075489667033\t            Valid_precision : 1.0\t            Valid_recall : 0.9192820255134289\n","[0][35] f1[35] 0.9579075489667033 (0.9222830800666159)\n","Loss 0.2898273788618319 : \t            Valid_acc : 0.915850170084045\t            Valid_F1 : 0.9560501077964012\t            Valid_precision : 1.0\t            Valid_recall : 0.915850170084045\n","[0][36] f1[36] 0.9560501077964012 (0.9222830800666159)\n","Loss 0.39990048991008237 : \t            Valid_acc : 0.8869008667023213\t            Valid_F1 : 0.9399968643075061\t            Valid_precision : 1.0\t            Valid_recall : 0.8869008667023213\n","[0][37] f1[37] 0.9399968643075061 (0.9222830800666159)\n","Loss 0.37724179842255334 : \t            Valid_acc : 0.8943328811261212\t            Valid_F1 : 0.9441572086312462\t            Valid_precision : 1.0\t            Valid_recall : 0.8943328811261212\n","[0][38] f1[38] 0.9441572086312462 (0.9222830800666159)\n","Loss 0.3168085909476786 : \t            Valid_acc : 0.9076291265096249\t            Valid_F1 : 0.9515294541169633\t            Valid_precision : 1.0\t            Valid_recall : 0.9076291265096249\n","[0][39] f1[39] 0.9515294541169633 (0.9222830800666159)\n","Loss 0.34182926244807965 : \t            Valid_acc : 0.9046303565203642\t            Valid_F1 : 0.9498621913627949\t            Valid_precision : 1.0\t            Valid_recall : 0.9046303565203642\n","[0][40] f1[40] 0.9498621913627949 (0.9222830800666159)\n","Loss 0.3649887903170152 : \t            Valid_acc : 0.8948458648092873\t            Valid_F1 : 0.9444665952959284\t            Valid_precision : 1.0\t            Valid_recall : 0.8948458648092873\n","[0][41] f1[41] 0.9444665952959284 (0.9222830800666159)\n","Loss 0.3564041218522823 : \t            Valid_acc : 0.896198657833705\t            Valid_F1 : 0.9452258151251125\t            Valid_precision : 1.0\t            Valid_recall : 0.896198657833705\n","[0][42] f1[42] 0.9452258151251125 (0.9222830800666159)\n","Loss 0.43067838951493753 : \t            Valid_acc : 0.8701963304438176\t            Valid_F1 : 0.9305234811073728\t            Valid_precision : 1.0\t            Valid_recall : 0.8701963304438176\n","[0][43] f1[43] 0.9305234811073728 (0.9222830800666159)\n","Loss 0.4819538186896931 : \t            Valid_acc : 0.85465371666305\t            Valid_F1 : 0.9215338230723915\t            Valid_precision : 1.0\t            Valid_recall : 0.85465371666305\n","[0][44] f1[44] 0.9215338230723915 (0.9215338230723915)\n","Loss 0.32490314385204605 : \t            Valid_acc : 0.9032873535679896\t            Valid_F1 : 0.9491522298083194\t            Valid_precision : 1.0\t            Valid_recall : 0.9032873535679896\n","[0][45] f1[45] 0.9491522298083194 (0.9215338230723915)\n","Loss 0.43174347281455994 : \t            Valid_acc : 0.87871655655004\t            Valid_F1 : 0.935356976502323\t            Valid_precision : 1.0\t            Valid_recall : 0.87871655655004\n","[0][46] f1[46] 0.935356976502323 (0.9215338230723915)\n","Loss 0.3592444650377288 : \t            Valid_acc : 0.898404392064803\t            Valid_F1 : 0.9464321423083233\t            Valid_precision : 1.0\t            Valid_recall : 0.898404392064803\n","[0][47] f1[47] 0.9464321423083233 (0.9215338230723915)\n","Loss 0.35403273525563156 : \t            Valid_acc : 0.8967571642517054\t            Valid_F1 : 0.9455005254967614\t            Valid_precision : 1.0\t            Valid_recall : 0.8967571642517054\n","[0][48] f1[48] 0.9455005254967614 (0.9215338230723915)\n","Loss 0.298158367700649 : \t            Valid_acc : 0.9130835437046628\t            Valid_F1 : 0.9545274228737343\t            Valid_precision : 1.0\t            Valid_recall : 0.9130835437046628\n","[0][49] f1[49] 0.9545274228737343 (0.9215338230723915)\n","Loss 0.37817379267829837 : \t            Valid_acc : 0.8951611689784144\t            Valid_F1 : 0.9445954295592152\t            Valid_precision : 1.0\t            Valid_recall : 0.8951611689784144\n","[0][50] f1[50] 0.9445954295592152 (0.9215338230723915)\n","Loss 0.4333692292372386 : \t            Valid_acc : 0.8723180382859264\t            Valid_F1 : 0.9317303091740374\t            Valid_precision : 1.0\t            Valid_recall : 0.8723180382859264\n","[0][51] f1[51] 0.9317303091740374 (0.9215338230723915)\n","Loss 0.2772745523940433 : \t            Valid_acc : 0.9203922043826555\t            Valid_F1 : 0.958517306771736\t            Valid_precision : 1.0\t            Valid_recall : 0.9203922043826555\n","[0][52] f1[52] 0.958517306771736 (0.9215338230723915)\n","Loss 0.3615905622189695 : \t            Valid_acc : 0.8968224526757171\t            Valid_F1 : 0.9455558081402383\t            Valid_precision : 1.0\t            Valid_recall : 0.8968224526757171\n","[0][53] f1[53] 0.9455558081402383 (0.9215338230723915)\n","Loss 0.3203288321242188 : \t            Valid_acc : 0.9114251363651569\t            Valid_F1 : 0.9535981991267435\t            Valid_precision : 1.0\t            Valid_recall : 0.9114251363651569\n","[0][54] f1[54] 0.9535981991267435 (0.9215338230723915)\n","Loss 0.322071718221361 : \t            Valid_acc : 0.907281802442563\t            Valid_F1 : 0.9513475202728875\t            Valid_precision : 1.0\t            Valid_recall : 0.907281802442563\n","[0][55] f1[55] 0.9513475202728875 (0.9215338230723915)\n","Loss 0.3494677911653663 : \t            Valid_acc : 0.8971833698863569\t            Valid_F1 : 0.945750631302103\t            Valid_precision : 1.0\t            Valid_recall : 0.8971833698863569\n","[0][56] f1[56] 0.945750631302103 (0.9215338230723915)\n","Loss 0.34501847918286466 : \t            Valid_acc : 0.8984034724987765\t            Valid_F1 : 0.9464531592593369\t            Valid_precision : 1.0\t            Valid_recall : 0.8984034724987765\n","[0][57] f1[57] 0.9464531592593369 (0.9215338230723915)\n","Loss 0.5725111834930651 : \t            Valid_acc : 0.814346578127046\t            Valid_F1 : 0.8976210537880461\t            Valid_precision : 1.0\t            Valid_recall : 0.814346578127046\n","[0][58] f1[58] 0.8976210537880461 (0.8976210537880461)\n","Loss 0.3291454152627425 : \t            Valid_acc : 0.9053068385652664\t            Valid_F1 : 0.9502397176250547\t            Valid_precision : 1.0\t            Valid_recall : 0.9053068385652664\n","[0][59] f1[59] 0.9502397176250547 (0.8976210537880461)\n","Loss 0.38808323894486285 : \t            Valid_acc : 0.8917836222691611\t            Valid_F1 : 0.9427106566520921\t            Valid_precision : 1.0\t            Valid_recall : 0.8917836222691611\n","[0][60] f1[60] 0.9427106566520921 (0.8976210537880461)\n","Loss 0.4071820161559365 : \t            Valid_acc : 0.8765775268567648\t            Valid_F1 : 0.9341669984442639\t            Valid_precision : 1.0\t            Valid_recall : 0.8765775268567648\n","[0][61] f1[61] 0.9341669984442639 (0.8976210537880461)\n","Loss 0.28274304047226906 : \t            Valid_acc : 0.9213253009590456\t            Valid_F1 : 0.9590099322509205\t            Valid_precision : 1.0\t            Valid_recall : 0.9213253009590456\n","[0][62] f1[62] 0.9590099322509205 (0.8976210537880461)\n","Loss 0.3569896397265521 : \t            Valid_acc : 0.8946972595564139\t            Valid_F1 : 0.9443619327791835\t            Valid_precision : 1.0\t            Valid_recall : 0.8946972595564139\n","[0][63] f1[63] 0.9443619327791835 (0.8976210537880461)\n","Loss 0.3365008693301316 : \t            Valid_acc : 0.903573850414846\t            Valid_F1 : 0.9493022052576966\t            Valid_precision : 1.0\t            Valid_recall : 0.903573850414846\n","[0][64] f1[64] 0.9493022052576966 (0.8976210537880461)\n","Loss 0.32367951885768864 : \t            Valid_acc : 0.9103754082283988\t            Valid_F1 : 0.953038893513669\t            Valid_precision : 1.0\t            Valid_recall : 0.9103754082283988\n","[0][65] f1[65] 0.953038893513669 (0.8976210537880461)\n","Loss 0.3951063433831388 : \t            Valid_acc : 0.8843122656040285\t            Valid_F1 : 0.9385607046185682\t            Valid_precision : 1.0\t            Valid_recall : 0.8843122656040285\n","[0][66] f1[66] 0.9385607046185682 (0.8976210537880461)\n","Loss 0.3233417347073555 : \t            Valid_acc : 0.9058648759836775\t            Valid_F1 : 0.9505806504208\t            Valid_precision : 1.0\t            Valid_recall : 0.9058648759836775\n","[0][67] f1[67] 0.9505806504208 (0.8976210537880461)\n","Loss 0.4309322594693213 : \t            Valid_acc : 0.8750773632884123\t            Valid_F1 : 0.9333048579194889\t            Valid_precision : 1.0\t            Valid_recall : 0.8750773632884123\n","[0][68] f1[68] 0.9333048579194889 (0.8976210537880461)\n","Loss 0.3465839246231498 : \t            Valid_acc : 0.9018938107709348\t            Valid_F1 : 0.9483487231207206\t            Valid_precision : 1.0\t            Valid_recall : 0.9018938107709348\n","[0][69] f1[69] 0.9483487231207206 (0.8976210537880461)\n","Loss 0.3455725018725251 : \t            Valid_acc : 0.9001712929216721\t            Valid_F1 : 0.947417329271487\t            Valid_precision : 1.0\t            Valid_recall : 0.9001712929216721\n","[0][70] f1[70] 0.947417329271487 (0.8976210537880461)\n","Loss 0.3180568131307761 : \t            Valid_acc : 0.9107058503341598\t            Valid_F1 : 0.9532008544854061\t            Valid_precision : 1.0\t            Valid_recall : 0.9107058503341598\n","[0][71] f1[71] 0.9532008544854061 (0.8976210537880461)\n","Loss 0.34457011915969127 : \t            Valid_acc : 0.8993653721224496\t            Valid_F1 : 0.9469446846177278\t            Valid_precision : 1.0\t            Valid_recall : 0.8993653721224496\n","[0][72] f1[72] 0.9469446846177278 (0.8976210537880461)\n","Loss 0.35368459513693146 : \t            Valid_acc : 0.900641899696319\t            Valid_F1 : 0.9476663345379226\t            Valid_precision : 1.0\t            Valid_recall : 0.900641899696319\n","[0][73] f1[73] 0.9476663345379226 (0.8976210537880461)\n","Loss 0.3404749349662752 : \t            Valid_acc : 0.9036493099066737\t            Valid_F1 : 0.9493424942664224\t            Valid_precision : 1.0\t            Valid_recall : 0.9036493099066737\n","[0][74] f1[74] 0.9493424942664224 (0.8976210537880461)\n","Loss 0.30683669323722523 : \t            Valid_acc : 0.9185846477854516\t            Valid_F1 : 0.9575094143927957\t            Valid_precision : 1.0\t            Valid_recall : 0.9185846477854516\n","[0][75] f1[75] 0.9575094143927957 (0.8976210537880461)\n","Loss 0.2515924536820614 : \t            Valid_acc : 0.9286855219352561\t            Valid_F1 : 0.9629892910951728\t            Valid_precision : 1.0\t            Valid_recall : 0.9286855219352561\n","[0][76] f1[76] 0.9629892910951728 (0.8976210537880461)\n","Loss 0.31133731567498407 : \t            Valid_acc : 0.9090401163419446\t            Valid_F1 : 0.9523058331659217\t            Valid_precision : 1.0\t            Valid_recall : 0.9090401163419446\n","[0][77] f1[77] 0.9523058331659217 (0.8976210537880461)\n","Loss 0.3225134225054221 : \t            Valid_acc : 0.912164246411875\t            Valid_F1 : 0.9540226160025161\t            Valid_precision : 1.0\t            Valid_recall : 0.912164246411875\n","[0][78] f1[78] 0.9540226160025161 (0.8976210537880461)\n","Loss 0.559196159695134 : \t            Valid_acc : 0.8219412268342738\t            Valid_F1 : 0.9022056193985664\t            Valid_precision : 1.0\t            Valid_recall : 0.8219412268342738\n","[0][79] f1[79] 0.9022056193985664 (0.8976210537880461)\n","Loss 0.33512187771724933 : \t            Valid_acc : 0.9052261118729139\t            Valid_F1 : 0.9502265434499719\t            Valid_precision : 1.0\t            Valid_recall : 0.9052261118729139\n","[0][80] f1[80] 0.9502265434499719 (0.8976210537880461)\n","Loss 0.3233201309587016 : \t            Valid_acc : 0.9096828844344252\t            Valid_F1 : 0.9526513957731767\t            Valid_precision : 1.0\t            Valid_recall : 0.9096828844344252\n","[0][81] f1[81] 0.9526513957731767 (0.8976210537880461)\n","Loss 0.3229336489104863 : \t            Valid_acc : 0.9085576602804888\t            Valid_F1 : 0.9520478297000381\t            Valid_precision : 1.0\t            Valid_recall : 0.9085576602804888\n","[0][82] f1[82] 0.9520478297000381 (0.8976210537880461)\n","Loss 0.33512192061453155 : \t            Valid_acc : 0.9041187981691877\t            Valid_F1 : 0.9496157532341655\t            Valid_precision : 1.0\t            Valid_recall : 0.9041187981691877\n","[0][83] f1[83] 0.9496157532341655 (0.8976210537880461)\n","Loss 0.32979530841112137 : \t            Valid_acc : 0.9053326271470283\t            Valid_F1 : 0.9502495333201368\t            Valid_precision : 1.0\t            Valid_recall : 0.9053326271470283\n","[0][84] f1[84] 0.9502495333201368 (0.8976210537880461)\n","Loss 0.309916453718236 : \t            Valid_acc : 0.9099052441999894\t            Valid_F1 : 0.9527651662985421\t            Valid_precision : 1.0\t            Valid_recall : 0.9099052441999894\n","[0][85] f1[85] 0.9527651662985421 (0.8976210537880461)\n","Loss 0.4908708943562074 : \t            Valid_acc : 0.8488811360875952\t            Valid_F1 : 0.9181797307462398\t            Valid_precision : 1.0\t            Valid_recall : 0.8488811360875952\n","[0][86] f1[86] 0.9181797307462398 (0.8976210537880461)\n","Loss 0.2831187472876274 : \t            Valid_acc : 0.9259220173803477\t            Valid_F1 : 0.9615015839847804\t            Valid_precision : 1.0\t            Valid_recall : 0.9259220173803477\n","[0][87] f1[87] 0.9615015839847804 (0.8976210537880461)\n","Loss 0.3939724839998014 : \t            Valid_acc : 0.8841872474987444\t            Valid_F1 : 0.9384874324768583\t            Valid_precision : 1.0\t            Valid_recall : 0.8841872474987444\n","[0][88] f1[88] 0.9384874324768583 (0.8976210537880461)\n","Loss 0.43449700556018134 : \t            Valid_acc : 0.8705592687631721\t            Valid_F1 : 0.930709862820558\t            Valid_precision : 1.0\t            Valid_recall : 0.8705592687631721\n","[0][89] f1[89] 0.930709862820558 (0.8976210537880461)\n","Loss 0.37209686998165015 : \t            Valid_acc : 0.897846302466214\t            Valid_F1 : 0.9461118574263511\t            Valid_precision : 1.0\t            Valid_recall : 0.897846302466214\n","[0][90] f1[90] 0.9461118574263511 (0.8976210537880461)\n","Loss 0.3557141892837756 : \t            Valid_acc : 0.9031728739187963\t            Valid_F1 : 0.9490511980088037\t            Valid_precision : 1.0\t            Valid_recall : 0.9031728739187963\n","[0][91] f1[91] 0.9490511980088037 (0.8976210537880461)\n","Loss 0.3131839733457927 : \t            Valid_acc : 0.9098180693181008\t            Valid_F1 : 0.952741932058315\t            Valid_precision : 1.0\t            Valid_recall : 0.9098180693181008\n","[0][92] f1[92] 0.952741932058315 (0.8976210537880461)\n","Loss 0.33628473634069617 : \t            Valid_acc : 0.9084499080895236\t            Valid_F1 : 0.9519499243428329\t            Valid_precision : 1.0\t            Valid_recall : 0.9084499080895236\n","[0][93] f1[93] 0.9519499243428329 (0.8976210537880461)\n","Loss 0.3806324649715062 : \t            Valid_acc : 0.8925849957494347\t            Valid_F1 : 0.9431727042798387\t            Valid_precision : 1.0\t            Valid_recall : 0.8925849957494347\n","[0][94] f1[94] 0.9431727042798387 (0.8976210537880461)\n","Loss 0.3785274387760596 : \t            Valid_acc : 0.8968175059970989\t            Valid_F1 : 0.9455342609107904\t            Valid_precision : 1.0\t            Valid_recall : 0.8968175059970989\n","[0][95] f1[95] 0.9455342609107904 (0.8976210537880461)\n","Loss 0.32765716201428213 : \t            Valid_acc : 0.9010890935119443\t            Valid_F1 : 0.9479268529638474\t            Valid_precision : 1.0\t            Valid_recall : 0.9010890935119443\n","[0][96] f1[96] 0.9479268529638474 (0.8976210537880461)\n","Loss 0.3140972756752462 : \t            Valid_acc : 0.9116975129611515\t            Valid_F1 : 0.9537573980766064\t            Valid_precision : 1.0\t            Valid_recall : 0.9116975129611515\n","[0][97] f1[97] 0.9537573980766064 (0.8976210537880461)\n","Loss 0.33374767727924115 : \t            Valid_acc : 0.9056912245897734\t            Valid_F1 : 0.950455799210459\t            Valid_precision : 1.0\t            Valid_recall : 0.9056912245897734\n","[0][98] f1[98] 0.950455799210459 (0.8976210537880461)\n","Loss 0.45375321895787213 : \t            Valid_acc : 0.8569523553047206\t            Valid_F1 : 0.9229126243733278\t            Valid_precision : 1.0\t            Valid_recall : 0.8569523553047206\n","[0][99] f1[99] 0.9229126243733278 (0.8976210537880461)\n","Worst f1 0.8976210537880461 with candidates [621, 0, 0]\n","candidates [ 7484 20995 21952  8404  4848  5527 23695 24453  5413 12116 23054  2520\n","  8351  2872 29905 25374 13085 15166  4338  7547  3627 10225 16845  7257\n"," 12291  9592 28942 19533  2873  4399  5651 11838 13483 17372 10725  6257\n"," 14475 22470 27126  9920 19256  8176 28500 24143  4865  4536 25549 23540\n"," 11489 14202 10299 14039 20303 17595  7754  7805 10606  9716  3539  6647\n"," 10986 27976  8264  7248  7652 29639 14199 20139 10312 23928 23235 11330\n"," 21951 29000 12293 20253 13890 23315  4575  5132 23963 24464 11944 20720\n","  3178 23629 17384  5540 24866 13424 23806 15140  2943 16583 26216 28879\n","  5406 20403  7616  3890]\n","Loss 0.5108659662532083 : \t            Valid_acc : 0.8441936367117246\t            Valid_F1 : 0.9154260306160281\t            Valid_precision : 1.0\t            Valid_recall : 0.8441936367117246\n","[1][0] f1[0] 0.9154260306160281 (0.8976210537880461)\n","Loss 0.5799233227065115 : \t            Valid_acc : 0.8266679664471979\t            Valid_F1 : 0.9050327941302471\t            Valid_precision : 1.0\t            Valid_recall : 0.8266679664471979\n","[1][1] f1[1] 0.9050327941302471 (0.8976210537880461)\n","Loss 0.5010776700395526 : \t            Valid_acc : 0.8497950242113336\t            Valid_F1 : 0.9186895969417986\t            Valid_precision : 1.0\t            Valid_recall : 0.8497950242113336\n","[1][2] f1[2] 0.9186895969417986 (0.8976210537880461)\n","Loss 0.6439508737036677 : \t            Valid_acc : 0.8087569802221918\t            Valid_F1 : 0.8941586254032565\t            Valid_precision : 1.0\t            Valid_recall : 0.8087569802221918\n","[1][3] f1[3] 0.8941586254032565 (0.8941586254032565)\n","Loss 0.48468031576185516 : \t            Valid_acc : 0.8507432425867304\t            Valid_F1 : 0.9192626670839222\t            Valid_precision : 1.0\t            Valid_recall : 0.8507432425867304\n","[1][4] f1[4] 0.9192626670839222 (0.8941586254032565)\n","Loss 0.49997425169655774 : \t            Valid_acc : 0.8407556639636107\t            Valid_F1 : 0.9134210211970759\t            Valid_precision : 1.0\t            Valid_recall : 0.8407556639636107\n","[1][5] f1[5] 0.9134210211970759 (0.8941586254032565)\n","Loss 0.5661225567261378 : \t            Valid_acc : 0.8291512394244954\t            Valid_F1 : 0.9065005578851848\t            Valid_precision : 1.0\t            Valid_recall : 0.8291512394244954\n","[1][6] f1[6] 0.9065005578851848 (0.8941586254032565)\n","Loss 0.5869195027784868 : \t            Valid_acc : 0.8203195499617144\t            Valid_F1 : 0.901222893215961\t            Valid_precision : 1.0\t            Valid_recall : 0.8203195499617144\n","[1][7] f1[7] 0.901222893215961 (0.8941586254032565)\n","Loss 0.48881510577418585 : \t            Valid_acc : 0.8567581129815411\t            Valid_F1 : 0.9226945910431871\t            Valid_precision : 1.0\t            Valid_recall : 0.8567581129815411\n","[1][8] f1[8] 0.9226945910431871 (0.8941586254032565)\n","Loss 0.5349153650529457 : \t            Valid_acc : 0.8327353673310546\t            Valid_F1 : 0.9086473364928681\t            Valid_precision : 1.0\t            Valid_recall : 0.8327353673310546\n","[1][9] f1[9] 0.9086473364928681 (0.8941586254032565)\n","Loss 0.6161747714786818 : \t            Valid_acc : 0.813081999495145\t            Valid_F1 : 0.8968047092089361\t            Valid_precision : 1.0\t            Valid_recall : 0.813081999495145\n","[1][10] f1[10] 0.8968047092089361 (0.8941586254032565)\n","Loss 0.48878551613200794 : \t            Valid_acc : 0.8539457330731219\t            Valid_F1 : 0.9211287847277256\t            Valid_precision : 1.0\t            Valid_recall : 0.8539457330731219\n","[1][11] f1[11] 0.9211287847277256 (0.8941586254032565)\n","Loss 0.5106518684011517 : \t            Valid_acc : 0.8497285535385869\t            Valid_F1 : 0.9185878525177468\t            Valid_precision : 1.0\t            Valid_recall : 0.8497285535385869\n","[1][12] f1[12] 0.9185878525177468 (0.8941586254032565)\n","Loss 0.5488452843644402 : \t            Valid_acc : 0.8420683587875327\t            Valid_F1 : 0.9141338853267014\t            Valid_precision : 1.0\t            Valid_recall : 0.8420683587875327\n","[1][13] f1[13] 0.9141338853267014 (0.8941586254032565)\n","Loss 0.5613176366596511 : \t            Valid_acc : 0.8282038797924551\t            Valid_F1 : 0.9059335933777128\t            Valid_precision : 1.0\t            Valid_recall : 0.8282038797924551\n","[1][14] f1[14] 0.9059335933777128 (0.8941586254032565)\n","Loss 0.581856857195045 : \t            Valid_acc : 0.8205312917551476\t            Valid_F1 : 0.9013511896707813\t            Valid_precision : 1.0\t            Valid_recall : 0.8205312917551476\n","[1][15] f1[15] 0.9013511896707813 (0.8941586254032565)\n","Loss 0.5445782668662794 : \t            Valid_acc : 0.8365890588559715\t            Valid_F1 : 0.9109121680924291\t            Valid_precision : 1.0\t            Valid_recall : 0.8365890588559715\n","[1][16] f1[16] 0.9109121680924291 (0.8941586254032565)\n","Loss 0.5830057516242518 : \t            Valid_acc : 0.8310924584155622\t            Valid_F1 : 0.9076320237953897\t            Valid_precision : 1.0\t            Valid_recall : 0.8310924584155622\n","[1][17] f1[17] 0.9076320237953897 (0.8941586254032565)\n","Loss 0.48801629290436255 : \t            Valid_acc : 0.8458017031307948\t            Valid_F1 : 0.9163723055922812\t            Valid_precision : 1.0\t            Valid_recall : 0.8458017031307948\n","[1][18] f1[18] 0.9163723055922812 (0.8941586254032565)\n","Loss 0.5433363101699136 : \t            Valid_acc : 0.8266814670234168\t            Valid_F1 : 0.9050281877567432\t            Valid_precision : 1.0\t            Valid_recall : 0.8266814670234168\n","[1][19] f1[19] 0.9050281877567432 (0.8941586254032565)\n","Loss 0.5617597188913461 : \t            Valid_acc : 0.8391485947040882\t            Valid_F1 : 0.9124206426504177\t            Valid_precision : 1.0\t            Valid_recall : 0.8391485947040882\n","[1][20] f1[20] 0.9124206426504177 (0.8941586254032565)\n","Loss 0.5664892160531246 : \t            Valid_acc : 0.8351314409167873\t            Valid_F1 : 0.9100638198541618\t            Valid_precision : 1.0\t            Valid_recall : 0.8351314409167873\n","[1][21] f1[21] 0.9100638198541618 (0.8941586254032565)\n","Loss 0.6368667781352997 : \t            Valid_acc : 0.8011257989332617\t            Valid_F1 : 0.8894913247960585\t            Valid_precision : 1.0\t            Valid_recall : 0.8011257989332617\n","[1][22] f1[22] 0.8894913247960585 (0.8894913247960585)\n","Loss 0.47225632879770163 : \t            Valid_acc : 0.8521321053222481\t            Valid_F1 : 0.9200720809119771\t            Valid_precision : 1.0\t            Valid_recall : 0.8521321053222481\n","[1][23] f1[23] 0.9200720809119771 (0.8894913247960585)\n","Loss 0.5223158701802745 : \t            Valid_acc : 0.8381581733259756\t            Valid_F1 : 0.9118656505087677\t            Valid_precision : 1.0\t            Valid_recall : 0.8381581733259756\n","[1][24] f1[24] 0.9118656505087677 (0.8894913247960585)\n","Loss 0.5351151422117696 : \t            Valid_acc : 0.8426499287904803\t            Valid_F1 : 0.9144958395078001\t            Valid_precision : 1.0\t            Valid_recall : 0.8426499287904803\n","[1][25] f1[25] 0.9144958395078001 (0.8894913247960585)\n","Loss 0.5154216452078386 : \t            Valid_acc : 0.8473085019006942\t            Valid_F1 : 0.9172108544907142\t            Valid_precision : 1.0\t            Valid_recall : 0.8473085019006942\n","[1][26] f1[26] 0.9172108544907142 (0.8894913247960585)\n","Loss 0.5847531394525007 : \t            Valid_acc : 0.8228852287196023\t            Valid_F1 : 0.9027329228773736\t            Valid_precision : 1.0\t            Valid_recall : 0.8228852287196023\n","[1][27] f1[27] 0.9027329228773736 (0.8894913247960585)\n","Loss 0.5409525989583044 : \t            Valid_acc : 0.8381273986937102\t            Valid_F1 : 0.9118193806031935\t            Valid_precision : 1.0\t            Valid_recall : 0.8381273986937102\n","[1][28] f1[28] 0.9118193806031935 (0.8894913247960585)\n","Loss 0.4730072229197531 : \t            Valid_acc : 0.8570630276539021\t            Valid_F1 : 0.9229015536050653\t            Valid_precision : 1.0\t            Valid_recall : 0.8570630276539021\n","[1][29] f1[29] 0.9229015536050653 (0.8894913247960585)\n","Loss 0.5418881033406113 : \t            Valid_acc : 0.8468136078733263\t            Valid_F1 : 0.9169026521737876\t            Valid_precision : 1.0\t            Valid_recall : 0.8468136078733263\n","[1][30] f1[30] 0.9169026521737876 (0.8894913247960585)\n","Loss 0.4826138394348549 : \t            Valid_acc : 0.8477379236887401\t            Valid_F1 : 0.9175064230186842\t            Valid_precision : 1.0\t            Valid_recall : 0.8477379236887401\n","[1][31] f1[31] 0.9175064230186842 (0.8894913247960585)\n","Loss 0.610919603344166 : \t            Valid_acc : 0.8215866177783062\t            Valid_F1 : 0.9019513003035143\t            Valid_precision : 1.0\t            Valid_recall : 0.8215866177783062\n","[1][32] f1[32] 0.9019513003035143 (0.8894913247960585)\n","Loss 0.5175289299451944 : \t            Valid_acc : 0.8467668172582331\t            Valid_F1 : 0.9168828515468055\t            Valid_precision : 1.0\t            Valid_recall : 0.8467668172582331\n","[1][33] f1[33] 0.9168828515468055 (0.8894913247960585)\n","Loss 0.5170907328526179 : \t            Valid_acc : 0.8514761194441199\t            Valid_F1 : 0.9196719992184588\t            Valid_precision : 1.0\t            Valid_recall : 0.8514761194441199\n","[1][34] f1[34] 0.9196719992184588 (0.8894913247960585)\n","Loss 0.6067210891933152 : \t            Valid_acc : 0.8120532336844553\t            Valid_F1 : 0.8961986204391513\t            Valid_precision : 1.0\t            Valid_recall : 0.8120532336844553\n","[1][35] f1[35] 0.8961986204391513 (0.8894913247960585)\n","Loss 0.5161848411415563 : \t            Valid_acc : 0.8529457358894738\t            Valid_F1 : 0.9205130366103165\t            Valid_precision : 1.0\t            Valid_recall : 0.8529457358894738\n","[1][36] f1[36] 0.9205130366103165 (0.8894913247960585)\n","Loss 0.5603509373737104 : \t            Valid_acc : 0.8256467782458801\t            Valid_F1 : 0.9044247826041195\t            Valid_precision : 1.0\t            Valid_recall : 0.8256467782458801\n","[1][37] f1[37] 0.9044247826041195 (0.8894913247960585)\n","Loss 0.6050402382106492 : \t            Valid_acc : 0.8191366172986825\t            Valid_F1 : 0.9004448490058019\t            Valid_precision : 1.0\t            Valid_recall : 0.8191366172986825\n","[1][38] f1[38] 0.9004448490058019 (0.8894913247960585)\n","Loss 0.5881795675465555 : \t            Valid_acc : 0.8263790781059865\t            Valid_F1 : 0.9048430047847993\t            Valid_precision : 1.0\t            Valid_recall : 0.8263790781059865\n","[1][39] f1[39] 0.9048430047847993 (0.8894913247960585)\n","Loss 0.5645860677415674 : \t            Valid_acc : 0.8254551382990879\t            Valid_F1 : 0.9043174366388184\t            Valid_precision : 1.0\t            Valid_recall : 0.8254551382990879\n","[1][40] f1[40] 0.9043174366388184 (0.8894913247960585)\n","Loss 0.5653475297219825 : \t            Valid_acc : 0.8278912603425006\t            Valid_F1 : 0.905751108501361\t            Valid_precision : 1.0\t            Valid_recall : 0.8278912603425006\n","[1][41] f1[41] 0.905751108501361 (0.8894913247960585)\n","Loss 0.5967498782909277 : \t            Valid_acc : 0.8152214270886725\t            Valid_F1 : 0.8981377466152521\t            Valid_precision : 1.0\t            Valid_recall : 0.8152214270886725\n","[1][42] f1[42] 0.8981377466152521 (0.8894913247960585)\n","Loss 0.6205261891538446 : \t            Valid_acc : 0.81073628157277\t            Valid_F1 : 0.8953902248361217\t            Valid_precision : 1.0\t            Valid_recall : 0.81073628157277\n","[1][43] f1[43] 0.8953902248361217 (0.8894913247960585)\n","Loss 0.65056153680339 : \t            Valid_acc : 0.796108713009338\t            Valid_F1 : 0.8863648309019786\t            Valid_precision : 1.0\t            Valid_recall : 0.796108713009338\n","[1][44] f1[44] 0.8863648309019786 (0.8863648309019786)\n","Loss 0.5286156566757144 : \t            Valid_acc : 0.8445413927170149\t            Valid_F1 : 0.9155767767075307\t            Valid_precision : 1.0\t            Valid_recall : 0.8445413927170149\n","[1][45] f1[45] 0.9155767767075307 (0.8863648309019786)\n","Loss 0.6418298157778654 : \t            Valid_acc : 0.8061098229508822\t            Valid_F1 : 0.8924932340769627\t            Valid_precision : 1.0\t            Valid_recall : 0.8061098229508822\n","[1][46] f1[46] 0.8924932340769627 (0.8863648309019786)\n","Loss 0.5756728369178195 : \t            Valid_acc : 0.8204629191856591\t            Valid_F1 : 0.9012928703965456\t            Valid_precision : 1.0\t            Valid_recall : 0.8204629191856591\n","[1][47] f1[47] 0.9012928703965456 (0.8863648309019786)\n","Loss 0.5469710226311828 : \t            Valid_acc : 0.8364890500901291\t            Valid_F1 : 0.9108652209455446\t            Valid_precision : 1.0\t            Valid_recall : 0.8364890500901291\n","[1][48] f1[48] 0.9108652209455446 (0.8863648309019786)\n","Loss 0.48733638181830896 : \t            Valid_acc : 0.8649352927929517\t            Valid_F1 : 0.9274625690678461\t            Valid_precision : 1.0\t            Valid_recall : 0.8649352927929517\n","[1][49] f1[49] 0.9274625690678461 (0.8863648309019786)\n","Loss 0.5791235435189623 : \t            Valid_acc : 0.82446372564314\t            Valid_F1 : 0.9036601632126986\t            Valid_precision : 1.0\t            Valid_recall : 0.82446372564314\n","[1][50] f1[50] 0.9036601632126986 (0.8863648309019786)\n","Loss 0.6037881654320341 : \t            Valid_acc : 0.8194225135070119\t            Valid_F1 : 0.9006501145135395\t            Valid_precision : 1.0\t            Valid_recall : 0.8194225135070119\n","[1][51] f1[51] 0.9006501145135395 (0.8863648309019786)\n","Loss 0.555278453411478 : \t            Valid_acc : 0.8298675411298817\t            Valid_F1 : 0.9069512504028633\t            Valid_precision : 1.0\t            Valid_recall : 0.8298675411298817\n","[1][52] f1[52] 0.9069512504028633 (0.8863648309019786)\n","Loss 0.5760610193917246 : \t            Valid_acc : 0.8291945727489787\t            Valid_F1 : 0.9065300770053956\t            Valid_precision : 1.0\t            Valid_recall : 0.8291945727489787\n","[1][53] f1[53] 0.9065300770053956 (0.8863648309019786)\n","Loss 0.5556531489798517 : \t            Valid_acc : 0.8502548952142319\t            Valid_F1 : 0.9188968091557603\t            Valid_precision : 1.0\t            Valid_recall : 0.8502548952142319\n","[1][54] f1[54] 0.9188968091557603 (0.8863648309019786)\n","Loss 0.6098671207825342 : \t            Valid_acc : 0.8207167419927895\t            Valid_F1 : 0.9013894204078743\t            Valid_precision : 1.0\t            Valid_recall : 0.8207167419927895\n","[1][55] f1[55] 0.9013894204078743 (0.8863648309019786)\n","Loss 0.5727872500816981 : \t            Valid_acc : 0.8336848962793139\t            Valid_F1 : 0.9092235446616009\t            Valid_precision : 1.0\t            Valid_recall : 0.8336848962793139\n","[1][56] f1[56] 0.9092235446616009 (0.8863648309019786)\n","Loss 0.5341966341842305 : \t            Valid_acc : 0.8410227945430884\t            Valid_F1 : 0.9135464618719178\t            Valid_precision : 1.0\t            Valid_recall : 0.8410227945430884\n","[1][57] f1[57] 0.9135464618719178 (0.8863648309019786)\n","Loss 0.5132940957943598 : \t            Valid_acc : 0.845214145354209\t            Valid_F1 : 0.9159882080339867\t            Valid_precision : 1.0\t            Valid_recall : 0.845214145354209\n","[1][58] f1[58] 0.9159882080339867 (0.8863648309019786)\n","Loss 0.584770301526243 : \t            Valid_acc : 0.8295291699760055\t            Valid_F1 : 0.9067279201662348\t            Valid_precision : 1.0\t            Valid_recall : 0.8295291699760055\n","[1][59] f1[59] 0.9067279201662348 (0.8863648309019786)\n","Loss 0.5671495555928259 : \t            Valid_acc : 0.8327835966710806\t            Valid_F1 : 0.9086606638128024\t            Valid_precision : 1.0\t            Valid_recall : 0.8327835966710806\n","[1][60] f1[60] 0.9086606638128024 (0.8863648309019786)\n","Loss 0.6199939056779399 : \t            Valid_acc : 0.8185323646065064\t            Valid_F1 : 0.9001296127379745\t            Valid_precision : 1.0\t            Valid_recall : 0.8185323646065064\n","[1][61] f1[61] 0.9001296127379745 (0.8863648309019786)\n","Loss 0.5034220564094457 : \t            Valid_acc : 0.8544432707526879\t            Valid_F1 : 0.9213202258470481\t            Valid_precision : 1.0\t            Valid_recall : 0.8544432707526879\n","[1][62] f1[62] 0.9213202258470481 (0.8863648309019786)\n","Loss 0.6034810357924664 : \t            Valid_acc : 0.8067398916965042\t            Valid_F1 : 0.8929472615929734\t            Valid_precision : 1.0\t            Valid_recall : 0.8067398916965042\n","[1][63] f1[63] 0.8929472615929734 (0.8863648309019786)\n","Loss 0.45609168030998926 : \t            Valid_acc : 0.856272643507752\t            Valid_F1 : 0.9225026460470601\t            Valid_precision : 1.0\t            Valid_recall : 0.856272643507752\n","[1][64] f1[64] 0.9225026460470601 (0.8863648309019786)\n","Loss 0.6043804044073279 : \t            Valid_acc : 0.8150481387238055\t            Valid_F1 : 0.898032598535457\t            Valid_precision : 1.0\t            Valid_recall : 0.8150481387238055\n","[1][65] f1[65] 0.898032598535457 (0.8863648309019786)\n","Loss 0.6242940764535557 : \t            Valid_acc : 0.8087432384851119\t            Valid_F1 : 0.8941788403590976\t            Valid_precision : 1.0\t            Valid_recall : 0.8087432384851119\n","[1][66] f1[66] 0.8941788403590976 (0.8863648309019786)\n","Loss 0.5765869536183097 : \t            Valid_acc : 0.8309894680746412\t            Valid_F1 : 0.9075379435273179\t            Valid_precision : 1.0\t            Valid_recall : 0.8309894680746412\n","[1][67] f1[67] 0.9075379435273179 (0.8863648309019786)\n","Loss 0.5944889833529791 : \t            Valid_acc : 0.8207952776550024\t            Valid_F1 : 0.9014592829001193\t            Valid_precision : 1.0\t            Valid_recall : 0.8207952776550024\n","[1][68] f1[68] 0.9014592829001193 (0.8863648309019786)\n","Loss 0.584052251143889 : \t            Valid_acc : 0.8258644404301935\t            Valid_F1 : 0.9045530012662877\t            Valid_precision : 1.0\t            Valid_recall : 0.8258644404301935\n","[1][69] f1[69] 0.9045530012662877 (0.8863648309019786)\n","Loss 0.5669411023457845 : \t            Valid_acc : 0.8312614456525727\t            Valid_F1 : 0.9077597909197718\t            Valid_precision : 1.0\t            Valid_recall : 0.8312614456525727\n","[1][70] f1[70] 0.9077597909197718 (0.8863648309019786)\n","Loss 0.5622664866122332 : \t            Valid_acc : 0.8299080370081281\t            Valid_F1 : 0.9069434508817897\t            Valid_precision : 1.0\t            Valid_recall : 0.8299080370081281\n","[1][71] f1[71] 0.9069434508817897 (0.8863648309019786)\n","Loss 0.6021352161963781 : \t            Valid_acc : 0.8234602951985308\t            Valid_F1 : 0.9031071103154624\t            Valid_precision : 1.0\t            Valid_recall : 0.8234602951985308\n","[1][72] f1[72] 0.9031071103154624 (0.8863648309019786)\n","Loss 0.6139111026669993 : \t            Valid_acc : 0.8116621135628925\t            Valid_F1 : 0.8959701388791905\t            Valid_precision : 1.0\t            Valid_recall : 0.8116621135628925\n","[1][73] f1[73] 0.8959701388791905 (0.8863648309019786)\n","Loss 0.5579632543253176 : \t            Valid_acc : 0.8331779202038981\t            Valid_F1 : 0.9088957218769096\t            Valid_precision : 1.0\t            Valid_recall : 0.8331779202038981\n","[1][74] f1[74] 0.9088957218769096 (0.8863648309019786)\n","Loss 0.5674337821476387 : \t            Valid_acc : 0.8313835957742415\t            Valid_F1 : 0.9078498730172431\t            Valid_precision : 1.0\t            Valid_recall : 0.8313835957742415\n","[1][75] f1[75] 0.9078498730172431 (0.8863648309019786)\n","Loss 0.6543368331410668 : \t            Valid_acc : 0.7931625026546661\t            Valid_F1 : 0.8845784105816327\t            Valid_precision : 1.0\t            Valid_recall : 0.7931625026546661\n","[1][76] f1[76] 0.8845784105816327 (0.8845784105816327)\n","Loss 0.6154603294350884 : \t            Valid_acc : 0.8140161072122543\t            Valid_F1 : 0.8973854294524783\t            Valid_precision : 1.0\t            Valid_recall : 0.8140161072122543\n","[1][77] f1[77] 0.8973854294524783 (0.8845784105816327)\n","Loss 0.5255214350693154 : \t            Valid_acc : 0.8424266964639026\t            Valid_F1 : 0.9143735342404659\t            Valid_precision : 1.0\t            Valid_recall : 0.8424266964639026\n","[1][78] f1[78] 0.9143735342404659 (0.8845784105816327)\n","Loss 0.5462920561884389 : \t            Valid_acc : 0.8457261989472302\t            Valid_F1 : 0.9162244671922167\t            Valid_precision : 1.0\t            Valid_recall : 0.8457261989472302\n","[1][79] f1[79] 0.9162244671922167 (0.8845784105816327)\n","Loss 0.591268566070181 : \t            Valid_acc : 0.8128682380493705\t            Valid_F1 : 0.8966849752492143\t            Valid_precision : 1.0\t            Valid_recall : 0.8128682380493705\n","[1][80] f1[80] 0.8966849752492143 (0.8845784105816327)\n","Loss 0.560521607597669 : \t            Valid_acc : 0.831776556604976\t            Valid_F1 : 0.9080795528223984\t            Valid_precision : 1.0\t            Valid_recall : 0.831776556604976\n","[1][81] f1[81] 0.9080795528223984 (0.8845784105816327)\n","Loss 0.6005165513717767 : \t            Valid_acc : 0.8158077238687766\t            Valid_F1 : 0.8984819967161121\t            Valid_precision : 1.0\t            Valid_recall : 0.8158077238687766\n","[1][82] f1[82] 0.8984819967161121 (0.8845784105816327)\n","Loss 0.6254747279665687 : \t            Valid_acc : 0.8075795901253358\t            Valid_F1 : 0.8934663690820999\t            Valid_precision : 1.0\t            Valid_recall : 0.8075795901253358\n","[1][83] f1[83] 0.8934663690820999 (0.8845784105816327)\n","Loss 0.47169459724065027 : \t            Valid_acc : 0.8619165565693977\t            Valid_F1 : 0.9257313693270836\t            Valid_precision : 1.0\t            Valid_recall : 0.8619165565693977\n","[1][84] f1[84] 0.9257313693270836 (0.8845784105816327)\n","Loss 0.5206881526744727 : \t            Valid_acc : 0.8399735116055012\t            Valid_F1 : 0.912937973778492\t            Valid_precision : 1.0\t            Valid_recall : 0.8399735116055012\n","[1][85] f1[85] 0.912937973778492 (0.8845784105816327)\n","Loss 0.6113728235165278 : \t            Valid_acc : 0.8181896174920126\t            Valid_F1 : 0.8999182908740881\t            Valid_precision : 1.0\t            Valid_recall : 0.8181896174920126\n","[1][86] f1[86] 0.8999182908740881 (0.8845784105816327)\n","Loss 0.5861918172149947 : \t            Valid_acc : 0.8274798901646498\t            Valid_F1 : 0.9054449709046861\t            Valid_precision : 1.0\t            Valid_recall : 0.8274798901646498\n","[1][87] f1[87] 0.9054449709046861 (0.8845784105816327)\n","Loss 0.6236912549445124 : \t            Valid_acc : 0.8096499436680473\t            Valid_F1 : 0.894734654858892\t            Valid_precision : 1.0\t            Valid_recall : 0.8096499436680473\n","[1][88] f1[88] 0.894734654858892 (0.8845784105816327)\n","Loss 0.6337461643146746 : \t            Valid_acc : 0.8103461431069022\t            Valid_F1 : 0.8951033065471602\t            Valid_precision : 1.0\t            Valid_recall : 0.8103461431069022\n","[1][89] f1[89] 0.8951033065471602 (0.8845784105816327)\n","Loss 0.5762457192847223 : \t            Valid_acc : 0.8291374221714238\t            Valid_F1 : 0.9064891479743966\t            Valid_precision : 1.0\t            Valid_recall : 0.8291374221714238\n","[1][90] f1[90] 0.9064891479743966 (0.8845784105816327)\n","Loss 0.5198313593864441 : \t            Valid_acc : 0.8458612416796671\t            Valid_F1 : 0.9163831164132338\t            Valid_precision : 1.0\t            Valid_recall : 0.8458612416796671\n","[1][91] f1[91] 0.9163831164132338 (0.8845784105816327)\n","Loss 0.5063510564240542 : \t            Valid_acc : 0.8533427522145656\t            Valid_F1 : 0.9207218383678125\t            Valid_precision : 1.0\t            Valid_recall : 0.8533427522145656\n","[1][92] f1[92] 0.9207218383678125 (0.8845784105816327)\n","Loss 0.5681011586478262 : \t            Valid_acc : 0.8258054981695696\t            Valid_F1 : 0.9045203221434369\t            Valid_precision : 1.0\t            Valid_recall : 0.8258054981695696\n","[1][93] f1[93] 0.9045203221434369 (0.8845784105816327)\n","Loss 0.608416163560116 : \t            Valid_acc : 0.8206193391329063\t            Valid_F1 : 0.9013701326949674\t            Valid_precision : 1.0\t            Valid_recall : 0.8206193391329063\n","[1][94] f1[94] 0.9013701326949674 (0.8845784105816327)\n","Loss 0.5847997981490511 : \t            Valid_acc : 0.8153466119890077\t            Valid_F1 : 0.8982045149819193\t            Valid_precision : 1.0\t            Valid_recall : 0.8153466119890077\n","[1][95] f1[95] 0.8982045149819193 (0.8845784105816327)\n","Loss 0.5952351088776733 : \t            Valid_acc : 0.829934090855613\t            Valid_F1 : 0.9069446297981488\t            Valid_precision : 1.0\t            Valid_recall : 0.829934090855613\n","[1][96] f1[96] 0.9069446297981488 (0.8845784105816327)\n","Loss 0.6111133274706927 : \t            Valid_acc : 0.8092144675042174\t            Valid_F1 : 0.8944598676493484\t            Valid_precision : 1.0\t            Valid_recall : 0.8092144675042174\n","[1][97] f1[97] 0.8944598676493484 (0.8845784105816327)\n","Loss 0.551834245522817 : \t            Valid_acc : 0.8303401098983111\t            Valid_F1 : 0.9072069195924602\t            Valid_precision : 1.0\t            Valid_recall : 0.8303401098983111\n","[1][98] f1[98] 0.9072069195924602 (0.8845784105816327)\n","Loss 0.5738121989098462 : \t            Valid_acc : 0.8250024264844963\t            Valid_F1 : 0.9040067231258901\t            Valid_precision : 1.0\t            Valid_recall : 0.8250024264844963\n","[1][99] f1[99] 0.9040067231258901 (0.8845784105816327)\n","Worst f1 0.8845784105816327 with candidates [621, 13890, 0]\n","candidates [ 3005 10606   819  2878  5376  8559  4588  7484 28580  1970  6234  1886\n"," 13994   987 12293  7500  6354  4882 29182  2520 13085 25315  5465 11160\n","   992  9920  1974  7380  1591 11330 10959 16427 15227  1951  1972  2005\n","  2873 19074 20205 18766 11510  3699 20553 12858  3917  4395 20393 20895\n"," 16571  3539  4848  1339  5238 22801  4725  8863 11324  5007  5664 10089\n"," 17750 21418  2867  5527 24382  9932 13064 19624  1674  1950 21241  8351\n","  3306  3174  5132  2684 26454  7499  3402  3275  8264  6846 28037 17981\n"," 13228  6623 15302 24299  7010 19031  9992  6684  1524  4338  7670  3745\n","  3466  3823  5977  3857]\n","Loss 0.6981841903744321 : \t            Valid_acc : 0.8056365006143867\t            Valid_F1 : 0.8921866546139207\t            Valid_precision : 1.0\t            Valid_recall : 0.8056365006143867\n","[2][0] f1[0] 0.8921866546139207 (0.8845784105816327)\n","Loss 0.7354446626973875 : \t            Valid_acc : 0.7993740445572479\t            Valid_F1 : 0.8882757225542064\t            Valid_precision : 1.0\t            Valid_recall : 0.7993740445572479\n","[2][1] f1[1] 0.8882757225542064 (0.8845784105816327)\n","Loss 0.6933703657352563 : \t            Valid_acc : 0.80302905767879\t            Valid_F1 : 0.8905580665543518\t            Valid_precision : 1.0\t            Valid_recall : 0.80302905767879\n","[2][2] f1[2] 0.8905580665543518 (0.8845784105816327)\n","Loss 0.6297384216026827 : \t            Valid_acc : 0.8161433241437375\t            Valid_F1 : 0.8986317941538768\t            Valid_precision : 1.0\t            Valid_recall : 0.8161433241437375\n","[2][3] f1[3] 0.8986317941538768 (0.8845784105816327)\n","Loss 0.6603598890431 : \t            Valid_acc : 0.8030913227596737\t            Valid_F1 : 0.890642574276628\t            Valid_precision : 1.0\t            Valid_recall : 0.8030913227596737\n","[2][4] f1[4] 0.890642574276628 (0.8845784105816327)\n","Loss 0.6894142401940895 : \t            Valid_acc : 0.8045018442103992\t            Valid_F1 : 0.8915102682213811\t            Valid_precision : 1.0\t            Valid_recall : 0.8045018442103992\n","[2][5] f1[5] 0.8915102682213811 (0.8845784105816327)\n","Loss 0.5941228315685735 : \t            Valid_acc : 0.8229471045952396\t            Valid_F1 : 0.9027226089004432\t            Valid_precision : 1.0\t            Valid_recall : 0.8229471045952396\n","[2][6] f1[6] 0.9027226089004432 (0.8845784105816327)\n","Loss 0.6857131678949703 : \t            Valid_acc : 0.7961500777409483\t            Valid_F1 : 0.8863608013331385\t            Valid_precision : 1.0\t            Valid_recall : 0.7961500777409483\n","[2][7] f1[7] 0.8863608013331385 (0.8845784105816327)\n","Loss 0.708303715243484 : \t            Valid_acc : 0.7990507790955079\t            Valid_F1 : 0.8880968799862302\t            Valid_precision : 1.0\t            Valid_recall : 0.7990507790955079\n","[2][8] f1[8] 0.8880968799862302 (0.8845784105816327)\n","Loss 0.7900700293707125 : \t            Valid_acc : 0.7749051243713642\t            Valid_F1 : 0.8730100563796608\t            Valid_precision : 1.0\t            Valid_recall : 0.7749051243713642\n","[2][9] f1[9] 0.8730100563796608 (0.8730100563796608)\n","Loss 0.7424251784880956 : \t            Valid_acc : 0.7934157262056003\t            Valid_F1 : 0.8846446892892995\t            Valid_precision : 1.0\t            Valid_recall : 0.7934157262056003\n","[2][10] f1[10] 0.8846446892892995 (0.8730100563796608)\n","Loss 0.7190847419428102 : \t            Valid_acc : 0.7976651544061188\t            Valid_F1 : 0.8872968040288215\t            Valid_precision : 1.0\t            Valid_recall : 0.7976651544061188\n","[2][11] f1[11] 0.8872968040288215 (0.8730100563796608)\n","Loss 0.7265427798935862 : \t            Valid_acc : 0.7878266695661078\t            Valid_F1 : 0.8811539291370192\t            Valid_precision : 1.0\t            Valid_recall : 0.7878266695661078\n","[2][12] f1[12] 0.8811539291370192 (0.8730100563796608)\n","Loss 0.7623886606006911 : \t            Valid_acc : 0.7849883465822833\t            Valid_F1 : 0.8793288526565793\t            Valid_precision : 1.0\t            Valid_recall : 0.7849883465822833\n","[2][13] f1[13] 0.8793288526565793 (0.8730100563796608)\n","Loss 0.6903423368930817 : \t            Valid_acc : 0.7977858376757416\t            Valid_F1 : 0.8873755238311898\t            Valid_precision : 1.0\t            Valid_recall : 0.7977858376757416\n","[2][14] f1[14] 0.8873755238311898 (0.8730100563796608)\n","Loss 0.7614211914214221 : \t            Valid_acc : 0.7726761142258871\t            Valid_F1 : 0.8716332874567428\t            Valid_precision : 1.0\t            Valid_recall : 0.7726761142258871\n","[2][15] f1[15] 0.8716332874567428 (0.8716332874567428)\n","Loss 0.585723360379537 : \t            Valid_acc : 0.81890569658198\t            Valid_F1 : 0.9003099519526649\t            Valid_precision : 1.0\t            Valid_recall : 0.81890569658198\n","[2][16] f1[16] 0.9003099519526649 (0.8716332874567428)\n","Loss 0.6071671685486129 : \t            Valid_acc : 0.8266237070857508\t            Valid_F1 : 0.9049256503539425\t            Valid_precision : 1.0\t            Valid_recall : 0.8266237070857508\n","[2][17] f1[17] 0.9049256503539425 (0.8716332874567428)\n","Loss 0.7045768237475193 : \t            Valid_acc : 0.8023433458773397\t            Valid_F1 : 0.8901454882193869\t            Valid_precision : 1.0\t            Valid_recall : 0.8023433458773397\n","[2][18] f1[18] 0.8901454882193869 (0.8716332874567428)\n","Loss 0.6201909306374463 : \t            Valid_acc : 0.8132535929347109\t            Valid_F1 : 0.8968659974411952\t            Valid_precision : 1.0\t            Valid_recall : 0.8132535929347109\n","[2][19] f1[19] 0.8968659974411952 (0.8716332874567428)\n","Loss 0.7053110651446112 : \t            Valid_acc : 0.8017622800799264\t            Valid_F1 : 0.8897420543835487\t            Valid_precision : 1.0\t            Valid_recall : 0.8017622800799264\n","[2][20] f1[20] 0.8897420543835487 (0.8716332874567428)\n","Loss 0.7557589208537882 : \t            Valid_acc : 0.7840109493258681\t            Valid_F1 : 0.878775238040624\t            Valid_precision : 1.0\t            Valid_recall : 0.7840109493258681\n","[2][21] f1[21] 0.878775238040624 (0.8716332874567428)\n","Loss 0.6248058861855305 : \t            Valid_acc : 0.8061777612263027\t            Valid_F1 : 0.8924885952124011\t            Valid_precision : 1.0\t            Valid_recall : 0.8061777612263027\n","[2][22] f1[22] 0.8924885952124011 (0.8716332874567428)\n","Loss 0.7870801276329792 : \t            Valid_acc : 0.7809248018792849\t            Valid_F1 : 0.8768059927996321\t            Valid_precision : 1.0\t            Valid_recall : 0.7809248018792849\n","[2][23] f1[23] 0.8768059927996321 (0.8716332874567428)\n","Loss 0.7617116538864194 : \t            Valid_acc : 0.7830806423136415\t            Valid_F1 : 0.8781662855728376\t            Valid_precision : 1.0\t            Valid_recall : 0.7830806423136415\n","[2][24] f1[24] 0.8781662855728376 (0.8716332874567428)\n","Loss 0.7410891498580123 : \t            Valid_acc : 0.7884349015879462\t            Valid_F1 : 0.8815025005489942\t            Valid_precision : 1.0\t            Valid_recall : 0.7884349015879462\n","[2][25] f1[25] 0.8815025005489942 (0.8716332874567428)\n","Loss 0.6830410948305419 : \t            Valid_acc : 0.8050570678049619\t            Valid_F1 : 0.8918084307710729\t            Valid_precision : 1.0\t            Valid_recall : 0.8050570678049619\n","[2][26] f1[26] 0.8918084307710729 (0.8716332874567428)\n","Loss 0.6657472708911607 : \t            Valid_acc : 0.8054723414700463\t            Valid_F1 : 0.8921072452337364\t            Valid_precision : 1.0\t            Valid_recall : 0.8054723414700463\n","[2][27] f1[27] 0.8921072452337364 (0.8716332874567428)\n","Loss 0.6805931194262071 : \t            Valid_acc : 0.8014203764426138\t            Valid_F1 : 0.8896342329569902\t            Valid_precision : 1.0\t            Valid_recall : 0.8014203764426138\n","[2][28] f1[28] 0.8896342329569902 (0.8716332874567428)\n","Loss 0.7193631407889453 : \t            Valid_acc : 0.7948539962689348\t            Valid_F1 : 0.8855194396294782\t            Valid_precision : 1.0\t            Valid_recall : 0.7948539962689348\n","[2][29] f1[29] 0.8855194396294782 (0.8716332874567428)\n","Loss 0.692570760846138 : \t            Valid_acc : 0.7963357591345863\t            Valid_F1 : 0.8864580684068633\t            Valid_precision : 1.0\t            Valid_recall : 0.7963357591345863\n","[2][30] f1[30] 0.8864580684068633 (0.8716332874567428)\n","Loss 0.7156228748234835 : \t            Valid_acc : 0.7908491856785413\t            Valid_F1 : 0.8830653877703972\t            Valid_precision : 1.0\t            Valid_recall : 0.7908491856785413\n","[2][31] f1[31] 0.8830653877703972 (0.8716332874567428)\n","Loss 0.73049585295446 : \t            Valid_acc : 0.7902570209072752\t            Valid_F1 : 0.8827092542780494\t            Valid_precision : 1.0\t            Valid_recall : 0.7902570209072752\n","[2][32] f1[32] 0.8827092542780494 (0.8716332874567428)\n","Loss 0.7116999133969798 : \t            Valid_acc : 0.7994065900380934\t            Valid_F1 : 0.888321499170939\t            Valid_precision : 1.0\t            Valid_recall : 0.7994065900380934\n","[2][33] f1[33] 0.888321499170939 (0.8716332874567428)\n","Loss 0.7052461748773401 : \t            Valid_acc : 0.8071155309885008\t            Valid_F1 : 0.893024528310375\t            Valid_precision : 1.0\t            Valid_recall : 0.8071155309885008\n","[2][34] f1[34] 0.893024528310375 (0.8716332874567428)\n","Loss 0.6547934196212075 : \t            Valid_acc : 0.810309042711511\t            Valid_F1 : 0.8950288139618608\t            Valid_precision : 1.0\t            Valid_recall : 0.810309042711511\n","[2][35] f1[35] 0.8950288139618608 (0.8716332874567428)\n","Loss 0.7200630113030925 : \t            Valid_acc : 0.7948784221320067\t            Valid_F1 : 0.8855447957952992\t            Valid_precision : 1.0\t            Valid_recall : 0.7948784221320067\n","[2][36] f1[36] 0.8855447957952992 (0.8716332874567428)\n","Loss 0.6758861198569789 : \t            Valid_acc : 0.8096976297689216\t            Valid_F1 : 0.8947111068734313\t            Valid_precision : 1.0\t            Valid_recall : 0.8096976297689216\n","[2][37] f1[37] 0.8947111068734313 (0.8716332874567428)\n","Loss 0.7671933147040281 : \t            Valid_acc : 0.791605705851751\t            Valid_F1 : 0.8835079203035388\t            Valid_precision : 1.0\t            Valid_recall : 0.791605705851751\n","[2][38] f1[38] 0.8835079203035388 (0.8716332874567428)\n","Loss 0.7950260941729401 : \t            Valid_acc : 0.7768408255853421\t            Valid_F1 : 0.874247221279442\t            Valid_precision : 1.0\t            Valid_recall : 0.7768408255853421\n","[2][39] f1[39] 0.874247221279442 (0.8716332874567428)\n","Loss 0.6940713574488958 : \t            Valid_acc : 0.8046239654428168\t            Valid_F1 : 0.8915786849385103\t            Valid_precision : 1.0\t            Valid_recall : 0.8046239654428168\n","[2][40] f1[40] 0.8915786849385103 (0.8716332874567428)\n","Loss 0.7029542656558933 : \t            Valid_acc : 0.8016273838919709\t            Valid_F1 : 0.8897313895950429\t            Valid_precision : 1.0\t            Valid_recall : 0.8016273838919709\n","[2][41] f1[41] 0.8897313895950429 (0.8716332874567428)\n","Loss 0.7137912498279051 : \t            Valid_acc : 0.7931944851280948\t            Valid_F1 : 0.8844904426842499\t            Valid_precision : 1.0\t            Valid_recall : 0.7931944851280948\n","[2][42] f1[42] 0.8844904426842499 (0.8716332874567428)\n","Loss 0.6605392017147758 : \t            Valid_acc : 0.8070758270417908\t            Valid_F1 : 0.8930690302834571\t            Valid_precision : 1.0\t            Valid_recall : 0.8070758270417908\n","[2][43] f1[43] 0.8930690302834571 (0.8716332874567428)\n","Loss 0.6827726486054334 : \t            Valid_acc : 0.8087751691838273\t            Valid_F1 : 0.8941605159182966\t            Valid_precision : 1.0\t            Valid_recall : 0.8087751691838273\n","[2][44] f1[44] 0.8941605159182966 (0.8716332874567428)\n","Loss 0.6335332851969835 : \t            Valid_acc : 0.8172746375295226\t            Valid_F1 : 0.8992774963440748\t            Valid_precision : 1.0\t            Valid_recall : 0.8172746375295226\n","[2][45] f1[45] 0.8992774963440748 (0.8716332874567428)\n","Loss 0.6648069006023984 : \t            Valid_acc : 0.8069473271056339\t            Valid_F1 : 0.8930334773208325\t            Valid_precision : 1.0\t            Valid_recall : 0.8069473271056339\n","[2][46] f1[46] 0.8930334773208325 (0.8716332874567428)\n","Loss 0.6276864222053326 : \t            Valid_acc : 0.8186053470797875\t            Valid_F1 : 0.8999866062729797\t            Valid_precision : 1.0\t            Valid_recall : 0.8186053470797875\n","[2][47] f1[47] 0.8999866062729797 (0.8716332874567428)\n","Loss 0.7346633437908057 : \t            Valid_acc : 0.7980313570454198\t            Valid_F1 : 0.8874222691208272\t            Valid_precision : 1.0\t            Valid_recall : 0.7980313570454198\n","[2][48] f1[48] 0.8874222691208272 (0.8716332874567428)\n","Loss 0.6892044598406012 : \t            Valid_acc : 0.8026402206850881\t            Valid_F1 : 0.89035648631276\t            Valid_precision : 1.0\t            Valid_recall : 0.8026402206850881\n","[2][49] f1[49] 0.89035648631276 (0.8716332874567428)\n","Loss 0.6544910687388796 : \t            Valid_acc : 0.8105103727485224\t            Valid_F1 : 0.8950774002071759\t            Valid_precision : 1.0\t            Valid_recall : 0.8105103727485224\n","[2][50] f1[50] 0.8950774002071759 (0.8716332874567428)\n","Loss 0.7504374886100943 : \t            Valid_acc : 0.793851403009389\t            Valid_F1 : 0.8849110340291184\t            Valid_precision : 1.0\t            Valid_recall : 0.793851403009389\n","[2][51] f1[51] 0.8849110340291184 (0.8716332874567428)\n","Loss 0.6034734872254458 : \t            Valid_acc : 0.8107087864351451\t            Valid_F1 : 0.8953119374498851\t            Valid_precision : 1.0\t            Valid_recall : 0.8107087864351451\n","[2][52] f1[52] 0.8953119374498851 (0.8716332874567428)\n","Loss 0.6783097833395004 : \t            Valid_acc : 0.8023618685919734\t            Valid_F1 : 0.8901914201512526\t            Valid_precision : 1.0\t            Valid_recall : 0.8023618685919734\n","[2][53] f1[53] 0.8901914201512526 (0.8716332874567428)\n","Loss 0.7295566016074383 : \t            Valid_acc : 0.785209456423154\t            Valid_F1 : 0.8795771193996837\t            Valid_precision : 1.0\t            Valid_recall : 0.785209456423154\n","[2][54] f1[54] 0.8795771193996837 (0.8716332874567428)\n","Loss 0.6721138344569639 : \t            Valid_acc : 0.7996910777601622\t            Valid_F1 : 0.8885606739295746\t            Valid_precision : 1.0\t            Valid_recall : 0.7996910777601622\n","[2][55] f1[55] 0.8885606739295746 (0.8716332874567428)\n","Loss 0.7227602479132739 : \t            Valid_acc : 0.8016586842012831\t            Valid_F1 : 0.8897087336847724\t            Valid_precision : 1.0\t            Valid_recall : 0.8016586842012831\n","[2][56] f1[56] 0.8897087336847724 (0.8716332874567428)\n","Loss 0.7461789670315656 : \t            Valid_acc : 0.7887422114435376\t            Valid_F1 : 0.8817180138569322\t            Valid_precision : 1.0\t            Valid_recall : 0.7887422114435376\n","[2][57] f1[57] 0.8817180138569322 (0.8716332874567428)\n","Loss 0.7773574676477548 : \t            Valid_acc : 0.7886083129155085\t            Valid_F1 : 0.8815864660766605\t            Valid_precision : 1.0\t            Valid_recall : 0.7886083129155085\n","[2][58] f1[58] 0.8815864660766605 (0.8716332874567428)\n","Loss 0.7124084527745391 : \t            Valid_acc : 0.7924454163911587\t            Valid_F1 : 0.8840569172741667\t            Valid_precision : 1.0\t            Valid_recall : 0.7924454163911587\n","[2][59] f1[59] 0.8840569172741667 (0.8716332874567428)\n","Loss 0.7873333087473204 : \t            Valid_acc : 0.7725538676215786\t            Valid_F1 : 0.8715388855882316\t            Valid_precision : 1.0\t            Valid_recall : 0.7725538676215786\n","[2][60] f1[60] 0.8715388855882316 (0.8715388855882316)\n","Loss 0.6543571605826869 : \t            Valid_acc : 0.8007692333360689\t            Valid_F1 : 0.8892604952495516\t            Valid_precision : 1.0\t            Valid_recall : 0.8007692333360689\n","[2][61] f1[61] 0.8892604952495516 (0.8715388855882316)\n","Loss 0.5447977880636851 : \t            Valid_acc : 0.8454637750031092\t            Valid_F1 : 0.9160692093558453\t            Valid_precision : 1.0\t            Valid_recall : 0.8454637750031092\n","[2][62] f1[62] 0.9160692093558453 (0.8715388855882316)\n","Loss 0.6404206901788712 : \t            Valid_acc : 0.8051789531773874\t            Valid_F1 : 0.8919097524768212\t            Valid_precision : 1.0\t            Valid_recall : 0.8051789531773874\n","[2][63] f1[63] 0.8919097524768212 (0.8715388855882316)\n","Loss 0.5832053594516985 : \t            Valid_acc : 0.826645255963765\t            Valid_F1 : 0.9049419868011557\t            Valid_precision : 1.0\t            Valid_recall : 0.826645255963765\n","[2][64] f1[64] 0.9049419868011557 (0.8715388855882316)\n","Loss 0.6404846933755007 : \t            Valid_acc : 0.8127329804095249\t            Valid_F1 : 0.8964840456823732\t            Valid_precision : 1.0\t            Valid_recall : 0.8127329804095249\n","[2][65] f1[65] 0.8964840456823732 (0.8715388855882316)\n","Loss 0.7928290326486934 : \t            Valid_acc : 0.7635651843201592\t            Valid_F1 : 0.8657260955846291\t            Valid_precision : 1.0\t            Valid_recall : 0.7635651843201592\n","[2][66] f1[66] 0.8657260955846291 (0.8657260955846291)\n","Loss 0.6948160217566923 : \t            Valid_acc : 0.7980507255205878\t            Valid_F1 : 0.8874995586346579\t            Valid_precision : 1.0\t            Valid_recall : 0.7980507255205878\n","[2][67] f1[67] 0.8874995586346579 (0.8657260955846291)\n","Loss 0.666670122832963 : \t            Valid_acc : 0.8140440141870546\t            Valid_F1 : 0.8973272699315842\t            Valid_precision : 1.0\t            Valid_recall : 0.8140440141870546\n","[2][68] f1[68] 0.8973272699315842 (0.8657260955846291)\n","Loss 0.6691332364624197 : \t            Valid_acc : 0.7981573840276237\t            Valid_F1 : 0.8876296994085875\t            Valid_precision : 1.0\t            Valid_recall : 0.7981573840276237\n","[2][69] f1[69] 0.8876296994085875 (0.8657260955846291)\n","Loss 0.8218748348228859 : \t            Valid_acc : 0.7643441107615401\t            Valid_F1 : 0.8662231860094548\t            Valid_precision : 1.0\t            Valid_recall : 0.7643441107615401\n","[2][70] f1[70] 0.8662231860094548 (0.8657260955846291)\n","Loss 0.6438387483358383 : \t            Valid_acc : 0.8114557955606772\t            Valid_F1 : 0.8956591706021982\t            Valid_precision : 1.0\t            Valid_recall : 0.8114557955606772\n","[2][71] f1[71] 0.8956591706021982 (0.8657260955846291)\n","Loss 0.7854517820206556 : \t            Valid_acc : 0.7902215919202873\t            Valid_F1 : 0.8826166884767463\t            Valid_precision : 1.0\t            Valid_recall : 0.7902215919202873\n","[2][72] f1[72] 0.8826166884767463 (0.8657260955846291)\n","Loss 0.7301720981345032 : \t            Valid_acc : 0.8017275537443834\t            Valid_F1 : 0.8897710924399928\t            Valid_precision : 1.0\t            Valid_recall : 0.8017275537443834\n","[2][73] f1[73] 0.8897710924399928 (0.8657260955846291)\n","Loss 0.6847309068296895 : \t            Valid_acc : 0.8087879364215063\t            Valid_F1 : 0.8940858879183124\t            Valid_precision : 1.0\t            Valid_recall : 0.8087879364215063\n","[2][74] f1[74] 0.8940858879183124 (0.8657260955846291)\n","Loss 0.7278630281939651 : \t            Valid_acc : 0.7947111493146168\t            Valid_F1 : 0.885452695560869\t            Valid_precision : 1.0\t            Valid_recall : 0.7947111493146168\n","[2][75] f1[75] 0.885452695560869 (0.8657260955846291)\n","Loss 0.6597391245040026 : \t            Valid_acc : 0.8032611128333834\t            Valid_F1 : 0.8907583675072832\t            Valid_precision : 1.0\t            Valid_recall : 0.8032611128333834\n","[2][76] f1[76] 0.8907583675072832 (0.8657260955846291)\n","Loss 0.7377210074301922 : \t            Valid_acc : 0.7949536636216928\t            Valid_F1 : 0.8855690698638562\t            Valid_precision : 1.0\t            Valid_recall : 0.7949536636216928\n","[2][77] f1[77] 0.8855690698638562 (0.8657260955846291)\n","Loss 0.7183164881937432 : \t            Valid_acc : 0.7999741551983848\t            Valid_F1 : 0.8887083909852753\t            Valid_precision : 1.0\t            Valid_recall : 0.7999741551983848\n","[2][78] f1[78] 0.8887083909852753 (0.8657260955846291)\n","Loss 0.6848105065750353 : \t            Valid_acc : 0.8017099646231043\t            Valid_F1 : 0.889734543722761\t            Valid_precision : 1.0\t            Valid_recall : 0.8017099646231043\n","[2][79] f1[79] 0.889734543722761 (0.8657260955846291)\n","Loss 0.6403866053530665 : \t            Valid_acc : 0.8065328607694039\t            Valid_F1 : 0.8927436333534408\t            Valid_precision : 1.0\t            Valid_recall : 0.8065328607694039\n","[2][80] f1[80] 0.8927436333534408 (0.8657260955846291)\n","Loss 0.7736447421890317 : \t            Valid_acc : 0.7810232435069112\t            Valid_F1 : 0.8768302059184393\t            Valid_precision : 1.0\t            Valid_recall : 0.7810232435069112\n","[2][81] f1[81] 0.8768302059184393 (0.8657260955846291)\n","Loss 0.642886733918479 : \t            Valid_acc : 0.8106161311309676\t            Valid_F1 : 0.8952503999031467\t            Valid_precision : 1.0\t            Valid_recall : 0.8106161311309676\n","[2][82] f1[82] 0.8952503999031467 (0.8657260955846291)\n","Loss 0.7220537107099186 : \t            Valid_acc : 0.7940578452449845\t            Valid_F1 : 0.8850146662802246\t            Valid_precision : 1.0\t            Valid_recall : 0.7940578452449845\n","[2][83] f1[83] 0.8850146662802246 (0.8657260955846291)\n","Loss 0.6662561685749979 : \t            Valid_acc : 0.8106551532617767\t            Valid_F1 : 0.8952504011850043\t            Valid_precision : 1.0\t            Valid_recall : 0.8106551532617767\n","[2][84] f1[84] 0.8952504011850043 (0.8657260955846291)\n","Loss 0.7239981505906943 : \t            Valid_acc : 0.7906492814949859\t            Valid_F1 : 0.8829555265593765\t            Valid_precision : 1.0\t            Valid_recall : 0.7906492814949859\n","[2][85] f1[85] 0.8829555265593765 (0.8657260955846291)\n","Loss 0.6798467803182024 : \t            Valid_acc : 0.8023399373387546\t            Valid_F1 : 0.890180603056878\t            Valid_precision : 1.0\t            Valid_recall : 0.8023399373387546\n","[2][86] f1[86] 0.890180603056878 (0.8657260955846291)\n","Loss 0.6752288829196583 : \t            Valid_acc : 0.7972756624720502\t            Valid_F1 : 0.8870779025355098\t            Valid_precision : 1.0\t            Valid_recall : 0.7972756624720502\n","[2][87] f1[87] 0.8870779025355098 (0.8657260955846291)\n","Loss 0.6222922503948212 : \t            Valid_acc : 0.808836583814169\t            Valid_F1 : 0.8941757152341636\t            Valid_precision : 1.0\t            Valid_recall : 0.808836583814169\n","[2][88] f1[88] 0.8941757152341636 (0.8657260955846291)\n","Loss 0.6773600546699582 : \t            Valid_acc : 0.8066574688052082\t            Valid_F1 : 0.8927918267766306\t            Valid_precision : 1.0\t            Valid_recall : 0.8066574688052082\n","[2][89] f1[89] 0.8927918267766306 (0.8657260955846291)\n","Loss 0.7427057542584159 : \t            Valid_acc : 0.7927108445938897\t            Valid_F1 : 0.8841777737309922\t            Valid_precision : 1.0\t            Valid_recall : 0.7927108445938897\n","[2][90] f1[90] 0.8841777737309922 (0.8657260955846291)\n","Loss 0.6441827127427766 : \t            Valid_acc : 0.8133286814869144\t            Valid_F1 : 0.8968953071141123\t            Valid_precision : 1.0\t            Valid_recall : 0.8133286814869144\n","[2][91] f1[91] 0.8968953071141123 (0.8657260955846291)\n","Loss 0.594850792126222 : \t            Valid_acc : 0.8235475628373199\t            Valid_F1 : 0.903036974267902\t            Valid_precision : 1.0\t            Valid_recall : 0.8235475628373199\n","[2][92] f1[92] 0.903036974267902 (0.8657260955846291)\n","Loss 0.6313039059891845 : \t            Valid_acc : 0.8103650668548937\t            Valid_F1 : 0.8950277487924493\t            Valid_precision : 1.0\t            Valid_recall : 0.8103650668548937\n","[2][93] f1[93] 0.8950277487924493 (0.8657260955846291)\n","Loss 0.6879151305465987 : \t            Valid_acc : 0.8007593119919205\t            Valid_F1 : 0.8891359945524688\t            Valid_precision : 1.0\t            Valid_recall : 0.8007593119919205\n","[2][94] f1[94] 0.8891359945524688 (0.8657260955846291)\n","Loss 0.6954882239753549 : \t            Valid_acc : 0.7995575989561096\t            Valid_F1 : 0.8884295906825652\t            Valid_precision : 1.0\t            Valid_recall : 0.7995575989561096\n","[2][95] f1[95] 0.8884295906825652 (0.8657260955846291)\n","Loss 0.6719852033438105 : \t            Valid_acc : 0.8030548341355054\t            Valid_F1 : 0.8906137521911\t            Valid_precision : 1.0\t            Valid_recall : 0.8030548341355054\n","[2][96] f1[96] 0.8906137521911 (0.8657260955846291)\n","Loss 0.7752708729469415 : \t            Valid_acc : 0.7697386758267364\t            Valid_F1 : 0.8697104803518668\t            Valid_precision : 1.0\t            Valid_recall : 0.7697386758267364\n","[2][97] f1[97] 0.8697104803518668 (0.8657260955846291)\n","Loss 0.6548377298044435 : \t            Valid_acc : 0.8071506556244515\t            Valid_F1 : 0.893168513132097\t            Valid_precision : 1.0\t            Valid_recall : 0.8071506556244515\n","[2][98] f1[98] 0.893168513132097 (0.8657260955846291)\n","Loss 0.7872999355648503 : \t            Valid_acc : 0.7803246509605566\t            Valid_F1 : 0.8763624374021983\t            Valid_precision : 1.0\t            Valid_recall : 0.7803246509605566\n","[2][99] f1[99] 0.8763624374021983 (0.8657260955846291)\n","Worst f1 0.8657260955846291 with candidates [621, 13890, 13064]\n"]}]},{"cell_type":"code","source":["#print(tokenizer.decode([621, 4865, 21241]))\n","#print(tokenizer.decode([621, 13890, 21241]))# Loss => unless communist normativ\n","#print(tokenizer.decode([621, 13890, 13064]))# Accuracy => unless communist tolerate\n","print(tokenizer.decode([621, 13890, 13064]))# F1 => unless communist tolerate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdhC5LNWQk_x","executionInfo":{"status":"ok","timestamp":1657561454203,"user_tz":-120,"elapsed":214,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"f1f2c6c6-5b6f-4df6-be42-701eec31059a"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["unless communist tolerate\n"]}]},{"cell_type":"code","source":["\"\"\"\n","extracted_grads = []\n","model.eval()\n","model.to(device)\n","loss_obtained = get_loss_and_metrics(model, dataloader, device)\n","print(f'loss_obtained {loss_obtained}')\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"S4JCX2TmE_yA","executionInfo":{"status":"ok","timestamp":1657561348984,"user_tz":-120,"elapsed":26,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"d33af7f1-cd4a-405c-d54e-5830e7d19a83"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nextracted_grads = []\\nmodel.eval()\\nmodel.to(device)\\nloss_obtained = get_loss_and_metrics(model, dataloader, device)\\nprint(f'loss_obtained {loss_obtained}')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["\"\"\"\n","extracted_grads = []\n","\n","# get initial loss for the trigger\n","model.zero_grad()\n","loss = get_loss(model, BATCH_SIZE, trigger_tokens, target_tokens, device)\n","best_loss = loss\n","counter = 0\n","end_iter = False\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"-nddZPP1B1RJ","executionInfo":{"status":"ok","timestamp":1657561348984,"user_tz":-120,"elapsed":25,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"8516e1bb-8907-4ce1-a1bc-76ddc07c753e"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nextracted_grads = []\\n\\n# get initial loss for the trigger\\nmodel.zero_grad()\\nloss = get_loss(model, BATCH_SIZE, trigger_tokens, target_tokens, device)\\nbest_loss = loss\\ncounter = 0\\nend_iter = False\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["\"\"\"\n","del extracted_grads\n","del dataloader\n","del model\n","del input_ids\n","del attention_masks\n","del labels\n","del loss_obtained\n","del dataset\n","\"\"\""],"metadata":{"id":"3IWgPUFKkRy1","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1657561348985,"user_tz":-120,"elapsed":25,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"5637ca9d-aee9-484b-cb5a-28d4c2622ba9"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndel extracted_grads\\ndel dataloader\\ndel model\\ndel input_ids\\ndel attention_masks\\ndel labels\\ndel loss_obtained\\ndel dataset\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["\"\"\"import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"vDMAFktYISWA","executionInfo":{"status":"ok","timestamp":1657561348985,"user_tz":-120,"elapsed":24,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"ab7e3748-4f0f-4e3e-d3cc-33b61896b89d"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'import torch, gc\\ngc.collect()\\ntorch.cuda.empty_cache()\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["len(extracted_grads)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4QJtyr7K8oc","executionInfo":{"status":"ok","timestamp":1657561348986,"user_tz":-120,"elapsed":25,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"74b1ca02-46b3-45b5-d3e7-eea529b9e189"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["input_ids[0][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7cGz0zGLVeL","executionInfo":{"status":"ok","timestamp":1657561348987,"user_tz":-120,"elapsed":23,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"5800fa8a-6c50-4c02-d4d3-2bab23e52c5e"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(621)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":[""],"metadata":{"id":"y5TYKJ9aUK6o","executionInfo":{"status":"ok","timestamp":1657561348987,"user_tz":-120,"elapsed":22,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":38,"outputs":[]}]}