{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AdversarialAttack_LegalBert.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOv3cR3DVQVk9cFlOjHEIOQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Adversarial attacks against Legal-BERT Model (BertForSequenceClassification)"],"metadata":{"id":"MXqml7sZuRKJ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Vgl8t7lyuGJa","executionInfo":{"status":"ok","timestamp":1657498279094,"user_tz":-120,"elapsed":17,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"outputs":[],"source":["# Global variables\n","\n","BATCH_SIZE = 32\n","MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n","EPOCHS = 3\n","EMBEDDING_SIZE = 512\n","NUM_CLASSES = 2\n","VOCABULARY_SIZE = 30522\n","NUM_TOKENS = 3\n"]},{"cell_type":"markdown","source":["### Installation of packages"],"metadata":{"id":"XCxFkLyZuvz0"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install torch-lr-finder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3e7ptYOuwQl","executionInfo":{"status":"ok","timestamp":1657498285342,"user_tz":-120,"elapsed":6262,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"f9b61326-c859-4d14-dad4-d56127e47d3a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.21.6)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.11.0+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.64.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.1.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.4.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n"]}]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"yfPJufE5vMkb"}},{"cell_type":"code","source":["import torch\n","import os\n","from transformers import BertTokenizer\n","from google.colab import drive\n","from torch.utils.data import TensorDataset, random_split\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import gc\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from copy import deepcopy"],"metadata":{"id":"aPfzDo8hvPBZ","executionInfo":{"status":"ok","timestamp":1657498288493,"user_tz":-120,"elapsed":3160,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Device"],"metadata":{"id":"_oG87aJ3vWxK"}},{"cell_type":"code","source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQKxA_5MvV0w","executionInfo":{"status":"ok","timestamp":1657498288498,"user_tz":-120,"elapsed":39,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"2875e3ad-fc1e-4d4e-b209-fa0ba8f74b7e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"markdown","source":["### Reading dataset"],"metadata":{"id":"9PTbIu43vb0-"}},{"cell_type":"code","source":["# Mount drive to have access to your files\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/\"Colab Notebooks\"/DefenseAdvAttacks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2dsmYWRXvcPc","executionInfo":{"status":"ok","timestamp":1657498289820,"user_tz":-120,"elapsed":1350,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"bbfe225a-3b1c-419d-a914-13e12e4338a8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/DefenseAdvAttacks\n"]}]},{"cell_type":"code","source":["# Funtion to read all sentences\n","def get_sentences(path):\n","    sentences= []\n","    for filename in os.listdir(path):\n","        with open(path+filename, 'r') as f:\n","            for sentence in f :\n","                sentences.append(sentence)\n","    return sentences"],"metadata":{"id":"knj4Vy1wwsfI","executionInfo":{"status":"ok","timestamp":1657498289822,"user_tz":-120,"elapsed":22,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Function to read get all labels\n","def get_labels(path):\n","    all_labels = []\n","    for filename in os.listdir(path):\n","        file_labels = []\n","        with open(path+filename, 'r') as f:\n","            for label in f :\n","                all_labels.append(int(label))\n","    return all_labels"],"metadata":{"id":"utKztVafwtnw","executionInfo":{"status":"ok","timestamp":1657498289824,"user_tz":-120,"elapsed":20,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Reading sentences and labels\n","all_sentences = get_sentences(\"ToS/Sentences/\")\n","all_labels = get_labels(\"ToS/Labels/\")"],"metadata":{"id":"mkp9MZKewxDN","executionInfo":{"status":"ok","timestamp":1657498290164,"user_tz":-120,"elapsed":356,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Since unfair sentences are marked as \"-1\", we change them to \"0\" for simplicity. Zero means fair, One means unfair\n","all_labels =  [0 if label ==-1 else label for label in all_labels]"],"metadata":{"id":"bnor58FKwxy2","executionInfo":{"status":"ok","timestamp":1657498290164,"user_tz":-120,"elapsed":6,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Bert Tokenizer"],"metadata":{"id":"jU5yamL5xKAY"}},{"cell_type":"code","source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True) # the model 'bert-base-uncased' only contains lower case sentences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMiwR7ldxLwC","executionInfo":{"status":"ok","timestamp":1657498291496,"user_tz":-120,"elapsed":1337,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"8cc462a7-ba44-44e1-aa69-a1743e0fd354"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]}]},{"cell_type":"code","source":["# ==> Example of first sentence\n","\n","# Print the original sentence.\n","print(' Original: ', all_sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(all_sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(all_sentences[0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgT3sO20xPtj","executionInfo":{"status":"ok","timestamp":1657498291499,"user_tz":-120,"elapsed":11,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"272a0aa5-8320-4116-f450-6a57985741aa"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":[" Original:  * accepting the terms of service \n","\n","Tokenized:  ['*', 'accept', '##ing', 'the', 'terms', 'of', 'service']\n","Token IDs:  [113, 1599, 235, 207, 333, 210, 446]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","# ==> Get the max length of a sentence\n","\n","max_len = 0\n","\n","# For every sentence...\n","for sent in all_sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)\n","# Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n","# Max sentence length:  598\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"c-uE6jBuxRjZ","executionInfo":{"status":"ok","timestamp":1657498291499,"user_tz":-120,"elapsed":10,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"9c27910e-06a6-403e-e008-e3ff076dc8f0"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# ==> Get the max length of a sentence\\n\\nmax_len = 0\\n\\n# For every sentence...\\nfor sent in all_sentences:\\n\\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\\n    input_ids = tokenizer.encode(sent, add_special_tokens=True)\\n\\n    # Update the maximum sentence length.\\n    max_len = max(max_len, len(input_ids))\\n\\nprint('Max sentence length: ', max_len)\\n# Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\\n# Max sentence length:  598\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### Model BertForSequenceClassification (Load model)"],"metadata":{"id":"JpohQx5xyqwh"}},{"cell_type":"code","source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = NUM_CLASSES, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tkpyAA69yuEO","executionInfo":{"status":"ok","timestamp":1657498296617,"user_tz":-120,"elapsed":5125,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"ce67716a-9bca-42c9-e3ee-b43f7a22237b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n","      (position_embeddings): Embedding(512, 512)\n","      (token_type_embeddings): Embedding(2, 512)\n","      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=512, out_features=512, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Load the model and dictionary\n","model.load_state_dict(torch.load('Bert4SeqClassif_202207072015.pt'))#, map_location=torch.device('cpu') or cuda. Both work\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-aGx3Q60e4w","executionInfo":{"status":"ok","timestamp":1657498297144,"user_tz":-120,"elapsed":542,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"9ee93073-7b7a-4a71-8d87-9993ef63c42f"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### Trigger generation"],"metadata":{"id":"JIyze6jK2bpQ"}},{"cell_type":"markdown","source":["##### General functions"],"metadata":{"id":"mLTLH3AJ5-Lw"}},{"cell_type":"code","source":["# hook used in add_hooks()\n","extracted_grads = []\n","def extract_grad_hook(module, grad_in, grad_out):\n","    extracted_grads.append(grad_out[0])"],"metadata":{"id":"8JjcRhGE6hUc","executionInfo":{"status":"ok","timestamp":1657498297145,"user_tz":-120,"elapsed":50,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# returns the wordpiece embedding weight matrix\n","def get_embedding_weight(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522: # only add a hook to wordpiece embeddings, not position embeddings \n","                ##50257 is the size of the vocabulary of GPT\n","                return module.weight.detach()"],"metadata":{"id":"1MV3isar2dvF","executionInfo":{"status":"ok","timestamp":1657498297146,"user_tz":-120,"elapsed":47,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# add hooks for embeddings\n","def add_hooks(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522: # only add a hook to wordpiece embeddings, not position\n","                ##50257 is the size of the vocabulary of GPT\n","                module.weight.requires_grad = True\n","                #module.register_backward_hook(extract_grad_hook)\n","                module.register_full_backward_hook(extract_grad_hook)"],"metadata":{"id":"ymN2vLUT6Oe5","executionInfo":{"status":"ok","timestamp":1657498297147,"user_tz":-120,"elapsed":46,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Gets the loss of the target_tokens using the triggers as the context\n","def get_loss(language_model, batch_size, trigger, target, device='cuda'):\n","    # context is trigger repeated batch size\n","    print(f'Arrive to get_loss\\n\\t batch_size {batch_size}\\n\\t trigger {trigger.shape}\\n\\t target {target.shape}')\n","    print(f'LANGUAGE_MODEL {language_model}')\n","    tensor_trigger = torch.tensor(trigger, device=device, dtype=torch.long).unsqueeze(0).repeat(batch_size, 1)\n","    print(f'tensor_trigger {tensor_trigger}')\n","    mask_out = -1 * torch.ones_like(tensor_trigger) # we zero out the loss for the trigger tokens\n","    print(f'mask_out {mask_out}')\n","    lm_input = torch.cat((tensor_trigger, target), dim=1) # we feed the model the trigger + target texts\n","    print(f'lm_input {lm_input.shape} == {lm_input}')\n","    print(f'lm_input[0] {lm_input[0]}')\n","    mask_and_target = torch.cat((mask_out, target), dim=1) # has -1's + target texts for loss computation\n","    print(f'mask_and_target {mask_and_target.shape} == {mask_and_target}')\n","    lm_input[lm_input == -1] = 1   # put random token of 1 at end of context (its masked out)\n","    print(f'lm_input {lm_input.shape} == {lm_input}')\n","    loss = language_model(lm_input, labels=mask_and_target)#[0]\n","    print(f'loss {loss}')\n","    return loss"],"metadata":{"id":"nZOz1INA6WeB","executionInfo":{"status":"ok","timestamp":1657498297147,"user_tz":-120,"elapsed":44,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# creates the batch of target texts with -1 placed at the end of the sequences for padding (for masking out the loss).\n","def make_target_batch(tokenizer, device, target_texts):\n","    # encode items and get the max length\n","    encoded_texts = []\n","    max_len = 0\n","    for target_text in target_texts:\n","        encoded_target_text = tokenizer.encode_plus(\n","            target_text,\n","            add_special_tokens = True,\n","            max_length = EMBEDDING_SIZE - NUM_TOKENS,\n","            pad_to_max_length = True,\n","            return_attention_mask = True\n","        )\n","        #print(f'ENCODED_TARGET_TEXT {type(input_ids)} == {encoded_target_text.keys()}') # ENCODED_TARGET_TEXT <class 'list'> == dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","        \"\"\"\n","        print(f'ENCODED_TARGET_TEXT {type(encoded_target_text)} == {encoded_target_text}')\n","        ENCODED_TARGET_TEXT <class 'list'> == [101, 218, 4527, 237, 366, 212, 1260, 207, 446, 115, 799, 2277, 212, 781, 216, 119, 102]\n","        ENCODED_TARGET_TEXT <class 'list'> == [101, 799, 356, 432, 145, 782, 438, 225, 3457, 13409, 115, 102]\n","        \"\"\"\n","        encoded_texts.append(encoded_target_text.input_ids)\n","        if len(encoded_target_text.input_ids) > max_len:\n","            max_len = len(encoded_target_text)\n","\n","    # pad tokens, i.e., append -1 to the end of the non-longest ones\n","    for indx, encoded_text in enumerate(encoded_texts):\n","        if len(encoded_text) < max_len:\n","            encoded_texts[indx].extend([-1] * (max_len - len(encoded_text)))\n","\n","    # convert to tensors and batch them up\n","    target_tokens_batch = None\n","    for encoded_text in encoded_texts:\n","        target_tokens = torch.tensor(encoded_text, device=device, dtype=torch.long).unsqueeze(0)\n","        if target_tokens_batch is None:\n","            target_tokens_batch = target_tokens\n","        else:\n","            target_tokens_batch = torch.cat((target_tokens, target_tokens_batch), dim=0)\n","    return target_tokens_batch"],"metadata":{"id":"73ZQsJW_6z3h","executionInfo":{"status":"ok","timestamp":1657498297148,"user_tz":-120,"elapsed":42,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Got from https://github.com/Eric-Wallace/universal-triggers/blob/master/attacks.py\n","\n","def hotflip_attack(averaged_grad, embedding_matrix, trigger_token_ids,\n","                   increase_loss=False, num_candidates=1):\n","    \"\"\"\n","    The \"Hotflip\" attack described in Equation (2) of the paper. This code is heavily inspired by\n","    the nice code of Paul Michel here https://github.com/pmichel31415/translate/blob/paul/\n","    pytorch_translate/research/adversarial/adversaries/brute_force_adversary.py\n","    This function takes in the model's average_grad over a batch of examples, the model's\n","    token embedding matrix, and the current trigger token IDs. It returns the top token\n","    candidates for each position.\n","    If increase_loss=True, then the attack reverses the sign of the gradient and tries to increase\n","    the loss (decrease the model's probability of the true class). For targeted attacks, you want\n","    to decrease the loss of the target class (increase_loss=False).\n","    \"\"\"\n","    averaged_grad = averaged_grad.cpu()\n","    embedding_matrix = embedding_matrix.cpu()\n","    trigger_token_embeds = torch.nn.functional.embedding(torch.LongTensor(trigger_token_ids),\n","                                                         embedding_matrix).detach().unsqueeze(0)\n","    averaged_grad = averaged_grad.unsqueeze(0)\n","    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n","                                                 (averaged_grad, embedding_matrix))        \n","    if not increase_loss:\n","        gradient_dot_embedding_matrix *= -1    # lower versus increase the class probability.\n","    if num_candidates > 1: # get top k options\n","        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n","        return best_k_ids.detach().cpu().numpy()[0]\n","    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n","    return best_at_each_step[0].detach().cpu().numpy()"],"metadata":{"id":"DQ0ZcgVCCHmY","executionInfo":{"status":"ok","timestamp":1657498297149,"user_tz":-120,"elapsed":42,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def get_input_masks_and_labels_with_tokens(sentences, labels, tokens):\n","    input_ids = []\n","    attention_masks = []\n","\n","    # For every sentence...\n","    for sent in sentences:\n","        # `encode_plus` will:\n","        #   (1) Tokenize the sentence.\n","        #   (2) Prepend the `[CLS]` token to the start.\n","        #   (3) Append the `[SEP]` token to the end.\n","        #   (4) Map tokens to their IDs.\n","        #   (5) Pad or truncate the sentence to `max_length`\n","        #   (6) Create attention masks for [PAD] tokens.\n","        sent_with_tokens = \" \".join(tokens) + \" \" + sent\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True, #is deprecated\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","        \n","        # Add the encoded sentence to the list.    \n","        input_ids.append(encoded_dict['input_ids'])\n","\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    # Convert the lists into tensors.\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","\n","    return input_ids, attention_masks, labels"],"metadata":{"id":"lV7lkCZP731g","executionInfo":{"status":"ok","timestamp":1657498297149,"user_tz":-120,"elapsed":40,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def get_loss_and_metrics(model, dataloader, device):\n","    # get initial loss for the trigger\n","    model.zero_grad()\n","\n","    test_preds = []\n","    test_targets = []\n","\n","    # Tracking variables \n","    #total_test_accuracy = 0\n","    total_test_loss = 0\n","\n","    for batch in dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        result = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels,\n","                    return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Accumulate the validation loss.\n","        total_test_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        loss.backward()\n","\n","        #print(f'loss.backward() {loss.backward()}')\n","\n","        \"\"\"\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_test_accuracy += flat_accuracy(logits, label_ids)\n","        \n","        valid_acc = accuracy_score(valid_targets, valid_preds)\n","        valid_precision = precision_score(valid_targets, valid_preds)\n","        valid_recall = recall_score(valid_targets, valid_preds)\n","        valid_f1 = f1_score(valid_targets, valid_preds)\n","\n","        io_total_valid_acc += valid_acc\n","        io_total_valid_prec += valid_precision\n","        io_total_valid_recall += valid_recall\n","        io_total_valid_f1 += valid_f1\n","\n","    io_avg_valid_acc = io_total_valid_acc / len(validation_dataloader)\n","    io_avg_valid_prec = io_total_valid_prec / len(validation_dataloader)\n","    io_avg_valid_recall = io_total_valid_recall / len(validation_dataloader)\n","    io_avg_valid_f1 = io_total_valid_f1 / len(validation_dataloader)\n","    print(\n","            f'Epoch {epoch_i+1} : \\n\\\n","            Valid_acc : {io_avg_valid_acc}\\n\\\n","            Valid_F1 : {io_avg_valid_f1}\\n\\\n","            Valid_precision : {io_avg_valid_prec}\\n\\\n","            Valid_recall : {io_avg_valid_recall}'\n","          )\n","        \"\"\"\n","\n","    #print(f\"total_test_loss {total_test_loss/len(dataloader)}\")\n","\n","    return total_test_loss/len(dataloader)"],"metadata":{"id":"myWBJ3tc-XCR","executionInfo":{"status":"ok","timestamp":1657498297150,"user_tz":-120,"elapsed":38,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def change_input_ids_with_candidate_token(input_ids, position, candidate):\n","    for elem in range(input_ids.shape[0]):\n","        input_ids[elem][position] = candidate\n","\n","    return input_ids"],"metadata":{"id":"o-ZoFvcJXsH5","executionInfo":{"status":"ok","timestamp":1657498297151,"user_tz":-120,"elapsed":37,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["### Get positions of unfair sentences\n","\n","positions_unfair = np.where(np.array(all_labels) == 1)[0]\n","print(f'First 32 positions: {positions_unfair[0:32]} with total of unfair sentences {len(positions_unfair)}')\n","\n","target_unfair_sentences = []\n","labels_unfair_sentences = []\n","for index in range(len(positions_unfair[0:128])):\n","    target_unfair_sentences.append(all_sentences[positions_unfair[index]])\n","    labels_unfair_sentences.append(all_labels[positions_unfair[index]])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cr3D9l6q8CD5","executionInfo":{"status":"ok","timestamp":1657498297152,"user_tz":-120,"elapsed":36,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"6cce1285-61dc-4714-95ed-05f004dfec5f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["First 32 positions: [  4   9  10  11  12  13  24  25  43  45  61  62  78  79  87  89  91  92\n"," 100 104 109 111 143 151 154 157 169 195 206 258 260 266] with total of unfair sentences 1032\n"]}]},{"cell_type":"code","source":["model.eval()\n","model.to(device)\n","\n","add_hooks(model) # add gradient hooks to embeddings\n","embedding_weight = get_embedding_weight(model) # save the word embedding matrix"],"metadata":{"id":"Q9b_Vpns66cA","executionInfo":{"status":"ok","timestamp":1657498297154,"user_tz":-120,"elapsed":32,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["print(f'embedding_weight {embedding_weight} \\n\\nwith shape {embedding_weight.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c_bgvnKs7Gt1","executionInfo":{"status":"ok","timestamp":1657498297154,"user_tz":-120,"elapsed":31,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"203bfcd2-0dc1-4f35-f39b-96683da68c49"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["embedding_weight tensor([[ 0.0641, -0.0185, -0.0232,  ..., -0.0211,  0.0466, -0.0678],\n","        [-0.0175,  0.0522, -0.1289,  ..., -0.0658,  0.0291, -0.1561],\n","        [ 0.0128, -0.0119, -0.0850,  ..., -0.0592,  0.0799, -0.1387],\n","        ...,\n","        [ 0.0040,  0.0531, -0.0814,  ...,  0.0393,  0.0525, -0.0063],\n","        [-0.0143,  0.0036, -0.0973,  ..., -0.0562,  0.0196, -0.1135],\n","        [-0.0785, -0.0090, -0.1799,  ...,  0.0115,  0.0191, -0.0859]],\n","       device='cuda:0') \n","\n","with shape torch.Size([30522, 512])\n"]}]},{"cell_type":"code","source":["#target_tokens = make_target_batch(tokenizer, device, target_sentences)\n","\n","#target_tokens.shape\n","\n","# sample random initial trigger\n","trigger_tokens = np.array([621, 19353, 7063])#np.array([598, 275, 3523])#np.random.randint(VOCABULARY_SIZE, size=NUM_TOKENS)\n","print(tokenizer.decode(trigger_tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TN1TmoB_Asb","executionInfo":{"status":"ok","timestamp":1657498297155,"user_tz":-120,"elapsed":29,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"634a6c31-5bac-4b9f-d35b-b5cdf237fd20"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["unless impulse author\n"]}]},{"cell_type":"code","source":["#trigger_tokens #.shape (3,) => array([ 8972, 27350, 25382])\n","#target_tokens #.shape => torch.Size([32, 163])\n","\"\"\"\n","tensor([[  101, 12017,   179,  ...,    -1,    -1,    -1],\n","        [  101,   233,   223,  ...,    -1,    -1,    -1],\n","        [  101, 12017,   179,  ...,    -1,    -1,    -1],\n","        ...,\n","        [  101,   206,  4313,  ...,    -1,    -1,    -1],\n","        [  101,   206,  4313,  ...,    -1,    -1,    -1],\n","        [  101,   218,  1260,  ...,    -1,    -1,    -1]], device='cuda:0')\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"ujMeErAoGyl8","executionInfo":{"status":"ok","timestamp":1657498297156,"user_tz":-120,"elapsed":25,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"3283a281-5abc-4c2f-e4c8-66804523f0d2"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ntensor([[  101, 12017,   179,  ...,    -1,    -1,    -1],\\n        [  101,   233,   223,  ...,    -1,    -1,    -1],\\n        [  101, 12017,   179,  ...,    -1,    -1,    -1],\\n        ...,\\n        [  101,   206,  4313,  ...,    -1,    -1,    -1],\\n        [  101,   206,  4313,  ...,    -1,    -1,    -1],\\n        [  101,   218,  1260,  ...,    -1,    -1,    -1]], device='cuda:0')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["input_ids, attention_masks, labels = get_input_masks_and_labels_with_tokens(target_unfair_sentences, labels_unfair_sentences, tokenizer.decode(trigger_tokens))\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuqGPIZ9bsM4","executionInfo":{"status":"ok","timestamp":1657498297377,"user_tz":-120,"elapsed":245,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"17f8f037-8492-4efe-ffbd-84b41365f402"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["\n","extracted_grads = []\n","\n","loss_obtained = get_loss_and_metrics(model, dataloader, device)\n","print(f'loss_obtained {loss_obtained}')\n","\n","best_loss = loss_obtained\n","candidates_selented = [0,0,0]\n","# try all the candidates and pick the best\n","curr_best_loss = 0\n","curr_best_trigger_tokens = None\n","\n","for id_token_to_flip in range(0, NUM_TOKENS):\n","    # Get average gradient w.r.t. the triggers\n","    #extracted_grads = []\n","    #loss_obtained.backward()\n","\n","    averaged_grad = torch.sum(extracted_grads[0], dim=0)\n","    averaged_grad = averaged_grad[id_token_to_flip].unsqueeze(0)\n","\n","    # Use hotflip (linear approximation) attack to get the top num_candidates\n","    candidates = hotflip_attack(averaged_grad, embedding_weight,\n","                                        [trigger_tokens[id_token_to_flip]], \n","                                        increase_loss=False, num_candidates=100)[0]\n","    print(f'candidates {candidates}')\n","    \n","    for index, cand in enumerate(candidates):\n","        # replace one token with new candidate\n","        extracted_grads = []\n","\n","        input_ids_with_candidate_trigger = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, cand)\n","        dataset_with_candidate_trigger = TensorDataset(input_ids_with_candidate_trigger, attention_masks, labels)\n","        dataloader_with_candidate_trigger = torch.utils.data.DataLoader(dataset_with_candidate_trigger, batch_size=BATCH_SIZE)\n","\n","        current_loss = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device)\n","\n","        if curr_best_loss < current_loss:\n","            curr_best_loss = current_loss\n","            candidates_selented[id_token_to_flip] = cand\n","\n","        del input_ids_with_candidate_trigger\n","        del dataset_with_candidate_trigger\n","        del dataloader_with_candidate_trigger\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        print(f'[{id_token_to_flip}][{index}] loss[{index}] {current_loss} ({curr_best_loss})')\n","    input_ids = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, candidates_selented[id_token_to_flip])\n","    print(f'Best loss {curr_best_loss} with candidates {candidates_selented}')\n","\n","#Best loss 0.5344366431236267 with candidates [598, 275, 3523]\n","#Best loss 0.9147895276546478 with candidates [621, 19353, 7063]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFhC5DN9ggz4","executionInfo":{"status":"ok","timestamp":1657498864413,"user_tz":-120,"elapsed":567047,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"ed1336cf-ce0a-4ffb-9169-25ff16855ff5"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["loss_obtained 0.25122037902474403\n","candidates [  457 12986  5102   660  7742   232  2176  2705 10902   587   591  3522\n","  2940  1607  1914   454 20458  6966  1750   378  1890 23836   382  1635\n","  3477   936  1382   679   266  4004   531   572  1672  3626  1401  1753\n","  1731  2126  1363   410  4203  1427  1281  1297   799 18253   318   358\n"," 29799  1050   599  1089  1688   635   782 23272   338  8498   621  1415\n","   226  6665  8628  1807  3774  1375  2127  7455   271  2872   547  2586\n","   644  7784  7110  1327 13056 23357  1924   598  1626  2527  2318  1280\n"," 12491 24438  2090 11472  1073  2764  1735   606  1492   390  1414   435\n","   775  6767  8707   419]\n","[0][0] loss[0] 0.3504040986299515 (0.3504040986299515)\n","[0][1] loss[1] 0.3625735118985176 (0.3625735118985176)\n","[0][2] loss[2] 0.3406316787004471 (0.3625735118985176)\n","[0][3] loss[3] 0.33971817791461945 (0.3625735118985176)\n","[0][4] loss[4] 0.252808403223753 (0.3625735118985176)\n","[0][5] loss[5] 0.3542017564177513 (0.3625735118985176)\n","[0][6] loss[6] 0.29921193048357964 (0.3625735118985176)\n","[0][7] loss[7] 0.330042764544487 (0.3625735118985176)\n","[0][8] loss[8] 0.22343502938747406 (0.3625735118985176)\n","[0][9] loss[9] 0.3307056203484535 (0.3625735118985176)\n","[0][10] loss[10] 0.3063581548631191 (0.3625735118985176)\n","[0][11] loss[11] 0.36436789482831955 (0.36436789482831955)\n","[0][12] loss[12] 0.2836535833775997 (0.36436789482831955)\n","[0][13] loss[13] 0.312764298170805 (0.36436789482831955)\n","[0][14] loss[14] 0.2802325002849102 (0.36436789482831955)\n","[0][15] loss[15] 0.3620580583810806 (0.36436789482831955)\n","[0][16] loss[16] 0.30528315156698227 (0.36436789482831955)\n","[0][17] loss[17] 0.2463269606232643 (0.36436789482831955)\n","[0][18] loss[18] 0.28372708708047867 (0.36436789482831955)\n","[0][19] loss[19] 0.3332504667341709 (0.36436789482831955)\n","[0][20] loss[20] 0.41676413267850876 (0.41676413267850876)\n","[0][21] loss[21] 0.266454741358757 (0.41676413267850876)\n","[0][22] loss[22] 0.3016981706023216 (0.41676413267850876)\n","[0][23] loss[23] 0.2980436123907566 (0.41676413267850876)\n","[0][24] loss[24] 0.41780776530504227 (0.41780776530504227)\n","[0][25] loss[25] 0.2724228836596012 (0.41780776530504227)\n","[0][26] loss[26] 0.3001079149544239 (0.41780776530504227)\n","[0][27] loss[27] 0.31890929490327835 (0.41780776530504227)\n","[0][28] loss[28] 0.2714228592813015 (0.41780776530504227)\n","[0][29] loss[29] 0.3401990905404091 (0.41780776530504227)\n","[0][30] loss[30] 0.2987384870648384 (0.41780776530504227)\n","[0][31] loss[31] 0.3123672269284725 (0.41780776530504227)\n","[0][32] loss[32] 0.3228245973587036 (0.41780776530504227)\n","[0][33] loss[33] 0.3408842235803604 (0.41780776530504227)\n","[0][34] loss[34] 0.28061116486787796 (0.41780776530504227)\n","[0][35] loss[35] 0.2569439858198166 (0.41780776530504227)\n","[0][36] loss[36] 0.2673090435564518 (0.41780776530504227)\n","[0][37] loss[37] 0.3637078255414963 (0.41780776530504227)\n","[0][38] loss[38] 0.3138530030846596 (0.41780776530504227)\n","[0][39] loss[39] 0.2655276320874691 (0.41780776530504227)\n","[0][40] loss[40] 0.29954979941248894 (0.41780776530504227)\n","[0][41] loss[41] 0.33967458829283714 (0.41780776530504227)\n","[0][42] loss[42] 0.3158740736544132 (0.41780776530504227)\n","[0][43] loss[43] 0.3933856934309006 (0.41780776530504227)\n","[0][44] loss[44] 0.42584673315286636 (0.42584673315286636)\n","[0][45] loss[45] 0.3024766705930233 (0.42584673315286636)\n","[0][46] loss[46] 0.36984579265117645 (0.42584673315286636)\n","[0][47] loss[47] 0.3042430989444256 (0.42584673315286636)\n","[0][48] loss[48] 0.3198165148496628 (0.42584673315286636)\n","[0][49] loss[49] 0.26269759610295296 (0.42584673315286636)\n","[0][50] loss[50] 0.3243744745850563 (0.42584673315286636)\n","[0][51] loss[51] 0.3926476240158081 (0.42584673315286636)\n","[0][52] loss[52] 0.25287819653749466 (0.42584673315286636)\n","[0][53] loss[53] 0.32332078367471695 (0.42584673315286636)\n","[0][54] loss[54] 0.3050011806190014 (0.42584673315286636)\n","[0][55] loss[55] 0.28838295489549637 (0.42584673315286636)\n","[0][56] loss[56] 0.3126274272799492 (0.42584673315286636)\n","[0][57] loss[57] 0.3224455751478672 (0.42584673315286636)\n","[0][58] loss[58] 0.5034442767500877 (0.5034442767500877)\n","[0][59] loss[59] 0.29449373111128807 (0.5034442767500877)\n","[0][60] loss[60] 0.33860862627625465 (0.5034442767500877)\n","[0][61] loss[61] 0.3560311868786812 (0.5034442767500877)\n","[0][62] loss[62] 0.2592368684709072 (0.5034442767500877)\n","[0][63] loss[63] 0.3149384558200836 (0.5034442767500877)\n","[0][64] loss[64] 0.2972073294222355 (0.5034442767500877)\n","[0][65] loss[65] 0.28908783197402954 (0.5034442767500877)\n","[0][66] loss[66] 0.3383571617305279 (0.5034442767500877)\n","[0][67] loss[67] 0.29455284029245377 (0.5034442767500877)\n","[0][68] loss[68] 0.36583442986011505 (0.5034442767500877)\n","[0][69] loss[69] 0.27813686057925224 (0.5034442767500877)\n","[0][70] loss[70] 0.3190704509615898 (0.5034442767500877)\n","[0][71] loss[71] 0.2681891955435276 (0.5034442767500877)\n","[0][72] loss[72] 0.3032018542289734 (0.5034442767500877)\n","[0][73] loss[73] 0.30010702833533287 (0.5034442767500877)\n","[0][74] loss[74] 0.2996842935681343 (0.5034442767500877)\n","[0][75] loss[75] 0.2543082982301712 (0.5034442767500877)\n","[0][76] loss[76] 0.23016351461410522 (0.5034442767500877)\n","[0][77] loss[77] 0.2703612633049488 (0.5034442767500877)\n","[0][78] loss[78] 0.2943083867430687 (0.5034442767500877)\n","[0][79] loss[79] 0.49116596579551697 (0.5034442767500877)\n","[0][80] loss[80] 0.3030172660946846 (0.5034442767500877)\n","[0][81] loss[81] 0.2814617455005646 (0.5034442767500877)\n","[0][82] loss[82] 0.2848288454115391 (0.5034442767500877)\n","[0][83] loss[83] 0.2915682755410671 (0.5034442767500877)\n","[0][84] loss[84] 0.28652994707226753 (0.5034442767500877)\n","[0][85] loss[85] 0.2938057482242584 (0.5034442767500877)\n","[0][86] loss[86] 0.464126855134964 (0.5034442767500877)\n","[0][87] loss[87] 0.24541142955422401 (0.5034442767500877)\n","[0][88] loss[88] 0.3540468327701092 (0.5034442767500877)\n","[0][89] loss[89] 0.3958985507488251 (0.5034442767500877)\n","[0][90] loss[90] 0.328315369784832 (0.5034442767500877)\n","[0][91] loss[91] 0.3078960180282593 (0.5034442767500877)\n","[0][92] loss[92] 0.27831878140568733 (0.5034442767500877)\n","[0][93] loss[93] 0.29378827288746834 (0.5034442767500877)\n","[0][94] loss[94] 0.33236289396882057 (0.5034442767500877)\n","[0][95] loss[95] 0.3447825610637665 (0.5034442767500877)\n","[0][96] loss[96] 0.2896447964012623 (0.5034442767500877)\n","[0][97] loss[97] 0.2726166285574436 (0.5034442767500877)\n","[0][98] loss[98] 0.3110014349222183 (0.5034442767500877)\n","[0][99] loss[99] 0.4072623774409294 (0.5034442767500877)\n","Best loss 0.5034442767500877 with candidates [621, 0, 0]\n","candidates [ 7484 20995 21952  8404  4848  5527 23695 24453  5413 12116 23054  2520\n","  8351  2872 29905 25374 13085 15166  4338  7547  3627 10225 16845  7257\n"," 12291  9592 28942 19533  2873  4399  5651 11838 13483 17372 10725  6257\n"," 14475 22470 27126  9920 19256  8176 28500 24143  4865  4536 25549 23540\n"," 11489 14202 10299 14039 20303 17595  7754  7805 10606  9716  3539  6647\n"," 10986 27976  8264  7248  7652 29639 14199 20139 10312 23928 23235 11330\n"," 21951 29000 12293 20253 13890 23315  4575  5132 23963 24464 11944 20720\n","  3178 23629 17384  5540 24866 13424 23806 15140  2943 16583 26216 28879\n","  5406 20403  7616  3890]\n","[1][0] loss[0] 0.4272855967283249 (0.5034442767500877)\n","[1][1] loss[1] 0.4710824117064476 (0.5034442767500877)\n","[1][2] loss[2] 0.4124227687716484 (0.5034442767500877)\n","[1][3] loss[3] 0.5029634833335876 (0.5034442767500877)\n","[1][4] loss[4] 0.38003743439912796 (0.5034442767500877)\n","[1][5] loss[5] 0.4164608493447304 (0.5034442767500877)\n","[1][6] loss[6] 0.46272019296884537 (0.5034442767500877)\n","[1][7] loss[7] 0.4774073287844658 (0.5034442767500877)\n","[1][8] loss[8] 0.4067915081977844 (0.5034442767500877)\n","[1][9] loss[9] 0.4375869110226631 (0.5034442767500877)\n","[1][10] loss[10] 0.5014313459396362 (0.5034442767500877)\n","[1][11] loss[11] 0.4042297527194023 (0.5034442767500877)\n","[1][12] loss[12] 0.37518375739455223 (0.5034442767500877)\n","[1][13] loss[13] 0.4234449937939644 (0.5034442767500877)\n","[1][14] loss[14] 0.4612531289458275 (0.5034442767500877)\n","[1][15] loss[15] 0.49884407222270966 (0.5034442767500877)\n","[1][16] loss[16] 0.44946612417697906 (0.5034442767500877)\n","[1][17] loss[17] 0.43127383291721344 (0.5034442767500877)\n","[1][18] loss[18] 0.39361581206321716 (0.5034442767500877)\n","[1][19] loss[19] 0.45596369355916977 (0.5034442767500877)\n","[1][20] loss[20] 0.4425145089626312 (0.5034442767500877)\n","[1][21] loss[21] 0.46047618240118027 (0.5034442767500877)\n","[1][22] loss[22] 0.5357408672571182 (0.5357408672571182)\n","[1][23] loss[23] 0.41079436242580414 (0.5357408672571182)\n","[1][24] loss[24] 0.4194888398051262 (0.5357408672571182)\n","[1][25] loss[25] 0.415656216442585 (0.5357408672571182)\n","[1][26] loss[26] 0.423639141023159 (0.5357408672571182)\n","[1][27] loss[27] 0.4679025560617447 (0.5357408672571182)\n","[1][28] loss[28] 0.4370386675000191 (0.5357408672571182)\n","[1][29] loss[29] 0.3741454482078552 (0.5357408672571182)\n","[1][30] loss[30] 0.411180704832077 (0.5357408672571182)\n","[1][31] loss[31] 0.4008350372314453 (0.5357408672571182)\n","[1][32] loss[32] 0.46856309473514557 (0.5357408672571182)\n","[1][33] loss[33] 0.4182593822479248 (0.5357408672571182)\n","[1][34] loss[34] 0.43722956627607346 (0.5357408672571182)\n","[1][35] loss[35] 0.4907093048095703 (0.5357408672571182)\n","[1][36] loss[36] 0.41599617898464203 (0.5357408672571182)\n","[1][37] loss[37] 0.4795398488640785 (0.5357408672571182)\n","[1][38] loss[38] 0.5059422552585602 (0.5357408672571182)\n","[1][39] loss[39] 0.4762692451477051 (0.5357408672571182)\n","[1][40] loss[40] 0.45237574726343155 (0.5357408672571182)\n","[1][41] loss[41] 0.46675558388233185 (0.5357408672571182)\n","[1][42] loss[42] 0.48054371774196625 (0.5357408672571182)\n","[1][43] loss[43] 0.5318689942359924 (0.5357408672571182)\n","[1][44] loss[44] 0.5469861850142479 (0.5469861850142479)\n","[1][45] loss[45] 0.4474346488714218 (0.5469861850142479)\n","[1][46] loss[46] 0.5108369514346123 (0.5469861850142479)\n","[1][47] loss[47] 0.49888642132282257 (0.5469861850142479)\n","[1][48] loss[48] 0.4534040316939354 (0.5469861850142479)\n","[1][49] loss[49] 0.38928236812353134 (0.5469861850142479)\n","[1][50] loss[50] 0.44685572385787964 (0.5469861850142479)\n","[1][51] loss[51] 0.4723891392350197 (0.5469861850142479)\n","[1][52] loss[52] 0.4608098939061165 (0.5469861850142479)\n","[1][53] loss[53] 0.46856769174337387 (0.5469861850142479)\n","[1][54] loss[54] 0.41435953229665756 (0.5469861850142479)\n","[1][55] loss[55] 0.46188976615667343 (0.5469861850142479)\n","[1][56] loss[56] 0.44356168806552887 (0.5469861850142479)\n","[1][57] loss[57] 0.43175158649683 (0.5469861850142479)\n","[1][58] loss[58] 0.42218561470508575 (0.5469861850142479)\n","[1][59] loss[59] 0.46338213235139847 (0.5469861850142479)\n","[1][60] loss[60] 0.4730697572231293 (0.5469861850142479)\n","[1][61] loss[61] 0.500901959836483 (0.5469861850142479)\n","[1][62] loss[62] 0.37447933852672577 (0.5469861850142479)\n","[1][63] loss[63] 0.48094452917575836 (0.5469861850142479)\n","[1][64] loss[64] 0.3935312032699585 (0.5469861850142479)\n","[1][65] loss[65] 0.510927252471447 (0.5469861850142479)\n","[1][66] loss[66] 0.5041635781526566 (0.5469861850142479)\n","[1][67] loss[67] 0.46451572328805923 (0.5469861850142479)\n","[1][68] loss[68] 0.4988068714737892 (0.5469861850142479)\n","[1][69] loss[69] 0.4857281520962715 (0.5469861850142479)\n","[1][70] loss[70] 0.45367418974637985 (0.5469861850142479)\n","[1][71] loss[71] 0.4631473124027252 (0.5469861850142479)\n","[1][72] loss[72] 0.48227615654468536 (0.5469861850142479)\n","[1][73] loss[73] 0.5116652995347977 (0.5469861850142479)\n","[1][74] loss[74] 0.4661609083414078 (0.5469861850142479)\n","[1][75] loss[75] 0.4677278473973274 (0.5469861850142479)\n","[1][76] loss[76] 0.5295415148139 (0.5469861850142479)\n","[1][77] loss[77] 0.48597273975610733 (0.5469861850142479)\n","[1][78] loss[78] 0.4278639778494835 (0.5469861850142479)\n","[1][79] loss[79] 0.4255864545702934 (0.5469861850142479)\n","[1][80] loss[80] 0.49608610570430756 (0.5469861850142479)\n","[1][81] loss[81] 0.4725305214524269 (0.5469861850142479)\n","[1][82] loss[82] 0.5029078423976898 (0.5469861850142479)\n","[1][83] loss[83] 0.5160144791007042 (0.5469861850142479)\n","[1][84] loss[84] 0.38818832486867905 (0.5469861850142479)\n","[1][85] loss[85] 0.4324455261230469 (0.5469861850142479)\n","[1][86] loss[86] 0.49866561591625214 (0.5469861850142479)\n","[1][87] loss[87] 0.4574578180909157 (0.5469861850142479)\n","[1][88] loss[88] 0.5243712663650513 (0.5469861850142479)\n","[1][89] loss[89] 0.5021118968725204 (0.5469861850142479)\n","[1][90] loss[90] 0.47548115253448486 (0.5469861850142479)\n","[1][91] loss[91] 0.4007677510380745 (0.5469861850142479)\n","[1][92] loss[92] 0.38617049157619476 (0.5469861850142479)\n","[1][93] loss[93] 0.47059254348278046 (0.5469861850142479)\n","[1][94] loss[94] 0.5002786070108414 (0.5469861850142479)\n","[1][95] loss[95] 0.4981069341301918 (0.5469861850142479)\n","[1][96] loss[96] 0.46016816794872284 (0.5469861850142479)\n","[1][97] loss[97] 0.505784422159195 (0.5469861850142479)\n","[1][98] loss[98] 0.42471980303525925 (0.5469861850142479)\n","[1][99] loss[99] 0.46942469477653503 (0.5469861850142479)\n","Best loss 0.5469861850142479 with candidates [621, 4865, 0]\n","candidates [ 3005 10606   819  2878  5376  8559  4588  7484 28580  1970  6234  1886\n"," 13994   987 12293  7500  6354  4882 29182  2520 13085 25315  5465 11160\n","   992  9920  1974  7380  1591 11330 10959 16427 15227  1951  1972  2005\n","  2873 19074 20205 18766 11510  3699 20553 12858  3917  4395 20393 20895\n"," 16571  3539  4848  1339  5238 22801  4725  8863 11324  5007  5664 10089\n"," 17750 21418  2867  5527 24382  9932 13064 19624  1674  1950 21241  8351\n","  3306  3174  5132  2684 26454  7499  3402  3275  8264  6846 28037 17981\n"," 13228  6623 15302 24299  7010 19031  9992  6684  1524  4338  7670  3745\n","  3466  3823  5977  3857]\n","[2][0] loss[0] 0.5253410115838051 (0.5469861850142479)\n","[2][1] loss[1] 0.5224781036376953 (0.5469861850142479)\n","[2][2] loss[2] 0.5333079025149345 (0.5469861850142479)\n","[2][3] loss[3] 0.4586494714021683 (0.5469861850142479)\n","[2][4] loss[4] 0.49785415828227997 (0.5469861850142479)\n","[2][5] loss[5] 0.5103384107351303 (0.5469861850142479)\n","[2][6] loss[6] 0.4310344532132149 (0.5469861850142479)\n","[2][7] loss[7] 0.5169643461704254 (0.5469861850142479)\n","[2][8] loss[8] 0.4938805401325226 (0.5469861850142479)\n","[2][9] loss[9] 0.6157253459095955 (0.6157253459095955)\n","[2][10] loss[10] 0.5786240547895432 (0.6157253459095955)\n","[2][11] loss[11] 0.5301700010895729 (0.6157253459095955)\n","[2][12] loss[12] 0.541773609817028 (0.6157253459095955)\n","[2][13] loss[13] 0.5806472152471542 (0.6157253459095955)\n","[2][14] loss[14] 0.5276438519358635 (0.6157253459095955)\n","[2][15] loss[15] 0.6159203574061394 (0.6159203574061394)\n","[2][16] loss[16] 0.4323977530002594 (0.6159203574061394)\n","[2][17] loss[17] 0.4454369768500328 (0.6159203574061394)\n","[2][18] loss[18] 0.5093025863170624 (0.6159203574061394)\n","[2][19] loss[19] 0.45657264441251755 (0.6159203574061394)\n","[2][20] loss[20] 0.5107688754796982 (0.6159203574061394)\n","[2][21] loss[21] 0.5635907128453255 (0.6159203574061394)\n","[2][22] loss[22] 0.450901634991169 (0.6159203574061394)\n","[2][23] loss[23] 0.5779568925499916 (0.6159203574061394)\n","[2][24] loss[24] 0.6099003702402115 (0.6159203574061394)\n","[2][25] loss[25] 0.5574101507663727 (0.6159203574061394)\n","[2][26] loss[26] 0.5121906846761703 (0.6159203574061394)\n","[2][27] loss[27] 0.5429200530052185 (0.6159203574061394)\n","[2][28] loss[28] 0.5313510671257973 (0.6159203574061394)\n","[2][29] loss[29] 0.5365418717265129 (0.6159203574061394)\n","[2][30] loss[30] 0.45635656267404556 (0.6159203574061394)\n","[2][31] loss[31] 0.5419338271021843 (0.6159203574061394)\n","[2][32] loss[32] 0.5634558275341988 (0.6159203574061394)\n","[2][33] loss[33] 0.5171412080526352 (0.6159203574061394)\n","[2][34] loss[34] 0.5007192939519882 (0.6159203574061394)\n","[2][35] loss[35] 0.5355828478932381 (0.6159203574061394)\n","[2][36] loss[36] 0.5588643327355385 (0.6159203574061394)\n","[2][37] loss[37] 0.4966171681880951 (0.6159203574061394)\n","[2][38] loss[38] 0.5636590421199799 (0.6159203574061394)\n","[2][39] loss[39] 0.6312653869390488 (0.6312653869390488)\n","[2][40] loss[40] 0.5213886052370071 (0.6312653869390488)\n","[2][41] loss[41] 0.5349401533603668 (0.6312653869390488)\n","[2][42] loss[42] 0.5286948010325432 (0.6312653869390488)\n","[2][43] loss[43] 0.46331503242254257 (0.6312653869390488)\n","[2][44] loss[44] 0.520948976278305 (0.6312653869390488)\n","[2][45] loss[45] 0.4671914353966713 (0.6312653869390488)\n","[2][46] loss[46] 0.4819781184196472 (0.6312653869390488)\n","[2][47] loss[47] 0.42901814728975296 (0.6312653869390488)\n","[2][48] loss[48] 0.532207302749157 (0.6312653869390488)\n","[2][49] loss[49] 0.5316406637430191 (0.6312653869390488)\n","[2][50] loss[50] 0.45330677181482315 (0.6312653869390488)\n","[2][51] loss[51] 0.5882146582007408 (0.6312653869390488)\n","[2][52] loss[52] 0.43335750699043274 (0.6312653869390488)\n","[2][53] loss[53] 0.5109191164374352 (0.6312653869390488)\n","[2][54] loss[54] 0.5516135394573212 (0.6312653869390488)\n","[2][55] loss[55] 0.503212183713913 (0.6312653869390488)\n","[2][56] loss[56] 0.5332642421126366 (0.6312653869390488)\n","[2][57] loss[57] 0.5832520052790642 (0.6312653869390488)\n","[2][58] loss[58] 0.5903002023696899 (0.6312653869390488)\n","[2][59] loss[59] 0.5566781684756279 (0.6312653869390488)\n","[2][60] loss[60] 0.5899098515510559 (0.6312653869390488)\n","[2][61] loss[61] 0.4912448152899742 (0.6312653869390488)\n","[2][62] loss[62] 0.397666297852993 (0.6312653869390488)\n","[2][63] loss[63] 0.46904000639915466 (0.6312653869390488)\n","[2][64] loss[64] 0.41855488717556 (0.6312653869390488)\n","[2][65] loss[65] 0.45930010080337524 (0.6312653869390488)\n","[2][66] loss[66] 0.5914180874824524 (0.6312653869390488)\n","[2][67] loss[67] 0.49778522551059723 (0.6312653869390488)\n","[2][68] loss[68] 0.48620952665805817 (0.6312653869390488)\n","[2][69] loss[69] 0.5076198950409889 (0.6312653869390488)\n","[2][70] loss[70] 0.644255705177784 (0.644255705177784)\n","[2][71] loss[71] 0.4540582224726677 (0.644255705177784)\n","[2][72] loss[72] 0.6072957962751389 (0.644255705177784)\n","[2][73] loss[73] 0.5378639474511147 (0.644255705177784)\n","[2][74] loss[74] 0.49817077070474625 (0.644255705177784)\n","[2][75] loss[75] 0.5689906924962997 (0.644255705177784)\n","[2][76] loss[76] 0.4956141710281372 (0.644255705177784)\n","[2][77] loss[77] 0.5460979416966438 (0.644255705177784)\n","[2][78] loss[78] 0.54671710729599 (0.644255705177784)\n","[2][79] loss[79] 0.49010562896728516 (0.644255705177784)\n","[2][80] loss[80] 0.47075632214546204 (0.644255705177784)\n","[2][81] loss[81] 0.59455306828022 (0.644255705177784)\n","[2][82] loss[82] 0.5054252296686172 (0.644255705177784)\n","[2][83] loss[83] 0.5357050374150276 (0.644255705177784)\n","[2][84] loss[84] 0.49943384528160095 (0.644255705177784)\n","[2][85] loss[85] 0.5544520393013954 (0.644255705177784)\n","[2][86] loss[86] 0.49552513659000397 (0.644255705177784)\n","[2][87] loss[87] 0.513682909309864 (0.644255705177784)\n","[2][88] loss[88] 0.4629876911640167 (0.644255705177784)\n","[2][89] loss[89] 0.5307457521557808 (0.644255705177784)\n","[2][90] loss[90] 0.5545673742890358 (0.644255705177784)\n","[2][91] loss[91] 0.4724864214658737 (0.644255705177784)\n","[2][92] loss[92] 0.4660797789692879 (0.644255705177784)\n","[2][93] loss[93] 0.4603457823395729 (0.644255705177784)\n","[2][94] loss[94] 0.5244900211691856 (0.644255705177784)\n","[2][95] loss[95] 0.5345291197299957 (0.644255705177784)\n","[2][96] loss[96] 0.4818778932094574 (0.644255705177784)\n","[2][97] loss[97] 0.6151305660605431 (0.644255705177784)\n","[2][98] loss[98] 0.502967432141304 (0.644255705177784)\n","[2][99] loss[99] 0.626083716750145 (0.644255705177784)\n","Best loss 0.644255705177784 with candidates [621, 4865, 21241]\n"]}]},{"cell_type":"code","source":["print(tokenizer.decode([621, 4865, 21241]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdhC5LNWQk_x","executionInfo":{"status":"ok","timestamp":1657498899481,"user_tz":-120,"elapsed":236,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"287e6fe8-a055-4d20-d011-2e7b83d67138"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["unlessidae normativ\n"]}]},{"cell_type":"code","source":["\"\"\"\n","extracted_grads = []\n","model.eval()\n","model.to(device)\n","loss_obtained = get_loss_and_metrics(model, dataloader, device)\n","print(f'loss_obtained {loss_obtained}')\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"S4JCX2TmE_yA","executionInfo":{"status":"ok","timestamp":1657498864417,"user_tz":-120,"elapsed":52,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"d239df52-9bce-42c5-8f76-d05897e00375"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nextracted_grads = []\\nmodel.eval()\\nmodel.to(device)\\nloss_obtained = get_loss_and_metrics(model, dataloader, device)\\nprint(f'loss_obtained {loss_obtained}')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["\"\"\"\n","extracted_grads = []\n","\n","# get initial loss for the trigger\n","model.zero_grad()\n","loss = get_loss(model, BATCH_SIZE, trigger_tokens, target_tokens, device)\n","best_loss = loss\n","counter = 0\n","end_iter = False\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"-nddZPP1B1RJ","executionInfo":{"status":"ok","timestamp":1657498864418,"user_tz":-120,"elapsed":47,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"77bc33c5-d242-42d0-ff51-892871a19550"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nextracted_grads = []\\n\\n# get initial loss for the trigger\\nmodel.zero_grad()\\nloss = get_loss(model, BATCH_SIZE, trigger_tokens, target_tokens, device)\\nbest_loss = loss\\ncounter = 0\\nend_iter = False\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["\"\"\"\n","del extracted_grads\n","del dataloader\n","del model\n","del input_ids\n","del attention_masks\n","del labels\n","del loss_obtained\n","del dataset\n","\"\"\""],"metadata":{"id":"3IWgPUFKkRy1","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1657498864418,"user_tz":-120,"elapsed":44,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"4a651677-3c6c-4b8f-f900-219f7103bb8a"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndel extracted_grads\\ndel dataloader\\ndel model\\ndel input_ids\\ndel attention_masks\\ndel labels\\ndel loss_obtained\\ndel dataset\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["\"\"\"import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vDMAFktYISWA","executionInfo":{"status":"ok","timestamp":1657498864419,"user_tz":-120,"elapsed":42,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"7ca4f847-7e0d-49a7-c683-ec35fbea292a"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'import torch, gc\\ngc.collect()\\ntorch.cuda.empty_cache()\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["len(extracted_grads)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4QJtyr7K8oc","executionInfo":{"status":"ok","timestamp":1657498864420,"user_tz":-120,"elapsed":39,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"97fddde6-37ac-4ad0-f174-5eead5f2210f"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["input_ids[0][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7cGz0zGLVeL","executionInfo":{"status":"ok","timestamp":1657498864421,"user_tz":-120,"elapsed":35,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"2c3a30cb-6f68-4729-98bd-2bf225a0b410"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(621)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[""],"metadata":{"id":"y5TYKJ9aUK6o","executionInfo":{"status":"ok","timestamp":1657498864422,"user_tz":-120,"elapsed":33,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":37,"outputs":[]}]}