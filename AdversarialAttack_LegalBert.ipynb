{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AdversarialAttack_LegalBert.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNtfaHB67hR3on8avgCy7Yi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Adversarial attacks against Legal-BERT Model (BertForSequenceClassification)"],"metadata":{"id":"MXqml7sZuRKJ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Vgl8t7lyuGJa","executionInfo":{"status":"ok","timestamp":1657657061716,"user_tz":-120,"elapsed":5,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"outputs":[],"source":["# Global variables\n","\n","BATCH_SIZE = 32\n","MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n","EPOCHS = 3\n","EMBEDDING_SIZE = 512\n","NUM_CLASSES = 2\n","VOCABULARY_SIZE = 30522\n","NUM_TOKENS = 6\n"]},{"cell_type":"markdown","source":["### Installation of packages"],"metadata":{"id":"XCxFkLyZuvz0"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install torch-lr-finder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3e7ptYOuwQl","executionInfo":{"status":"ok","timestamp":1657657070531,"user_tz":-120,"elapsed":8819,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"b9752ed5-f364-4d3e-a912-9d4199df8b62"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.64.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.21.6)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.12.0+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.1.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.4.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n"]}]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"yfPJufE5vMkb"}},{"cell_type":"code","source":["import torch\n","import os\n","from transformers import BertTokenizer\n","from google.colab import drive\n","from torch.utils.data import TensorDataset, random_split\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import gc\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from copy import deepcopy"],"metadata":{"id":"aPfzDo8hvPBZ","executionInfo":{"status":"ok","timestamp":1657657074996,"user_tz":-120,"elapsed":4469,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Device"],"metadata":{"id":"_oG87aJ3vWxK"}},{"cell_type":"code","source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQKxA_5MvV0w","executionInfo":{"status":"ok","timestamp":1657657074997,"user_tz":-120,"elapsed":10,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"116ee070-de4c-4521-a95e-2b0b63a2c80f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"markdown","source":["### Reading dataset"],"metadata":{"id":"9PTbIu43vb0-"}},{"cell_type":"code","source":["# Mount drive to have access to your files\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/\"Colab Notebooks\"/DefenseAdvAttacks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2dsmYWRXvcPc","executionInfo":{"status":"ok","timestamp":1657657077002,"user_tz":-120,"elapsed":2009,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"dd953eec-35fd-4e43-ff60-c4e9b24b0311"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/DefenseAdvAttacks\n"]}]},{"cell_type":"code","source":["# Funtion to read all sentences\n","def get_sentences(path):\n","    sentences= []\n","    for filename in os.listdir(path):\n","        with open(path+filename, 'r') as f:\n","            for sentence in f :\n","                sentences.append(sentence)\n","    return sentences"],"metadata":{"id":"knj4Vy1wwsfI","executionInfo":{"status":"ok","timestamp":1657657077002,"user_tz":-120,"elapsed":7,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Function to read get all labels\n","def get_labels(path):\n","    all_labels = []\n","    for filename in os.listdir(path):\n","        file_labels = []\n","        with open(path+filename, 'r') as f:\n","            for label in f :\n","                all_labels.append(int(label))\n","    return all_labels"],"metadata":{"id":"utKztVafwtnw","executionInfo":{"status":"ok","timestamp":1657657077003,"user_tz":-120,"elapsed":8,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Reading sentences and labels\n","all_sentences = get_sentences(\"ToS/Sentences/\")\n","all_labels = get_labels(\"ToS/Labels/\")"],"metadata":{"id":"mkp9MZKewxDN","executionInfo":{"status":"ok","timestamp":1657657077003,"user_tz":-120,"elapsed":7,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Since unfair sentences are marked as \"-1\", we change them to \"0\" for simplicity. Zero means fair, One means unfair\n","all_labels =  [0 if label ==-1 else label for label in all_labels]"],"metadata":{"id":"bnor58FKwxy2","executionInfo":{"status":"ok","timestamp":1657657077003,"user_tz":-120,"elapsed":7,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Bert Tokenizer"],"metadata":{"id":"jU5yamL5xKAY"}},{"cell_type":"code","source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True) # the model 'bert-base-uncased' only contains lower case sentences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMiwR7ldxLwC","executionInfo":{"status":"ok","timestamp":1657657078531,"user_tz":-120,"elapsed":1534,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"d20e74ca-47b9-49ec-8fe5-aaf3b35a2860"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]}]},{"cell_type":"code","source":["# ==> Example of first sentence\n","\n","# Print the original sentence.\n","print(' Original: ', all_sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(all_sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(all_sentences[0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgT3sO20xPtj","executionInfo":{"status":"ok","timestamp":1657657078532,"user_tz":-120,"elapsed":11,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"f32892e2-92a0-415a-ba01-32de603cfd71"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":[" Original:  * accepting the terms of service \n","\n","Tokenized:  ['*', 'accept', '##ing', 'the', 'terms', 'of', 'service']\n","Token IDs:  [113, 1599, 235, 207, 333, 210, 446]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","# ==> Get the max length of a sentence\n","\n","max_len = 0\n","\n","# For every sentence...\n","for sent in all_sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)\n","# Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n","# Max sentence length:  598\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"c-uE6jBuxRjZ","executionInfo":{"status":"ok","timestamp":1657657078533,"user_tz":-120,"elapsed":7,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"e79b7ff5-d6c4-4b74-d790-0af4f1772a7c"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# ==> Get the max length of a sentence\\n\\nmax_len = 0\\n\\n# For every sentence...\\nfor sent in all_sentences:\\n\\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\\n    input_ids = tokenizer.encode(sent, add_special_tokens=True)\\n\\n    # Update the maximum sentence length.\\n    max_len = max(max_len, len(input_ids))\\n\\nprint('Max sentence length: ', max_len)\\n# Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\\n# Max sentence length:  598\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### Model BertForSequenceClassification (Load model)"],"metadata":{"id":"JpohQx5xyqwh"}},{"cell_type":"code","source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = NUM_CLASSES, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tkpyAA69yuEO","executionInfo":{"status":"ok","timestamp":1657657082502,"user_tz":-120,"elapsed":3975,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"48d2cf97-2a2f-48c6-a5f2-6d3ba6798323"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n","      (position_embeddings): Embedding(512, 512)\n","      (token_type_embeddings): Embedding(2, 512)\n","      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=512, out_features=512, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Load the model and dictionary\n","model.load_state_dict(torch.load('Bert4SeqClassif_202207072015.pt'))#, map_location=torch.device('cpu') or cuda. Both work\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-aGx3Q60e4w","executionInfo":{"status":"ok","timestamp":1657657082742,"user_tz":-120,"elapsed":267,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"6b926eca-6387-47a8-983d-33d587d8fc7a"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["### Trigger generation"],"metadata":{"id":"JIyze6jK2bpQ"}},{"cell_type":"markdown","source":["##### General functions"],"metadata":{"id":"mLTLH3AJ5-Lw"}},{"cell_type":"code","source":["# hook used in add_hooks()\n","extracted_grads = []\n","def extract_grad_hook(module, grad_in, grad_out):\n","    extracted_grads.append(grad_out[0])"],"metadata":{"id":"8JjcRhGE6hUc","executionInfo":{"status":"ok","timestamp":1657657082744,"user_tz":-120,"elapsed":7,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# returns the wordpiece embedding weight matrix\n","def get_embedding_weight(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522: # only add a hook to wordpiece embeddings, not position embeddings \n","                ##50257 is the size of the vocabulary of GPT\n","                return module.weight.detach()"],"metadata":{"id":"1MV3isar2dvF","executionInfo":{"status":"ok","timestamp":1657657082745,"user_tz":-120,"elapsed":7,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# add hooks for embeddings\n","def add_hooks(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522: # only add a hook to wordpiece embeddings, not position\n","                ##50257 is the size of the vocabulary of GPT\n","                module.weight.requires_grad = True\n","                #module.register_backward_hook(extract_grad_hook)\n","                module.register_full_backward_hook(extract_grad_hook)"],"metadata":{"id":"ymN2vLUT6Oe5","executionInfo":{"status":"ok","timestamp":1657657082746,"user_tz":-120,"elapsed":8,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Gets the loss of the target_tokens using the triggers as the context\n","def get_loss(language_model, batch_size, trigger, target, device='cuda'):\n","    # context is trigger repeated batch size\n","    print(f'Arrive to get_loss\\n\\t batch_size {batch_size}\\n\\t trigger {trigger.shape}\\n\\t target {target.shape}')\n","    print(f'LANGUAGE_MODEL {language_model}')\n","    tensor_trigger = torch.tensor(trigger, device=device, dtype=torch.long).unsqueeze(0).repeat(batch_size, 1)\n","    print(f'tensor_trigger {tensor_trigger}')\n","    mask_out = -1 * torch.ones_like(tensor_trigger) # we zero out the loss for the trigger tokens\n","    print(f'mask_out {mask_out}')\n","    lm_input = torch.cat((tensor_trigger, target), dim=1) # we feed the model the trigger + target texts\n","    print(f'lm_input {lm_input.shape} == {lm_input}')\n","    print(f'lm_input[0] {lm_input[0]}')\n","    mask_and_target = torch.cat((mask_out, target), dim=1) # has -1's + target texts for loss computation\n","    print(f'mask_and_target {mask_and_target.shape} == {mask_and_target}')\n","    lm_input[lm_input == -1] = 1   # put random token of 1 at end of context (its masked out)\n","    print(f'lm_input {lm_input.shape} == {lm_input}')\n","    loss = language_model(lm_input, labels=mask_and_target)#[0]\n","    print(f'loss {loss}')\n","    return loss"],"metadata":{"id":"nZOz1INA6WeB","executionInfo":{"status":"ok","timestamp":1657657082747,"user_tz":-120,"elapsed":9,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# creates the batch of target texts with -1 placed at the end of the sequences for padding (for masking out the loss).\n","def make_target_batch(tokenizer, device, target_texts):\n","    # encode items and get the max length\n","    encoded_texts = []\n","    max_len = 0\n","    for target_text in target_texts:\n","        encoded_target_text = tokenizer.encode_plus(\n","            target_text,\n","            add_special_tokens = True,\n","            max_length = EMBEDDING_SIZE - NUM_TOKENS,\n","            pad_to_max_length = True,\n","            return_attention_mask = True\n","        )\n","        #print(f'ENCODED_TARGET_TEXT {type(input_ids)} == {encoded_target_text.keys()}') # ENCODED_TARGET_TEXT <class 'list'> == dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","        \"\"\"\n","        print(f'ENCODED_TARGET_TEXT {type(encoded_target_text)} == {encoded_target_text}')\n","        ENCODED_TARGET_TEXT <class 'list'> == [101, 218, 4527, 237, 366, 212, 1260, 207, 446, 115, 799, 2277, 212, 781, 216, 119, 102]\n","        ENCODED_TARGET_TEXT <class 'list'> == [101, 799, 356, 432, 145, 782, 438, 225, 3457, 13409, 115, 102]\n","        \"\"\"\n","        encoded_texts.append(encoded_target_text.input_ids)\n","        if len(encoded_target_text.input_ids) > max_len:\n","            max_len = len(encoded_target_text)\n","\n","    # pad tokens, i.e., append -1 to the end of the non-longest ones\n","    for indx, encoded_text in enumerate(encoded_texts):\n","        if len(encoded_text) < max_len:\n","            encoded_texts[indx].extend([-1] * (max_len - len(encoded_text)))\n","\n","    # convert to tensors and batch them up\n","    target_tokens_batch = None\n","    for encoded_text in encoded_texts:\n","        target_tokens = torch.tensor(encoded_text, device=device, dtype=torch.long).unsqueeze(0)\n","        if target_tokens_batch is None:\n","            target_tokens_batch = target_tokens\n","        else:\n","            target_tokens_batch = torch.cat((target_tokens, target_tokens_batch), dim=0)\n","    return target_tokens_batch"],"metadata":{"id":"73ZQsJW_6z3h","executionInfo":{"status":"ok","timestamp":1657657083096,"user_tz":-120,"elapsed":357,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Got from https://github.com/Eric-Wallace/universal-triggers/blob/master/attacks.py\n","\n","def hotflip_attack(averaged_grad, embedding_matrix, trigger_token_ids,\n","                   increase_loss=False, num_candidates=1):\n","    \"\"\"\n","    The \"Hotflip\" attack described in Equation (2) of the paper. This code is heavily inspired by\n","    the nice code of Paul Michel here https://github.com/pmichel31415/translate/blob/paul/\n","    pytorch_translate/research/adversarial/adversaries/brute_force_adversary.py\n","    This function takes in the model's average_grad over a batch of examples, the model's\n","    token embedding matrix, and the current trigger token IDs. It returns the top token\n","    candidates for each position.\n","    If increase_loss=True, then the attack reverses the sign of the gradient and tries to increase\n","    the loss (decrease the model's probability of the true class). For targeted attacks, you want\n","    to decrease the loss of the target class (increase_loss=False).\n","    \"\"\"\n","    averaged_grad = averaged_grad.cpu()\n","    embedding_matrix = embedding_matrix.cpu()\n","    trigger_token_embeds = torch.nn.functional.embedding(torch.LongTensor(trigger_token_ids),\n","                                                         embedding_matrix).detach().unsqueeze(0)\n","    averaged_grad = averaged_grad.unsqueeze(0)\n","    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n","                                                 (averaged_grad, embedding_matrix))        \n","    if not increase_loss:\n","        gradient_dot_embedding_matrix *= -1    # lower versus increase the class probability.\n","    if num_candidates > 1: # get top k options\n","        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n","        return best_k_ids.detach().cpu().numpy()[0]\n","    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n","    return best_at_each_step[0].detach().cpu().numpy()"],"metadata":{"id":"DQ0ZcgVCCHmY","executionInfo":{"status":"ok","timestamp":1657657083097,"user_tz":-120,"elapsed":24,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def get_input_masks_and_labels_with_tokens(sentences, labels, tokens):\n","    input_ids = []\n","    attention_masks = []\n","\n","    # For every sentence...\n","    for sent in sentences:\n","        # `encode_plus` will:\n","        #   (1) Tokenize the sentence.\n","        #   (2) Prepend the `[CLS]` token to the start.\n","        #   (3) Append the `[SEP]` token to the end.\n","        #   (4) Map tokens to their IDs.\n","        #   (5) Pad or truncate the sentence to `max_length`\n","        #   (6) Create attention masks for [PAD] tokens.\n","        sent_with_tokens = \" \".join(tokens) + \" \" + sent\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True, #is deprecated\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","        \n","        # Add the encoded sentence to the list.    \n","        input_ids.append(encoded_dict['input_ids'])\n","\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    # Convert the lists into tensors.\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","\n","    return input_ids, attention_masks, labels"],"metadata":{"id":"lV7lkCZP731g","executionInfo":{"status":"ok","timestamp":1657657083097,"user_tz":-120,"elapsed":23,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def get_loss_and_metrics(model, dataloader, device):\n","    # get initial loss for the trigger\n","    model.zero_grad()\n","\n","    test_preds = []\n","    test_targets = []\n","\n","    # Tracking variables \n","    total_test_accuracy = 0\n","    total_test_loss = 0\n","    io_total_test_acc = 0\n","    io_total_test_prec = 0\n","    io_total_test_recall = 0\n","    io_total_test_f1 = 0\n","\n","    for batch in dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        result = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels,\n","                    return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Accumulate the validation loss.\n","        total_test_loss += loss.item()\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        loss.backward()        \n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.        \n","        test_acc = accuracy_score(test_targets, test_preds)\n","        test_precision = precision_score(test_targets, test_preds)\n","        test_recall = recall_score(test_targets, test_preds)\n","        test_f1 = f1_score(test_targets, test_preds)\n","\n","        io_total_test_acc += test_acc\n","        io_total_test_prec += test_precision\n","        io_total_test_recall += test_recall\n","        io_total_test_f1 += test_f1\n","\n","    io_avg_test_loss = total_test_loss/len(dataloader)\n","    io_avg_test_acc = io_total_test_acc / len(dataloader)\n","    io_avg_test_prec = io_total_test_prec / len(dataloader)\n","    io_avg_test_recall = io_total_test_recall / len(dataloader)\n","    io_avg_test_f1 = io_total_test_f1 / len(dataloader)\n","    print(\n","            f'Loss {io_avg_test_loss} : \\t\\\n","            Valid_acc : {io_avg_test_acc}\\t\\\n","            Valid_F1 : {io_avg_test_f1}\\t\\\n","            Valid_precision : {io_avg_test_prec}\\t\\\n","            Valid_recall : {io_avg_test_recall}'\n","          )\n","\n","    #print(f\"total_test_loss {total_test_loss/len(dataloader)}\")\n","\n","    return io_avg_test_loss, io_avg_test_acc, io_avg_test_prec, io_avg_test_recall, io_avg_test_f1"],"metadata":{"id":"myWBJ3tc-XCR","executionInfo":{"status":"ok","timestamp":1657657083098,"user_tz":-120,"elapsed":24,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def change_input_ids_with_candidate_token(input_ids, position, candidate):\n","    for elem in range(input_ids.shape[0]):\n","        input_ids[elem][position] = candidate\n","\n","    return input_ids"],"metadata":{"id":"o-ZoFvcJXsH5","executionInfo":{"status":"ok","timestamp":1657657083098,"user_tz":-120,"elapsed":23,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"NfnLkgMPgMui","executionInfo":{"status":"ok","timestamp":1657657083099,"user_tz":-120,"elapsed":24,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["### Get positions of unfair sentences\n","\n","positions_unfair = np.where(np.array(all_labels) == 1)[0]\n","print(f'First 32 positions: {positions_unfair[0:32]} with total of unfair sentences {len(positions_unfair)}')\n","\n","target_unfair_sentences = []\n","labels_unfair_sentences = []\n","for index in range(len(positions_unfair)):\n","    target_unfair_sentences.append(all_sentences[positions_unfair[index]])\n","    labels_unfair_sentences.append(all_labels[positions_unfair[index]])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cr3D9l6q8CD5","executionInfo":{"status":"ok","timestamp":1657657083099,"user_tz":-120,"elapsed":24,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"b8d55b7d-5373-4925-f263-d811d38d34ba"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["First 32 positions: [  4   9  10  11  12  13  24  25  43  45  61  62  78  79  87  89  91  92\n"," 100 104 109 111 143 151 154 157 169 195 206 258 260 266] with total of unfair sentences 1032\n"]}]},{"cell_type":"code","source":["model.eval()\n","model.to(device)\n","\n","add_hooks(model) # add gradient hooks to embeddings\n","embedding_weight = get_embedding_weight(model) # save the word embedding matrix"],"metadata":{"id":"Q9b_Vpns66cA","executionInfo":{"status":"ok","timestamp":1657657083100,"user_tz":-120,"elapsed":17,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(f'embedding_weight {embedding_weight} \\n\\nwith shape {embedding_weight.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c_bgvnKs7Gt1","executionInfo":{"status":"ok","timestamp":1657657083100,"user_tz":-120,"elapsed":17,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"79572f78-29f4-4155-bb36-49f0e14c4e98"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["embedding_weight tensor([[ 0.0641, -0.0185, -0.0232,  ..., -0.0211,  0.0466, -0.0678],\n","        [-0.0175,  0.0522, -0.1289,  ..., -0.0658,  0.0291, -0.1561],\n","        [ 0.0128, -0.0119, -0.0850,  ..., -0.0592,  0.0799, -0.1387],\n","        ...,\n","        [ 0.0040,  0.0531, -0.0814,  ...,  0.0393,  0.0525, -0.0063],\n","        [-0.0143,  0.0036, -0.0973,  ..., -0.0562,  0.0196, -0.1135],\n","        [-0.0785, -0.0090, -0.1799,  ...,  0.0115,  0.0191, -0.0859]],\n","       device='cuda:0') \n","\n","with shape torch.Size([30522, 512])\n"]}]},{"cell_type":"code","source":["#target_tokens = make_target_batch(tokenizer, device, target_sentences)\n","\n","#target_tokens.shape\n","\n","# sample random initial trigger\n","#trigger_tokens = np.array([621, 19353, 7063])#np.array([598, 275, 3523])#np.random.randint(VOCABULARY_SIZE, size=NUM_TOKENS)\n","trigger_tokens = np.array([207, 207, 207, 207, 207, 207])\n","print(tokenizer.decode(trigger_tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TN1TmoB_Asb","executionInfo":{"status":"ok","timestamp":1657657083100,"user_tz":-120,"elapsed":15,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"fe398371-265f-4d95-e8b5-b9be3b1addd3"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["the the the the the the\n"]}]},{"cell_type":"code","source":["#trigger_tokens #.shape (3,) => array([ 8972, 27350, 25382])\n","#target_tokens #.shape => torch.Size([32, 163])\n","\"\"\"\n","tensor([[  101, 12017,   179,  ...,    -1,    -1,    -1],\n","        [  101,   233,   223,  ...,    -1,    -1,    -1],\n","        [  101, 12017,   179,  ...,    -1,    -1,    -1],\n","        ...,\n","        [  101,   206,  4313,  ...,    -1,    -1,    -1],\n","        [  101,   206,  4313,  ...,    -1,    -1,    -1],\n","        [  101,   218,  1260,  ...,    -1,    -1,    -1]], device='cuda:0')\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"ujMeErAoGyl8","executionInfo":{"status":"ok","timestamp":1657657083101,"user_tz":-120,"elapsed":13,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"2f52af9b-df35-4a77-9004-6f7a3f48b098"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ntensor([[  101, 12017,   179,  ...,    -1,    -1,    -1],\\n        [  101,   233,   223,  ...,    -1,    -1,    -1],\\n        [  101, 12017,   179,  ...,    -1,    -1,    -1],\\n        ...,\\n        [  101,   206,  4313,  ...,    -1,    -1,    -1],\\n        [  101,   206,  4313,  ...,    -1,    -1,    -1],\\n        [  101,   218,  1260,  ...,    -1,    -1,    -1]], device='cuda:0')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["input_ids, attention_masks, labels = get_input_masks_and_labels_with_tokens(target_unfair_sentences, labels_unfair_sentences, tokenizer.decode(trigger_tokens))\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuqGPIZ9bsM4","executionInfo":{"status":"ok","timestamp":1657657085657,"user_tz":-120,"elapsed":2568,"user":{"displayName":"Isaac Olguín","userId":"09697151780329788960"}},"outputId":"d37a2b6e-194b-4787-b7b0-f7e9f649cf8f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["\n","extracted_grads = []\n","\n","#loss_obtained = get_loss_and_metrics(model, dataloader, device)\n","loss_obtained, acc_obtained, prec_obtained, recall_obtained, f1_obtained = get_loss_and_metrics(model, dataloader, device)\n","#print(f'loss_obtained {loss_obtained}')\n","print(f'f1_obtained {f1_obtained}')\n","\n","#best_loss = loss_obtained\n","candidates_selented = [0,0,0,0,0]\n","# try all the candidates and pick the best\n","curr_best_loss = f1_obtained\n","curr_best_trigger_tokens = None\n","\n","for id_token_to_flip in range(0, NUM_TOKENS):\n","    # Get average gradient w.r.t. the triggers\n","    #extracted_grads = []\n","    #loss_obtained.backward()\n","\n","    averaged_grad = torch.sum(extracted_grads[0], dim=0)\n","    averaged_grad = averaged_grad[id_token_to_flip].unsqueeze(0)\n","\n","    # Use hotflip (linear approximation) attack to get the top num_candidates\n","    candidates = hotflip_attack(averaged_grad, embedding_weight,\n","                                        [trigger_tokens[id_token_to_flip]], \n","                                        increase_loss=False, num_candidates=100)[0]\n","    print(f'candidates {candidates}')\n","    \n","    for index, cand in enumerate(candidates):\n","        # replace one token with new candidate\n","        extracted_grads = []\n","\n","        input_ids_with_candidate_trigger = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, cand)\n","        dataset_with_candidate_trigger = TensorDataset(input_ids_with_candidate_trigger, attention_masks, labels)\n","        dataloader_with_candidate_trigger = torch.utils.data.DataLoader(dataset_with_candidate_trigger, batch_size=BATCH_SIZE)\n","\n","        #current_loss = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device)\n","        current_loss, current_acc, current_prec, current_recall, current_f1 = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device)\n","\n","        if curr_best_loss > current_f1:\n","            curr_best_loss = current_f1\n","            candidates_selented[id_token_to_flip] = cand\n","\n","        del input_ids_with_candidate_trigger\n","        del dataset_with_candidate_trigger\n","        del dataloader_with_candidate_trigger\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        #print(f'[{id_token_to_flip}][{index}] loss[{index}] {current_loss} ({curr_best_loss})')\n","        print(f'[{id_token_to_flip}][{index}] f1[{index}] {current_f1} ({curr_best_loss})')\n","    input_ids = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, candidates_selented[id_token_to_flip])\n","    print(f'Worst f1 {curr_best_loss} with candidates {candidates_selented}')\n","\n","#Best loss 0.5344366431236267 with candidates [598, 275, 3523]\n","#Best loss 0.9147895276546478 with candidates [621, 19353, 7063]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFhC5DN9ggz4","outputId":"e92b4d3e-6f58-4ec6-865b-35d6ccf987a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss 0.3013410616778966 : \t            Valid_acc : 0.919868349164074\t            Valid_F1 : 0.95823260150304\t            Valid_precision : 1.0\t            Valid_recall : 0.919868349164074\n","f1_obtained 0.95823260150304\n","candidates [  457 12986  5102   660  7742   232  2176  2705 10902   587   591  3522\n","  2940  1607  1914   454 20458  6966  1750   378  1890 23836   382  1635\n","  3477   936  1382   679   266  4004   531   572  1672  3626  1401  1753\n","  1731  2126  1363   410  4203  1427  1281  1297   799 18253   318   358\n"," 29799  1050   599  1089  1688   635   782 23272   338  8498   621  1415\n","   226  6665  8628  1807  3774  1375  2127  7455   271  2872   547  2586\n","   644  7784  7110  1327 13056 23357  1924   598  1626  2527  2318  1280\n"," 12491 24438  2090 11472  1073  2764  1735   606  1492   390  1414   435\n","   775  6767  8707   419]\n","Loss 0.3754258453845978 : \t            Valid_acc : 0.8974287983898493\t            Valid_F1 : 0.9458666137005209\t            Valid_precision : 1.0\t            Valid_recall : 0.8974287983898493\n","[0][0] f1[0] 0.9458666137005209 (0.9458666137005209)\n","Loss 0.39919237182898953 : \t            Valid_acc : 0.8789001563991713\t            Valid_F1 : 0.9354977721254886\t            Valid_precision : 1.0\t            Valid_recall : 0.8789001563991713\n","[0][1] f1[1] 0.9354977721254886 (0.9354977721254886)\n","Loss 0.39468200369314715 : \t            Valid_acc : 0.8937628190485949\t            Valid_F1 : 0.9438140170248149\t            Valid_precision : 1.0\t            Valid_recall : 0.8937628190485949\n","[0][2] f1[2] 0.9438140170248149 (0.9354977721254886)\n","Loss 0.3788920162302075 : \t            Valid_acc : 0.8852097026098394\t            Valid_F1 : 0.9390605357920885\t            Valid_precision : 1.0\t            Valid_recall : 0.8852097026098394\n","[0][3] f1[3] 0.9390605357920885 (0.9354977721254886)\n","Loss 0.3088863121740746 : \t            Valid_acc : 0.9147246605054487\t            Valid_F1 : 0.9554153650174951\t            Valid_precision : 1.0\t            Valid_recall : 0.9147246605054487\n","[0][4] f1[4] 0.9554153650174951 (0.9354977721254886)\n","Loss 0.38131764260205353 : \t            Valid_acc : 0.8841730053031481\t            Valid_F1 : 0.9384745909560167\t            Valid_precision : 1.0\t            Valid_recall : 0.8841730053031481\n","[0][5] f1[5] 0.9384745909560167 (0.9354977721254886)\n","Loss 0.3267458108338443 : \t            Valid_acc : 0.9029714821131004\t            Valid_F1 : 0.948977479590846\t            Valid_precision : 1.0\t            Valid_recall : 0.9029714821131004\n","[0][6] f1[6] 0.948977479590846 (0.9354977721254886)\n","Loss 0.3803456136674592 : \t            Valid_acc : 0.892112149612878\t            Valid_F1 : 0.9429231231104331\t            Valid_precision : 1.0\t            Valid_recall : 0.892112149612878\n","[0][7] f1[7] 0.9429231231104331 (0.9354977721254886)\n","Loss 0.25429126225186116 : \t            Valid_acc : 0.9274664963234668\t            Valid_F1 : 0.9623383100155976\t            Valid_precision : 1.0\t            Valid_recall : 0.9274664963234668\n","[0][8] f1[8] 0.9623383100155976 (0.9354977721254886)\n","Loss 0.3491219424388625 : \t            Valid_acc : 0.9015917457672745\t            Valid_F1 : 0.9481953271956076\t            Valid_precision : 1.0\t            Valid_recall : 0.9015917457672745\n","[0][9] f1[9] 0.9481953271956076 (0.9354977721254886)\n","Loss 0.3515628616918217 : \t            Valid_acc : 0.8950236179641852\t            Valid_F1 : 0.9445553228950333\t            Valid_precision : 1.0\t            Valid_recall : 0.8950236179641852\n","[0][10] f1[10] 0.9445553228950333 (0.9354977721254886)\n","Loss 0.4079767833604957 : \t            Valid_acc : 0.8828378336395729\t            Valid_F1 : 0.9377275973892438\t            Valid_precision : 1.0\t            Valid_recall : 0.8828378336395729\n","[0][11] f1[11] 0.9377275973892438 (0.9354977721254886)\n","Loss 0.32125920779777295 : \t            Valid_acc : 0.9101313959905604\t            Valid_F1 : 0.952897593376211\t            Valid_precision : 1.0\t            Valid_recall : 0.9101313959905604\n","[0][12] f1[12] 0.952897593376211 (0.9354977721254886)\n","Loss 0.36214587261730974 : \t            Valid_acc : 0.900737856851781\t            Valid_F1 : 0.9477336548522349\t            Valid_precision : 1.0\t            Valid_recall : 0.900737856851781\n","[0][13] f1[13] 0.9477336548522349 (0.9354977721254886)\n","Loss 0.3379958609514164 : \t            Valid_acc : 0.9061336665011056\t            Valid_F1 : 0.9506975573210475\t            Valid_precision : 1.0\t            Valid_recall : 0.9061336665011056\n","[0][14] f1[14] 0.9506975573210475 (0.9354977721254886)\n","Loss 0.4253707501021298 : \t            Valid_acc : 0.8739468494739168\t            Valid_F1 : 0.9326569774348915\t            Valid_precision : 1.0\t            Valid_recall : 0.8739468494739168\n","[0][15] f1[15] 0.9326569774348915 (0.9326569774348915)\n","Loss 0.36262622927174426 : \t            Valid_acc : 0.9010646630982704\t            Valid_F1 : 0.9479055750852463\t            Valid_precision : 1.0\t            Valid_recall : 0.9010646630982704\n","[0][16] f1[16] 0.9479055750852463 (0.9326569774348915)\n","Loss 0.285569595793883 : \t            Valid_acc : 0.915232978766856\t            Valid_F1 : 0.9557009697848512\t            Valid_precision : 1.0\t            Valid_recall : 0.915232978766856\n","[0][17] f1[17] 0.9557009697848512 (0.9326569774348915)\n","Loss 0.33780856317642965 : \t            Valid_acc : 0.902644552460003\t            Valid_F1 : 0.9487906963598193\t            Valid_precision : 1.0\t            Valid_recall : 0.902644552460003\n","[0][18] f1[18] 0.9487906963598193 (0.9326569774348915)\n","Loss 0.37543854614098865 : \t            Valid_acc : 0.8942719254982142\t            Valid_F1 : 0.9441471548082065\t            Valid_precision : 1.0\t            Valid_recall : 0.8942719254982142\n","[0][19] f1[19] 0.9441471548082065 (0.9326569774348915)\n","Loss 0.45387115306926495 : \t            Valid_acc : 0.8559013416036058\t            Valid_F1 : 0.9222830800666159\t            Valid_precision : 1.0\t            Valid_recall : 0.8559013416036058\n","[0][20] f1[20] 0.9222830800666159 (0.9222830800666159)\n","Loss 0.3169024099003185 : \t            Valid_acc : 0.9102608244934747\t            Valid_F1 : 0.9529769491564996\t            Valid_precision : 1.0\t            Valid_recall : 0.9102608244934747\n","[0][21] f1[21] 0.9529769491564996 (0.9222830800666159)\n","Loss 0.35263836451552133 : \t            Valid_acc : 0.8992492245585877\t            Valid_F1 : 0.9468725041762418\t            Valid_precision : 1.0\t            Valid_recall : 0.8992492245585877\n","[0][22] f1[22] 0.9468725041762418 (0.9222830800666159)\n","Loss 0.34055807351162937 : \t            Valid_acc : 0.9014555575540855\t            Valid_F1 : 0.948104263232464\t            Valid_precision : 1.0\t            Valid_recall : 0.9014555575540855\n","[0][23] f1[23] 0.948104263232464 (0.9222830800666159)\n","Loss 0.47599838854688586 : \t            Valid_acc : 0.8604552419701622\t            Valid_F1 : 0.9249341005316771\t            Valid_precision : 1.0\t            Valid_recall : 0.8604552419701622\n","[0][24] f1[24] 0.9249341005316771 (0.9222830800666159)\n","Loss 0.2867599075490778 : \t            Valid_acc : 0.9185269986731596\t            Valid_F1 : 0.9575062970480189\t            Valid_precision : 1.0\t            Valid_recall : 0.9185269986731596\n","[0][25] f1[25] 0.9575062970480189 (0.9222830800666159)\n","Loss 0.3463735126636245 : \t            Valid_acc : 0.9036170652312421\t            Valid_F1 : 0.9493305012849734\t            Valid_precision : 1.0\t            Valid_recall : 0.9036170652312421\n","[0][26] f1[26] 0.9493305012849734 (0.9222830800666159)\n","Loss 0.3610686726416602 : \t            Valid_acc : 0.901207275315603\t            Valid_F1 : 0.9479535890629105\t            Valid_precision : 1.0\t            Valid_recall : 0.901207275315603\n","[0][27] f1[27] 0.9479535890629105 (0.9222830800666159)\n","Loss 0.3043920334541436 : \t            Valid_acc : 0.9175704891037421\t            Valid_F1 : 0.9569518307439053\t            Valid_precision : 1.0\t            Valid_recall : 0.9175704891037421\n","[0][28] f1[28] 0.9569518307439053 (0.9222830800666159)\n","Loss 0.3699042961904497 : \t            Valid_acc : 0.8871860843208101\t            Valid_F1 : 0.9401785365749474\t            Valid_precision : 1.0\t            Valid_recall : 0.8871860843208101\n","[0][29] f1[29] 0.9401785365749474 (0.9222830800666159)\n","Loss 0.335999111560258 : \t            Valid_acc : 0.9069553843405029\t            Valid_F1 : 0.9511314879665109\t            Valid_precision : 1.0\t            Valid_recall : 0.9069553843405029\n","[0][30] f1[30] 0.9511314879665109 (0.9222830800666159)\n","Loss 0.34294590241078177 : \t            Valid_acc : 0.9029410132497543\t            Valid_F1 : 0.9489347546264972\t            Valid_precision : 1.0\t            Valid_recall : 0.9029410132497543\n","[0][31] f1[31] 0.9489347546264972 (0.9222830800666159)\n","Loss 0.3750161770166773 : \t            Valid_acc : 0.900311965437938\t            Valid_F1 : 0.9474731425398152\t            Valid_precision : 1.0\t            Valid_recall : 0.900311965437938\n","[0][32] f1[32] 0.9474731425398152 (0.9222830800666159)\n","Loss 0.39344075186686084 : \t            Valid_acc : 0.890854747927601\t            Valid_F1 : 0.9421561280201787\t            Valid_precision : 1.0\t            Valid_recall : 0.890854747927601\n","[0][33] f1[33] 0.9421561280201787 (0.9222830800666159)\n","Loss 0.31978863037445326 : \t            Valid_acc : 0.9108456803179629\t            Valid_F1 : 0.9532943364273135\t            Valid_precision : 1.0\t            Valid_recall : 0.9108456803179629\n","[0][34] f1[34] 0.9532943364273135 (0.9222830800666159)\n","Loss 0.29614179333051044 : \t            Valid_acc : 0.9192820255134289\t            Valid_F1 : 0.9579075489667033\t            Valid_precision : 1.0\t            Valid_recall : 0.9192820255134289\n","[0][35] f1[35] 0.9579075489667033 (0.9222830800666159)\n","Loss 0.28982739206967933 : \t            Valid_acc : 0.915850170084045\t            Valid_F1 : 0.9560501077964012\t            Valid_precision : 1.0\t            Valid_recall : 0.915850170084045\n","[0][36] f1[36] 0.9560501077964012 (0.9222830800666159)\n","Loss 0.3999004634943875 : \t            Valid_acc : 0.8869008667023213\t            Valid_F1 : 0.9399968643075061\t            Valid_precision : 1.0\t            Valid_recall : 0.8869008667023213\n","[0][37] f1[37] 0.9399968643075061 (0.9222830800666159)\n","Loss 0.3772417916492982 : \t            Valid_acc : 0.8943328811261212\t            Valid_F1 : 0.9441572086312462\t            Valid_precision : 1.0\t            Valid_recall : 0.8943328811261212\n","[0][38] f1[38] 0.9441572086312462 (0.9222830800666159)\n","Loss 0.31680861002568045 : \t            Valid_acc : 0.9076291265096249\t            Valid_F1 : 0.9515294541169633\t            Valid_precision : 1.0\t            Valid_recall : 0.9076291265096249\n","[0][39] f1[39] 0.9515294541169633 (0.9222830800666159)\n","Loss 0.3418292719306368 : \t            Valid_acc : 0.9046303565203642\t            Valid_F1 : 0.9498621913627949\t            Valid_precision : 1.0\t            Valid_recall : 0.9046303565203642\n","[0][40] f1[40] 0.9498621913627949 (0.9222830800666159)\n","Loss 0.36498880702437775 : \t            Valid_acc : 0.8948458648092873\t            Valid_F1 : 0.9444665952959284\t            Valid_precision : 1.0\t            Valid_recall : 0.8948458648092873\n","[0][41] f1[41] 0.9444665952959284 (0.9222830800666159)\n","Loss 0.35640414228493517 : \t            Valid_acc : 0.896198657833705\t            Valid_F1 : 0.9452258151251125\t            Valid_precision : 1.0\t            Valid_recall : 0.896198657833705\n","[0][42] f1[42] 0.9452258151251125 (0.9222830800666159)\n","Loss 0.4306783536166856 : \t            Valid_acc : 0.8701963304438176\t            Valid_F1 : 0.9305234811073728\t            Valid_precision : 1.0\t            Valid_recall : 0.8701963304438176\n","[0][43] f1[43] 0.9305234811073728 (0.9222830800666159)\n","Loss 0.4819538028854312 : \t            Valid_acc : 0.85465371666305\t            Valid_F1 : 0.9215338230723915\t            Valid_precision : 1.0\t            Valid_recall : 0.85465371666305\n","[0][44] f1[44] 0.9215338230723915 (0.9215338230723915)\n","Loss 0.3249031695904154 : \t            Valid_acc : 0.9032873535679896\t            Valid_F1 : 0.9491522298083194\t            Valid_precision : 1.0\t            Valid_recall : 0.9032873535679896\n","[0][45] f1[45] 0.9491522298083194 (0.9215338230723915)\n","Loss 0.43174347371766064 : \t            Valid_acc : 0.87871655655004\t            Valid_F1 : 0.935356976502323\t            Valid_precision : 1.0\t            Valid_recall : 0.87871655655004\n","[0][46] f1[46] 0.935356976502323 (0.9215338230723915)\n","Loss 0.3592444658279419 : \t            Valid_acc : 0.898404392064803\t            Valid_F1 : 0.9464321423083233\t            Valid_precision : 1.0\t            Valid_recall : 0.898404392064803\n","[0][47] f1[47] 0.9464321423083233 (0.9215338230723915)\n","Loss 0.35403270251823193 : \t            Valid_acc : 0.8967571642517054\t            Valid_F1 : 0.9455005254967614\t            Valid_precision : 1.0\t            Valid_recall : 0.8967571642517054\n","[0][48] f1[48] 0.9455005254967614 (0.9215338230723915)\n","Loss 0.29815836329803325 : \t            Valid_acc : 0.9130835437046628\t            Valid_F1 : 0.9545274228737343\t            Valid_precision : 1.0\t            Valid_recall : 0.9130835437046628\n","[0][49] f1[49] 0.9545274228737343 (0.9215338230723915)\n","Loss 0.3781737739389593 : \t            Valid_acc : 0.8951611689784144\t            Valid_F1 : 0.9445954295592152\t            Valid_precision : 1.0\t            Valid_recall : 0.8951611689784144\n","[0][50] f1[50] 0.9445954295592152 (0.9215338230723915)\n","Loss 0.4333692229155338 : \t            Valid_acc : 0.8723180382859264\t            Valid_F1 : 0.9317303091740374\t            Valid_precision : 1.0\t            Valid_recall : 0.8723180382859264\n","[0][51] f1[51] 0.9317303091740374 (0.9215338230723915)\n","Loss 0.2772745374928821 : \t            Valid_acc : 0.9203922043826555\t            Valid_F1 : 0.958517306771736\t            Valid_precision : 1.0\t            Valid_recall : 0.9203922043826555\n","[0][52] f1[52] 0.958517306771736 (0.9215338230723915)\n","Loss 0.3615905660571474 : \t            Valid_acc : 0.8968224526757171\t            Valid_F1 : 0.9455558081402383\t            Valid_precision : 1.0\t            Valid_recall : 0.8968224526757171\n","[0][53] f1[53] 0.9455558081402383 (0.9215338230723915)\n","Loss 0.3203288551532861 : \t            Valid_acc : 0.9114251363651569\t            Valid_F1 : 0.9535981991267435\t            Valid_precision : 1.0\t            Valid_recall : 0.9114251363651569\n","[0][54] f1[54] 0.9535981991267435 (0.9215338230723915)\n","Loss 0.32207170038512256 : \t            Valid_acc : 0.907281802442563\t            Valid_F1 : 0.9513475202728875\t            Valid_precision : 1.0\t            Valid_recall : 0.907281802442563\n","[0][55] f1[55] 0.9513475202728875 (0.9215338230723915)\n","Loss 0.3494678182583867 : \t            Valid_acc : 0.8971833698863569\t            Valid_F1 : 0.945750631302103\t            Valid_precision : 1.0\t            Valid_recall : 0.8971833698863569\n","[0][56] f1[56] 0.945750631302103 (0.9215338230723915)\n","Loss 0.34501847060340823 : \t            Valid_acc : 0.8984034724987765\t            Valid_F1 : 0.9464531592593369\t            Valid_precision : 1.0\t            Valid_recall : 0.8984034724987765\n","[0][57] f1[57] 0.9464531592593369 (0.9215338230723915)\n","Loss 0.5725111722043066 : \t            Valid_acc : 0.814346578127046\t            Valid_F1 : 0.8976210537880461\t            Valid_precision : 1.0\t            Valid_recall : 0.814346578127046\n","[0][58] f1[58] 0.8976210537880461 (0.8976210537880461)\n","Loss 0.32914540137756954 : \t            Valid_acc : 0.9053068385652664\t            Valid_F1 : 0.9502397176250547\t            Valid_precision : 1.0\t            Valid_recall : 0.9053068385652664\n","[0][59] f1[59] 0.9502397176250547 (0.8976210537880461)\n","Loss 0.3880831716638623 : \t            Valid_acc : 0.8917836222691611\t            Valid_F1 : 0.9427106566520921\t            Valid_precision : 1.0\t            Valid_recall : 0.8917836222691611\n","[0][60] f1[60] 0.9427106566520921 (0.8976210537880461)\n","Loss 0.4071820093826814 : \t            Valid_acc : 0.8765775268567648\t            Valid_F1 : 0.9341669984442639\t            Valid_precision : 1.0\t            Valid_recall : 0.8765775268567648\n","[0][61] f1[61] 0.9341669984442639 (0.8976210537880461)\n","Loss 0.2827430535672289 : \t            Valid_acc : 0.9213253009590456\t            Valid_F1 : 0.9590099322509205\t            Valid_precision : 1.0\t            Valid_recall : 0.9213253009590456\n","[0][62] f1[62] 0.9590099322509205 (0.8976210537880461)\n","Loss 0.35698967923720676 : \t            Valid_acc : 0.8946972595564139\t            Valid_F1 : 0.9443619327791835\t            Valid_precision : 1.0\t            Valid_recall : 0.8946972595564139\n","[0][63] f1[63] 0.9443619327791835 (0.8976210537880461)\n","Loss 0.33650085375164496 : \t            Valid_acc : 0.903573850414846\t            Valid_F1 : 0.9493022052576966\t            Valid_precision : 1.0\t            Valid_recall : 0.903573850414846\n","[0][64] f1[64] 0.9493022052576966 (0.8976210537880461)\n","Loss 0.3236795294691216 : \t            Valid_acc : 0.9103754082283988\t            Valid_F1 : 0.953038893513669\t            Valid_precision : 1.0\t            Valid_recall : 0.9103754082283988\n","[0][65] f1[65] 0.953038893513669 (0.8976210537880461)\n","Loss 0.395106368895733 : \t            Valid_acc : 0.8843122656040285\t            Valid_F1 : 0.9385607046185682\t            Valid_precision : 1.0\t            Valid_recall : 0.8843122656040285\n","[0][66] f1[66] 0.9385607046185682 (0.8976210537880461)\n","Loss 0.32334174847964087 : \t            Valid_acc : 0.9058648759836775\t            Valid_F1 : 0.9505806504208\t            Valid_precision : 1.0\t            Valid_recall : 0.9058648759836775\n","[0][67] f1[67] 0.9505806504208 (0.8976210537880461)\n","Loss 0.43093227369315695 : \t            Valid_acc : 0.8750773632884123\t            Valid_F1 : 0.9333048579194889\t            Valid_precision : 1.0\t            Valid_recall : 0.8750773632884123\n","[0][68] f1[68] 0.9333048579194889 (0.8976210537880461)\n","Loss 0.3465839304933042 : \t            Valid_acc : 0.9018938107709348\t            Valid_F1 : 0.9483487231207206\t            Valid_precision : 1.0\t            Valid_recall : 0.9018938107709348\n","[0][69] f1[69] 0.9483487231207206 (0.8976210537880461)\n","Loss 0.3455724759083806 : \t            Valid_acc : 0.9001712929216721\t            Valid_F1 : 0.947417329271487\t            Valid_precision : 1.0\t            Valid_recall : 0.9001712929216721\n","[0][70] f1[70] 0.947417329271487 (0.8976210537880461)\n","Loss 0.3180568159529657 : \t            Valid_acc : 0.9107058503341598\t            Valid_F1 : 0.9532008544854061\t            Valid_precision : 1.0\t            Valid_recall : 0.9107058503341598\n","[0][71] f1[71] 0.9532008544854061 (0.8976210537880461)\n","Loss 0.34457011170911067 : \t            Valid_acc : 0.8993653721224496\t            Valid_F1 : 0.9469446846177278\t            Valid_precision : 1.0\t            Valid_recall : 0.8993653721224496\n","[0][72] f1[72] 0.9469446846177278 (0.8976210537880461)\n","Loss 0.35368456680214766 : \t            Valid_acc : 0.900641899696319\t            Valid_F1 : 0.9476663345379226\t            Valid_precision : 1.0\t            Valid_recall : 0.900641899696319\n","[0][73] f1[73] 0.9476663345379226 (0.8976210537880461)\n","Loss 0.3404749377884648 : \t            Valid_acc : 0.9036493099066737\t            Valid_F1 : 0.9493424942664224\t            Valid_precision : 1.0\t            Valid_recall : 0.9036493099066737\n","[0][74] f1[74] 0.9493424942664224 (0.8976210537880461)\n","Loss 0.30683669696251553 : \t            Valid_acc : 0.9185846477854516\t            Valid_F1 : 0.9575094143927957\t            Valid_precision : 1.0\t            Valid_recall : 0.9185846477854516\n","[0][75] f1[75] 0.9575094143927957 (0.8976210537880461)\n","Loss 0.25159245424649934 : \t            Valid_acc : 0.9286855219352561\t            Valid_F1 : 0.9629892910951728\t            Valid_precision : 1.0\t            Valid_recall : 0.9286855219352561\n","[0][76] f1[76] 0.9629892910951728 (0.8976210537880461)\n","Loss 0.3113373253833164 : \t            Valid_acc : 0.9090401163419446\t            Valid_F1 : 0.9523058331659217\t            Valid_precision : 1.0\t            Valid_recall : 0.9090401163419446\n","[0][77] f1[77] 0.9523058331659217 (0.8976210537880461)\n","Loss 0.3225134275853634 : \t            Valid_acc : 0.912164246411875\t            Valid_F1 : 0.9540226160025161\t            Valid_precision : 1.0\t            Valid_recall : 0.912164246411875\n","[0][78] f1[78] 0.9540226160025161 (0.8976210537880461)\n","Loss 0.5591961642106374 : \t            Valid_acc : 0.8219412268342738\t            Valid_F1 : 0.9022056193985664\t            Valid_precision : 1.0\t            Valid_recall : 0.8219412268342738\n","[0][79] f1[79] 0.9022056193985664 (0.8976210537880461)\n","Loss 0.3351218718470949 : \t            Valid_acc : 0.9052261118729139\t            Valid_F1 : 0.9502265434499719\t            Valid_precision : 1.0\t            Valid_recall : 0.9052261118729139\n","[0][80] f1[80] 0.9502265434499719 (0.8976210537880461)\n","Loss 0.32332013163602713 : \t            Valid_acc : 0.9096828844344252\t            Valid_F1 : 0.9526513957731767\t            Valid_precision : 1.0\t            Valid_recall : 0.9096828844344252\n","[0][81] f1[81] 0.9526513957731767 (0.8976210537880461)\n","Loss 0.32293363050981 : \t            Valid_acc : 0.9085576602804888\t            Valid_F1 : 0.9520478297000381\t            Valid_precision : 1.0\t            Valid_recall : 0.9085576602804888\n","[0][82] f1[82] 0.9520478297000381 (0.8976210537880461)\n","Loss 0.33512192084030673 : \t            Valid_acc : 0.9041187981691877\t            Valid_F1 : 0.9496157532341655\t            Valid_precision : 1.0\t            Valid_recall : 0.9041187981691877\n","[0][83] f1[83] 0.9496157532341655 (0.8976210537880461)\n","Loss 0.32979529509038635 : \t            Valid_acc : 0.9053326271470283\t            Valid_F1 : 0.9502495333201368\t            Valid_precision : 1.0\t            Valid_recall : 0.9053326271470283\n","[0][84] f1[84] 0.9502495333201368 (0.8976210537880461)\n","Loss 0.3099164698611606 : \t            Valid_acc : 0.9099052441999894\t            Valid_F1 : 0.9527651662985421\t            Valid_precision : 1.0\t            Valid_recall : 0.9099052441999894\n","[0][85] f1[85] 0.9527651662985421 (0.8976210537880461)\n","Loss 0.4908709173852747 : \t            Valid_acc : 0.8488811360875952\t            Valid_F1 : 0.9181797307462398\t            Valid_precision : 1.0\t            Valid_recall : 0.8488811360875952\n","[0][86] f1[86] 0.9181797307462398 (0.8976210537880461)\n","Loss 0.2831187302416021 : \t            Valid_acc : 0.9259220173803477\t            Valid_F1 : 0.9615015839847804\t            Valid_precision : 1.0\t            Valid_recall : 0.9259220173803477\n","[0][87] f1[87] 0.9615015839847804 (0.8976210537880461)\n","Loss 0.3939724544232542 : \t            Valid_acc : 0.8841872474987444\t            Valid_F1 : 0.9384874324768583\t            Valid_precision : 1.0\t            Valid_recall : 0.8841872474987444\n","[0][88] f1[88] 0.9384874324768583 (0.8976210537880461)\n","Loss 0.4344970154942888 : \t            Valid_acc : 0.8705592687631721\t            Valid_F1 : 0.930709862820558\t            Valid_precision : 1.0\t            Valid_recall : 0.8705592687631721\n","[0][89] f1[89] 0.930709862820558 (0.8976210537880461)\n","Loss 0.37209690046129806 : \t            Valid_acc : 0.897846302466214\t            Valid_F1 : 0.9461118574263511\t            Valid_precision : 1.0\t            Valid_recall : 0.897846302466214\n","[0][90] f1[90] 0.9461118574263511 (0.8976210537880461)\n","Loss 0.35571420847466495 : \t            Valid_acc : 0.9031728739187963\t            Valid_F1 : 0.9490511980088037\t            Valid_precision : 1.0\t            Valid_recall : 0.9031728739187963\n","[0][91] f1[91] 0.9490511980088037 (0.8976210537880461)\n","Loss 0.31318397639375745 : \t            Valid_acc : 0.9098180693181008\t            Valid_F1 : 0.952741932058315\t            Valid_precision : 1.0\t            Valid_recall : 0.9098180693181008\n","[0][92] f1[92] 0.952741932058315 (0.8976210537880461)\n","Loss 0.33628476095018967 : \t            Valid_acc : 0.9084499080895236\t            Valid_F1 : 0.9519499243428329\t            Valid_precision : 1.0\t            Valid_recall : 0.9084499080895236\n","[0][93] f1[93] 0.9519499243428329 (0.8976210537880461)\n","Loss 0.3806324565049374 : \t            Valid_acc : 0.8925849957494347\t            Valid_F1 : 0.9431727042798387\t            Valid_precision : 1.0\t            Valid_recall : 0.8925849957494347\n","[0][94] f1[94] 0.9431727042798387 (0.8976210537880461)\n","Loss 0.3785274426142375 : \t            Valid_acc : 0.8968175059970989\t            Valid_F1 : 0.9455342609107904\t            Valid_precision : 1.0\t            Valid_recall : 0.8968175059970989\n","[0][95] f1[95] 0.9455342609107904 (0.8976210537880461)\n","Loss 0.3276571666426731 : \t            Valid_acc : 0.9010890935119443\t            Valid_F1 : 0.9479268529638474\t            Valid_precision : 1.0\t            Valid_recall : 0.9010890935119443\n","[0][96] f1[96] 0.9479268529638474 (0.8976210537880461)\n","Loss 0.31409726788600284 : \t            Valid_acc : 0.9116975129611515\t            Valid_F1 : 0.9537573980766064\t            Valid_precision : 1.0\t            Valid_recall : 0.9116975129611515\n","[0][97] f1[97] 0.9537573980766064 (0.8976210537880461)\n","Loss 0.33374766102342895 : \t            Valid_acc : 0.9056912245897734\t            Valid_F1 : 0.950455799210459\t            Valid_precision : 1.0\t            Valid_recall : 0.9056912245897734\n","[0][98] f1[98] 0.950455799210459 (0.8976210537880461)\n","Loss 0.4537532365683353 : \t            Valid_acc : 0.8569523553047206\t            Valid_F1 : 0.9229126243733278\t            Valid_precision : 1.0\t            Valid_recall : 0.8569523553047206\n","[0][99] f1[99] 0.9229126243733278 (0.8976210537880461)\n","Worst f1 0.8976210537880461 with candidates [621, 0, 0, 0, 0]\n","candidates [ 7484 20995 21952  8404  4848  5527 23695 24453  5413 12116 23054  2520\n","  8351  2872 29905 25374 13085 15166  4338  7547  3627 10225 16845  7257\n"," 12291  9592 28942 19533  2873  4399  5651 11838 13483 17372 10725  6257\n"," 14475 22470 27126  9920 19256  8176 28500 24143  4865  4536 25549 23540\n"," 11489 14202 10299 14039 20303 17595  7754  7805 10606  9716  3539  6647\n"," 10986 27976  8264  7248  7652 29639 14199 20139 10312 23928 23235 11330\n"," 21951 29000 12293 20253 13890 23315  4575  5132 23963 24464 11944 20720\n","  3178 23629 17384  5540 24866 13424 23806 15140  2943 16583 26216 28879\n","  5406 20403  7616  3890]\n","Loss 0.5108660217939001 : \t            Valid_acc : 0.8441936367117246\t            Valid_F1 : 0.9154260306160281\t            Valid_precision : 1.0\t            Valid_recall : 0.8441936367117246\n","[1][0] f1[0] 0.9154260306160281 (0.8976210537880461)\n","Loss 0.5799233263189142 : \t            Valid_acc : 0.8266679664471979\t            Valid_F1 : 0.9050327941302471\t            Valid_precision : 1.0\t            Valid_recall : 0.8266679664471979\n","[1][1] f1[1] 0.9050327941302471 (0.8976210537880461)\n","Loss 0.5010776465589349 : \t            Valid_acc : 0.8497950242113336\t            Valid_F1 : 0.9186895969417986\t            Valid_precision : 1.0\t            Valid_recall : 0.8497950242113336\n","[1][2] f1[2] 0.9186895969417986 (0.8976210537880461)\n","Loss 0.6439508493199493 : \t            Valid_acc : 0.8087569802221918\t            Valid_F1 : 0.8941586254032565\t            Valid_precision : 1.0\t            Valid_recall : 0.8087569802221918\n","[1][3] f1[3] 0.8941586254032565 (0.8941586254032565)\n","Loss 0.4846803013122443 : \t            Valid_acc : 0.8507432425867304\t            Valid_F1 : 0.9192626670839222\t            Valid_precision : 1.0\t            Valid_recall : 0.8507432425867304\n","[1][4] f1[4] 0.9192626670839222 (0.8941586254032565)\n","Loss 0.4999742643399672 : \t            Valid_acc : 0.8407556639636107\t            Valid_F1 : 0.9134210211970759\t            Valid_precision : 1.0\t            Valid_recall : 0.8407556639636107\n","[1][5] f1[5] 0.9134210211970759 (0.8941586254032565)\n","Loss 0.5661224989276944 : \t            Valid_acc : 0.8291512394244954\t            Valid_F1 : 0.9065005578851848\t            Valid_precision : 1.0\t            Valid_recall : 0.8291512394244954\n","[1][6] f1[6] 0.9065005578851848 (0.8941586254032565)\n","Loss 0.5869195113579432 : \t            Valid_acc : 0.8203195499617144\t            Valid_F1 : 0.901222893215961\t            Valid_precision : 1.0\t            Valid_recall : 0.8203195499617144\n","[1][7] f1[7] 0.901222893215961 (0.8941586254032565)\n","Loss 0.48881509854938043 : \t            Valid_acc : 0.8567581129815411\t            Valid_F1 : 0.9226945910431871\t            Valid_precision : 1.0\t            Valid_recall : 0.8567581129815411\n","[1][8] f1[8] 0.9226945910431871 (0.8941586254032565)\n","Loss 0.5349153176401601 : \t            Valid_acc : 0.8327353673310546\t            Valid_F1 : 0.9086473364928681\t            Valid_precision : 1.0\t            Valid_recall : 0.8327353673310546\n","[1][9] f1[9] 0.9086473364928681 (0.8941586254032565)\n","Loss 0.6161747443856616 : \t            Valid_acc : 0.813081999495145\t            Valid_F1 : 0.8968047092089361\t            Valid_precision : 1.0\t            Valid_recall : 0.813081999495145\n","[1][10] f1[10] 0.8968047092089361 (0.8941586254032565)\n","Loss 0.48878548045953113 : \t            Valid_acc : 0.8539457330731219\t            Valid_F1 : 0.9211287847277256\t            Valid_precision : 1.0\t            Valid_recall : 0.8539457330731219\n","[1][11] f1[11] 0.9211287847277256 (0.8941586254032565)\n","Loss 0.5106519122015346 : \t            Valid_acc : 0.8497285535385869\t            Valid_F1 : 0.9185878525177468\t            Valid_precision : 1.0\t            Valid_recall : 0.8497285535385869\n","[1][12] f1[12] 0.9185878525177468 (0.8941586254032565)\n","Loss 0.5488452866221919 : \t            Valid_acc : 0.8420683587875327\t            Valid_F1 : 0.9141338853267014\t            Valid_precision : 1.0\t            Valid_recall : 0.8420683587875327\n","[1][13] f1[13] 0.9141338853267014 (0.8941586254032565)\n","Loss 0.5613176470453088 : \t            Valid_acc : 0.8282038797924551\t            Valid_F1 : 0.9059335933777128\t            Valid_precision : 1.0\t            Valid_recall : 0.8282038797924551\n","[1][14] f1[14] 0.9059335933777128 (0.8941586254032565)\n","Loss 0.5818568427454341 : \t            Valid_acc : 0.8205312917551476\t            Valid_F1 : 0.9013511896707813\t            Valid_precision : 1.0\t            Valid_recall : 0.8205312917551476\n","[1][15] f1[15] 0.9013511896707813 (0.8941586254032565)\n","Loss 0.5445782731879841 : \t            Valid_acc : 0.8365890588559715\t            Valid_F1 : 0.9109121680924291\t            Valid_precision : 1.0\t            Valid_recall : 0.8365890588559715\n","[1][16] f1[16] 0.9109121680924291 (0.8941586254032565)\n","Loss 0.5830056671843384 : \t            Valid_acc : 0.8310924584155622\t            Valid_F1 : 0.9076320237953897\t            Valid_precision : 1.0\t            Valid_recall : 0.8310924584155622\n","[1][17] f1[17] 0.9076320237953897 (0.8941586254032565)\n","Loss 0.48801627122994623 : \t            Valid_acc : 0.8458017031307948\t            Valid_F1 : 0.9163723055922812\t            Valid_precision : 1.0\t            Valid_recall : 0.8458017031307948\n","[1][18] f1[18] 0.9163723055922812 (0.8941586254032565)\n","Loss 0.5433363137823163 : \t            Valid_acc : 0.8266814670234168\t            Valid_F1 : 0.9050281877567432\t            Valid_precision : 1.0\t            Valid_recall : 0.8266814670234168\n","[1][19] f1[19] 0.9050281877567432 (0.8941586254032565)\n","Loss 0.5617597197944467 : \t            Valid_acc : 0.8391485947040882\t            Valid_F1 : 0.9124206426504177\t            Valid_precision : 1.0\t            Valid_recall : 0.8391485947040882\n","[1][20] f1[20] 0.9124206426504177 (0.8941586254032565)\n","Loss 0.5664892146984736 : \t            Valid_acc : 0.8351314409167873\t            Valid_F1 : 0.9100638198541618\t            Valid_precision : 1.0\t            Valid_recall : 0.8351314409167873\n","[1][21] f1[21] 0.9100638198541618 (0.8941586254032565)\n","Loss 0.636866771813595 : \t            Valid_acc : 0.8011257989332617\t            Valid_F1 : 0.8894913247960585\t            Valid_precision : 1.0\t            Valid_recall : 0.8011257989332617\n","[1][22] f1[22] 0.8894913247960585 (0.8894913247960585)\n","Loss 0.47225634708549036 : \t            Valid_acc : 0.8521321053222481\t            Valid_F1 : 0.9200720809119771\t            Valid_precision : 1.0\t            Valid_recall : 0.8521321053222481\n","[1][23] f1[23] 0.9200720809119771 (0.8894913247960585)\n","Loss 0.5223158954670934 : \t            Valid_acc : 0.8381581733259756\t            Valid_F1 : 0.9118656505087677\t            Valid_precision : 1.0\t            Valid_recall : 0.8381581733259756\n","[1][24] f1[24] 0.9118656505087677 (0.8894913247960585)\n","Loss 0.5351151611768838 : \t            Valid_acc : 0.8426499287904803\t            Valid_F1 : 0.9144958395078001\t            Valid_precision : 1.0\t            Valid_recall : 0.8426499287904803\n","[1][25] f1[25] 0.9144958395078001 (0.8894913247960585)\n","Loss 0.5154216899113222 : \t            Valid_acc : 0.8473085019006942\t            Valid_F1 : 0.9172108544907142\t            Valid_precision : 1.0\t            Valid_recall : 0.8473085019006942\n","[1][26] f1[26] 0.9172108544907142 (0.8894913247960585)\n","Loss 0.584753123648239 : \t            Valid_acc : 0.8228852287196023\t            Valid_F1 : 0.9027329228773736\t            Valid_precision : 1.0\t            Valid_recall : 0.8228852287196023\n","[1][27] f1[27] 0.9027329228773736 (0.8894913247960585)\n","Loss 0.5409525768323378 : \t            Valid_acc : 0.8381273986937102\t            Valid_F1 : 0.9118193806031935\t            Valid_precision : 1.0\t            Valid_recall : 0.8381273986937102\n","[1][28] f1[28] 0.9118193806031935 (0.8894913247960585)\n","Loss 0.4730072220166524 : \t            Valid_acc : 0.8570630276539021\t            Valid_F1 : 0.9229015536050653\t            Valid_precision : 1.0\t            Valid_recall : 0.8570630276539021\n","[1][29] f1[29] 0.9229015536050653 (0.8894913247960585)\n","Loss 0.5418881037921617 : \t            Valid_acc : 0.8468136078733263\t            Valid_F1 : 0.9169026521737876\t            Valid_precision : 1.0\t            Valid_recall : 0.8468136078733263\n","[1][30] f1[30] 0.9169026521737876 (0.8894913247960585)\n","Loss 0.4826138258883447 : \t            Valid_acc : 0.8477379236887401\t            Valid_F1 : 0.9175064230186842\t            Valid_precision : 1.0\t            Valid_recall : 0.8477379236887401\n","[1][31] f1[31] 0.9175064230186842 (0.8894913247960585)\n","Loss 0.6109195739933939 : \t            Valid_acc : 0.8215866177783062\t            Valid_F1 : 0.9019513003035143\t            Valid_precision : 1.0\t            Valid_recall : 0.8215866177783062\n","[1][32] f1[32] 0.9019513003035143 (0.8894913247960585)\n","Loss 0.5175289439432549 : \t            Valid_acc : 0.8467668172582331\t            Valid_F1 : 0.9168828515468055\t            Valid_precision : 1.0\t            Valid_recall : 0.8467668172582331\n","[1][33] f1[33] 0.9168828515468055 (0.8894913247960585)\n","Loss 0.517090767621994 : \t            Valid_acc : 0.8514761194441199\t            Valid_F1 : 0.9196719992184588\t            Valid_precision : 1.0\t            Valid_recall : 0.8514761194441199\n","[1][34] f1[34] 0.9196719992184588 (0.8894913247960585)\n","Loss 0.6067211108677315 : \t            Valid_acc : 0.8120532336844553\t            Valid_F1 : 0.8961986204391513\t            Valid_precision : 1.0\t            Valid_recall : 0.8120532336844553\n","[1][35] f1[35] 0.8961986204391513 (0.8894913247960585)\n","Loss 0.5161848253372944 : \t            Valid_acc : 0.8529457358894738\t            Valid_F1 : 0.9205130366103165\t            Valid_precision : 1.0\t            Valid_recall : 0.8529457358894738\n","[1][36] f1[36] 0.9205130366103165 (0.8894913247960585)\n","Loss 0.5603509161508444 : \t            Valid_acc : 0.8256467782458801\t            Valid_F1 : 0.9044247826041195\t            Valid_precision : 1.0\t            Valid_recall : 0.8256467782458801\n","[1][37] f1[37] 0.9044247826041195 (0.8894913247960585)\n","Loss 0.6050402783986294 : \t            Valid_acc : 0.8191366172986825\t            Valid_F1 : 0.9004448490058019\t            Valid_precision : 1.0\t            Valid_recall : 0.8191366172986825\n","[1][38] f1[38] 0.9004448490058019 (0.8894913247960585)\n","Loss 0.5881795878663207 : \t            Valid_acc : 0.8263790781059865\t            Valid_F1 : 0.9048430047847993\t            Valid_precision : 1.0\t            Valid_recall : 0.8263790781059865\n","[1][39] f1[39] 0.9048430047847993 (0.8894913247960585)\n","Loss 0.5645860329721913 : \t            Valid_acc : 0.8254551382990879\t            Valid_F1 : 0.9043174366388184\t            Valid_precision : 1.0\t            Valid_recall : 0.8254551382990879\n","[1][40] f1[40] 0.9043174366388184 (0.8894913247960585)\n","Loss 0.5653475468808954 : \t            Valid_acc : 0.8278912603425006\t            Valid_F1 : 0.905751108501361\t            Valid_precision : 1.0\t            Valid_recall : 0.8278912603425006\n","[1][41] f1[41] 0.905751108501361 (0.8894913247960585)\n","Loss 0.5967499017715454 : \t            Valid_acc : 0.8152214270886725\t            Valid_F1 : 0.8981377466152521\t            Valid_precision : 1.0\t            Valid_recall : 0.8152214270886725\n","[1][42] f1[42] 0.8981377466152521 (0.8894913247960585)\n","Loss 0.620526167027878 : \t            Valid_acc : 0.81073628157277\t            Valid_F1 : 0.8953902248361217\t            Valid_precision : 1.0\t            Valid_recall : 0.81073628157277\n","[1][43] f1[43] 0.8953902248361217 (0.8894913247960585)\n","Loss 0.6505614871328528 : \t            Valid_acc : 0.796108713009338\t            Valid_F1 : 0.8863648309019786\t            Valid_precision : 1.0\t            Valid_recall : 0.796108713009338\n","[1][44] f1[44] 0.8863648309019786 (0.8863648309019786)\n","Loss 0.5286156137784322 : \t            Valid_acc : 0.8445413927170149\t            Valid_F1 : 0.9155767767075307\t            Valid_precision : 1.0\t            Valid_recall : 0.8445413927170149\n","[1][45] f1[45] 0.9155767767075307 (0.8863648309019786)\n","Loss 0.6418298297759258 : \t            Valid_acc : 0.8061098229508822\t            Valid_F1 : 0.8924932340769627\t            Valid_precision : 1.0\t            Valid_recall : 0.8061098229508822\n","[1][46] f1[46] 0.8924932340769627 (0.8863648309019786)\n","Loss 0.5756728328538664 : \t            Valid_acc : 0.8204629191856591\t            Valid_F1 : 0.9012928703965456\t            Valid_precision : 1.0\t            Valid_recall : 0.8204629191856591\n","[1][47] f1[47] 0.9012928703965456 (0.8863648309019786)\n","Loss 0.5469709982474645 : \t            Valid_acc : 0.8364890500901291\t            Valid_F1 : 0.9108652209455446\t            Valid_precision : 1.0\t            Valid_recall : 0.8364890500901291\n","[1][48] f1[48] 0.9108652209455446 (0.8863648309019786)\n","Loss 0.48733638814001373 : \t            Valid_acc : 0.8649352927929517\t            Valid_F1 : 0.9274625690678461\t            Valid_precision : 1.0\t            Valid_recall : 0.8649352927929517\n","[1][49] f1[49] 0.9274625690678461 (0.8863648309019786)\n","Loss 0.5791235525499691 : \t            Valid_acc : 0.82446372564314\t            Valid_F1 : 0.9036601632126986\t            Valid_precision : 1.0\t            Valid_recall : 0.82446372564314\n","[1][50] f1[50] 0.9036601632126986 (0.8863648309019786)\n","Loss 0.6037881740114905 : \t            Valid_acc : 0.8194225135070119\t            Valid_F1 : 0.9006501145135395\t            Valid_precision : 1.0\t            Valid_recall : 0.8194225135070119\n","[1][51] f1[51] 0.9006501145135395 (0.8863648309019786)\n","Loss 0.5552784195452025 : \t            Valid_acc : 0.8298675411298817\t            Valid_F1 : 0.9069512504028633\t            Valid_precision : 1.0\t            Valid_recall : 0.8298675411298817\n","[1][52] f1[52] 0.9069512504028633 (0.8863648309019786)\n","Loss 0.5760610040390131 : \t            Valid_acc : 0.8291945727489787\t            Valid_F1 : 0.9065300770053956\t            Valid_precision : 1.0\t            Valid_recall : 0.8291945727489787\n","[1][53] f1[53] 0.9065300770053956 (0.8863648309019786)\n","Loss 0.5556531345302408 : \t            Valid_acc : 0.8502548952142319\t            Valid_F1 : 0.9188968091557603\t            Valid_precision : 1.0\t            Valid_recall : 0.8502548952142319\n","[1][54] f1[54] 0.9188968091557603 (0.8863648309019786)\n","Loss 0.6098671700015212 : \t            Valid_acc : 0.8207167419927895\t            Valid_F1 : 0.9013894204078743\t            Valid_precision : 1.0\t            Valid_recall : 0.8207167419927895\n","[1][55] f1[55] 0.9013894204078743 (0.8863648309019786)\n","Loss 0.5727871841553486 : \t            Valid_acc : 0.8336848962793139\t            Valid_F1 : 0.9092235446616009\t            Valid_precision : 1.0\t            Valid_recall : 0.8336848962793139\n","[1][56] f1[56] 0.9092235446616009 (0.8863648309019786)\n","Loss 0.5341966292171767 : \t            Valid_acc : 0.8410227945430884\t            Valid_F1 : 0.9135464618719178\t            Valid_precision : 1.0\t            Valid_recall : 0.8410227945430884\n","[1][57] f1[57] 0.9135464618719178 (0.8863648309019786)\n","Loss 0.5132941102439706 : \t            Valid_acc : 0.845214145354209\t            Valid_F1 : 0.9159882080339867\t            Valid_precision : 1.0\t            Valid_recall : 0.845214145354209\n","[1][58] f1[58] 0.9159882080339867 (0.8863648309019786)\n","Loss 0.5847703286192634 : \t            Valid_acc : 0.8295291699760055\t            Valid_F1 : 0.9067279201662348\t            Valid_precision : 1.0\t            Valid_recall : 0.8295291699760055\n","[1][59] f1[59] 0.9067279201662348 (0.8863648309019786)\n","Loss 0.567149489214926 : \t            Valid_acc : 0.8327835966710806\t            Valid_F1 : 0.9086606638128024\t            Valid_precision : 1.0\t            Valid_recall : 0.8327835966710806\n","[1][60] f1[60] 0.9086606638128024 (0.8863648309019786)\n","Loss 0.6199939020655372 : \t            Valid_acc : 0.8185323646065064\t            Valid_F1 : 0.9001296127379745\t            Valid_precision : 1.0\t            Valid_recall : 0.8185323646065064\n","[1][61] f1[61] 0.9001296127379745 (0.8863648309019786)\n","Loss 0.5034220541516939 : \t            Valid_acc : 0.8544432707526879\t            Valid_F1 : 0.9213202258470481\t            Valid_precision : 1.0\t            Valid_recall : 0.8544432707526879\n","[1][62] f1[62] 0.9213202258470481 (0.8863648309019786)\n","Loss 0.6034810005715399 : \t            Valid_acc : 0.8067398916965042\t            Valid_F1 : 0.8929472615929734\t            Valid_precision : 1.0\t            Valid_recall : 0.8067398916965042\n","[1][63] f1[63] 0.8929472615929734 (0.8863648309019786)\n","Loss 0.4560916717305328 : \t            Valid_acc : 0.856272643507752\t            Valid_F1 : 0.9225026460470601\t            Valid_precision : 1.0\t            Valid_recall : 0.856272643507752\n","[1][64] f1[64] 0.9225026460470601 (0.8863648309019786)\n","Loss 0.6043803890546163 : \t            Valid_acc : 0.8150481387238055\t            Valid_F1 : 0.898032598535457\t            Valid_precision : 1.0\t            Valid_recall : 0.8150481387238055\n","[1][65] f1[65] 0.898032598535457 (0.8863648309019786)\n","Loss 0.624294124769442 : \t            Valid_acc : 0.8087432384851119\t            Valid_F1 : 0.8941788403590976\t            Valid_precision : 1.0\t            Valid_recall : 0.8087432384851119\n","[1][66] f1[66] 0.8941788403590976 (0.8863648309019786)\n","Loss 0.5765869337500948 : \t            Valid_acc : 0.8309894680746412\t            Valid_F1 : 0.9075379435273179\t            Valid_precision : 1.0\t            Valid_recall : 0.8309894680746412\n","[1][67] f1[67] 0.9075379435273179 (0.8863648309019786)\n","Loss 0.5944889544537573 : \t            Valid_acc : 0.8207952776550024\t            Valid_F1 : 0.9014592829001193\t            Valid_precision : 1.0\t            Valid_recall : 0.8207952776550024\n","[1][68] f1[68] 0.9014592829001193 (0.8863648309019786)\n","Loss 0.584052296298923 : \t            Valid_acc : 0.8258644404301935\t            Valid_F1 : 0.9045530012662877\t            Valid_precision : 1.0\t            Valid_recall : 0.8258644404301935\n","[1][69] f1[69] 0.9045530012662877 (0.8863648309019786)\n","Loss 0.5669411696267851 : \t            Valid_acc : 0.8312614456525727\t            Valid_F1 : 0.9077597909197718\t            Valid_precision : 1.0\t            Valid_recall : 0.8312614456525727\n","[1][70] f1[70] 0.9077597909197718 (0.8863648309019786)\n","Loss 0.5622664536490585 : \t            Valid_acc : 0.8299080370081281\t            Valid_F1 : 0.9069434508817897\t            Valid_precision : 1.0\t            Valid_recall : 0.8299080370081281\n","[1][71] f1[71] 0.9069434508817897 (0.8863648309019786)\n","Loss 0.6021352261304855 : \t            Valid_acc : 0.8234602951985308\t            Valid_F1 : 0.9031071103154624\t            Valid_precision : 1.0\t            Valid_recall : 0.8234602951985308\n","[1][72] f1[72] 0.9031071103154624 (0.8863648309019786)\n","Loss 0.6139110936359926 : \t            Valid_acc : 0.8116621135628925\t            Valid_F1 : 0.8959701388791905\t            Valid_precision : 1.0\t            Valid_recall : 0.8116621135628925\n","[1][73] f1[73] 0.8959701388791905 (0.8863648309019786)\n","Loss 0.5579632592923713 : \t            Valid_acc : 0.8331779202038981\t            Valid_F1 : 0.9088957218769096\t            Valid_precision : 1.0\t            Valid_recall : 0.8331779202038981\n","[1][74] f1[74] 0.9088957218769096 (0.8863648309019786)\n","Loss 0.567433829108874 : \t            Valid_acc : 0.8313835957742415\t            Valid_F1 : 0.9078498730172431\t            Valid_precision : 1.0\t            Valid_recall : 0.8313835957742415\n","[1][75] f1[75] 0.9078498730172431 (0.8863648309019786)\n","Loss 0.6543368268193621 : \t            Valid_acc : 0.7931625026546661\t            Valid_F1 : 0.8845784105816327\t            Valid_precision : 1.0\t            Valid_recall : 0.7931625026546661\n","[1][76] f1[76] 0.8845784105816327 (0.8845784105816327)\n","Loss 0.615460351561055 : \t            Valid_acc : 0.8140161072122543\t            Valid_F1 : 0.8973854294524783\t            Valid_precision : 1.0\t            Valid_recall : 0.8140161072122543\n","[1][77] f1[77] 0.8973854294524783 (0.8845784105816327)\n","Loss 0.5255214422941208 : \t            Valid_acc : 0.8424266964639026\t            Valid_F1 : 0.9143735342404659\t            Valid_precision : 1.0\t            Valid_recall : 0.8424266964639026\n","[1][78] f1[78] 0.9143735342404659 (0.8845784105816327)\n","Loss 0.5462920846361102 : \t            Valid_acc : 0.8457261989472302\t            Valid_F1 : 0.9162244671922167\t            Valid_precision : 1.0\t            Valid_recall : 0.8457261989472302\n","[1][79] f1[79] 0.9162244671922167 (0.8845784105816327)\n","Loss 0.5912685732949864 : \t            Valid_acc : 0.8128682380493705\t            Valid_F1 : 0.8966849752492143\t            Valid_precision : 1.0\t            Valid_recall : 0.8128682380493705\n","[1][80] f1[80] 0.8966849752492143 (0.8845784105816327)\n","Loss 0.5605216486887499 : \t            Valid_acc : 0.831776556604976\t            Valid_F1 : 0.9080795528223984\t            Valid_precision : 1.0\t            Valid_recall : 0.831776556604976\n","[1][81] f1[81] 0.9080795528223984 (0.8845784105816327)\n","Loss 0.6005165342128638 : \t            Valid_acc : 0.8158077238687766\t            Valid_F1 : 0.8984819967161121\t            Valid_precision : 1.0\t            Valid_recall : 0.8158077238687766\n","[1][82] f1[82] 0.8984819967161121 (0.8845784105816327)\n","Loss 0.6254747379006762 : \t            Valid_acc : 0.8075795901253358\t            Valid_F1 : 0.8934663690820999\t            Valid_precision : 1.0\t            Valid_recall : 0.8075795901253358\n","[1][83] f1[83] 0.8934663690820999 (0.8845784105816327)\n","Loss 0.47169456879297894 : \t            Valid_acc : 0.8619165565693977\t            Valid_F1 : 0.9257313693270836\t            Valid_precision : 1.0\t            Valid_recall : 0.8619165565693977\n","[1][84] f1[84] 0.9257313693270836 (0.8845784105816327)\n","Loss 0.5206881829283454 : \t            Valid_acc : 0.8399735116055012\t            Valid_F1 : 0.912937973778492\t            Valid_precision : 1.0\t            Valid_recall : 0.8399735116055012\n","[1][85] f1[85] 0.912937973778492 (0.8845784105816327)\n","Loss 0.6113727882956014 : \t            Valid_acc : 0.8181896174920126\t            Valid_F1 : 0.8999182908740881\t            Valid_precision : 1.0\t            Valid_recall : 0.8181896174920126\n","[1][86] f1[86] 0.8999182908740881 (0.8845784105816327)\n","Loss 0.5861918023138335 : \t            Valid_acc : 0.8274798901646498\t            Valid_F1 : 0.9054449709046861\t            Valid_precision : 1.0\t            Valid_recall : 0.8274798901646498\n","[1][87] f1[87] 0.9054449709046861 (0.8845784105816327)\n","Loss 0.6236912806828817 : \t            Valid_acc : 0.8096499436680473\t            Valid_F1 : 0.894734654858892\t            Valid_precision : 1.0\t            Valid_recall : 0.8096499436680473\n","[1][88] f1[88] 0.894734654858892 (0.8845784105816327)\n","Loss 0.633746120965842 : \t            Valid_acc : 0.8103461431069022\t            Valid_F1 : 0.8951033065471602\t            Valid_precision : 1.0\t            Valid_recall : 0.8103461431069022\n","[1][89] f1[89] 0.8951033065471602 (0.8845784105816327)\n","Loss 0.5762457350889841 : \t            Valid_acc : 0.8291374221714238\t            Valid_F1 : 0.9064891479743966\t            Valid_precision : 1.0\t            Valid_recall : 0.8291374221714238\n","[1][90] f1[90] 0.9064891479743966 (0.8845784105816327)\n","Loss 0.519831325971719 : \t            Valid_acc : 0.8458612416796671\t            Valid_F1 : 0.9163831164132338\t            Valid_precision : 1.0\t            Valid_recall : 0.8458612416796671\n","[1][91] f1[91] 0.9163831164132338 (0.8845784105816327)\n","Loss 0.5063510501023495 : \t            Valid_acc : 0.8533427522145656\t            Valid_F1 : 0.9207218383678125\t            Valid_precision : 1.0\t            Valid_recall : 0.8533427522145656\n","[1][92] f1[92] 0.9207218383678125 (0.8845784105816327)\n","Loss 0.5681011487137188 : \t            Valid_acc : 0.8258054981695696\t            Valid_F1 : 0.9045203221434369\t            Valid_precision : 1.0\t            Valid_recall : 0.8258054981695696\n","[1][93] f1[93] 0.9045203221434369 (0.8845784105816327)\n","Loss 0.6084161427888003 : \t            Valid_acc : 0.8206193391329063\t            Valid_F1 : 0.9013701326949674\t            Valid_precision : 1.0\t            Valid_recall : 0.8206193391329063\n","[1][94] f1[94] 0.9013701326949674 (0.8845784105816327)\n","Loss 0.5847998085347089 : \t            Valid_acc : 0.8153466119890077\t            Valid_F1 : 0.8982045149819193\t            Valid_precision : 1.0\t            Valid_recall : 0.8153466119890077\n","[1][95] f1[95] 0.8982045149819193 (0.8845784105816327)\n","Loss 0.5952351170055794 : \t            Valid_acc : 0.829934090855613\t            Valid_F1 : 0.9069446297981488\t            Valid_precision : 1.0\t            Valid_recall : 0.829934090855613\n","[1][96] f1[96] 0.9069446297981488 (0.8845784105816327)\n","Loss 0.6111133378563505 : \t            Valid_acc : 0.8092144675042174\t            Valid_F1 : 0.8944598676493484\t            Valid_precision : 1.0\t            Valid_recall : 0.8092144675042174\n","[1][97] f1[97] 0.8944598676493484 (0.8845784105816327)\n","Loss 0.5518342626817299 : \t            Valid_acc : 0.8303401098983111\t            Valid_F1 : 0.9072069195924602\t            Valid_precision : 1.0\t            Valid_recall : 0.8303401098983111\n","[1][98] f1[98] 0.9072069195924602 (0.8845784105816327)\n","Loss 0.5738122106501551 : \t            Valid_acc : 0.8250024264844963\t            Valid_F1 : 0.9040067231258901\t            Valid_precision : 1.0\t            Valid_recall : 0.8250024264844963\n","[1][99] f1[99] 0.9040067231258901 (0.8845784105816327)\n","Worst f1 0.8845784105816327 with candidates [621, 13890, 0, 0, 0]\n","candidates [ 3005 10606   819  2878  5376  8559  4588  7484 28580  1970  6234  1886\n"," 13994   987 12293  7500  6354  4882 29182  2520 13085 25315  5465 11160\n","   992  9920  1974  7380  1591 11330 10959 16427 15227  1951  1972  2005\n","  2873 19074 20205 18766 11510  3699 20553 12858  3917  4395 20393 20895\n"," 16571  3539  4848  1339  5238 22801  4725  8863 11324  5007  5664 10089\n"," 17750 21418  2867  5527 24382  9932 13064 19624  1674  1950 21241  8351\n","  3306  3174  5132  2684 26454  7499  3402  3275  8264  6846 28037 17981\n"," 13228  6623 15302 24299  7010 19031  9992  6684  1524  4338  7670  3745\n","  3466  3823  5977  3857]\n","Loss 0.6981842517852783 : \t            Valid_acc : 0.8056365006143867\t            Valid_F1 : 0.8921866546139207\t            Valid_precision : 1.0\t            Valid_recall : 0.8056365006143867\n","[2][0] f1[0] 0.8921866546139207 (0.8845784105816327)\n","Loss 0.7354446432807229 : \t            Valid_acc : 0.7993740445572479\t            Valid_F1 : 0.8882757225542064\t            Valid_precision : 1.0\t            Valid_recall : 0.7993740445572479\n","[2][1] f1[1] 0.8882757225542064 (0.8845784105816327)\n","Loss 0.6933703819910685 : \t            Valid_acc : 0.80302905767879\t            Valid_F1 : 0.8905580665543518\t            Valid_precision : 1.0\t            Valid_recall : 0.80302905767879\n","[2][2] f1[2] 0.8905580665543518 (0.8845784105816327)\n","Loss 0.6297383730610212 : \t            Valid_acc : 0.8161433241437375\t            Valid_F1 : 0.8986317941538768\t            Valid_precision : 1.0\t            Valid_recall : 0.8161433241437375\n","[2][3] f1[3] 0.8986317941538768 (0.8845784105816327)\n","Loss 0.6603599098144155 : \t            Valid_acc : 0.8030913227596737\t            Valid_F1 : 0.890642574276628\t            Valid_precision : 1.0\t            Valid_recall : 0.8030913227596737\n","[2][4] f1[4] 0.890642574276628 (0.8845784105816327)\n","Loss 0.689414279478969 : \t            Valid_acc : 0.8045018442103992\t            Valid_F1 : 0.8915102682213811\t            Valid_precision : 1.0\t            Valid_recall : 0.8045018442103992\n","[2][5] f1[5] 0.8915102682213811 (0.8845784105816327)\n","Loss 0.5941228685957013 : \t            Valid_acc : 0.8229471045952396\t            Valid_F1 : 0.9027226089004432\t            Valid_precision : 1.0\t            Valid_recall : 0.8229471045952396\n","[2][6] f1[6] 0.9027226089004432 (0.8845784105816327)\n","Loss 0.6857131398988493 : \t            Valid_acc : 0.7961500777409483\t            Valid_F1 : 0.8863608013331385\t            Valid_precision : 1.0\t            Valid_recall : 0.7961500777409483\n","[2][7] f1[7] 0.8863608013331385 (0.8845784105816327)\n","Loss 0.7083037310477459 : \t            Valid_acc : 0.7990507790955079\t            Valid_F1 : 0.8880968799862302\t            Valid_precision : 1.0\t            Valid_recall : 0.7990507790955079\n","[2][8] f1[8] 0.8880968799862302 (0.8845784105816327)\n","Loss 0.7900700031807928 : \t            Valid_acc : 0.7749051243713642\t            Valid_F1 : 0.8730100563796608\t            Valid_precision : 1.0\t            Valid_recall : 0.7749051243713642\n","[2][9] f1[9] 0.8730100563796608 (0.8730100563796608)\n","Loss 0.7424252159667738 : \t            Valid_acc : 0.7934157262056003\t            Valid_F1 : 0.8846446892892995\t            Valid_precision : 1.0\t            Valid_recall : 0.7934157262056003\n","[2][10] f1[10] 0.8846446892892995 (0.8730100563796608)\n","Loss 0.7190847563924212 : \t            Valid_acc : 0.7976651544061188\t            Valid_F1 : 0.8872968040288215\t            Valid_precision : 1.0\t            Valid_recall : 0.7976651544061188\n","[2][11] f1[11] 0.8872968040288215 (0.8730100563796608)\n","Loss 0.726542816920714 : \t            Valid_acc : 0.7878266695661078\t            Valid_F1 : 0.8811539291370192\t            Valid_precision : 1.0\t            Valid_recall : 0.7878266695661078\n","[2][12] f1[12] 0.8811539291370192 (0.8730100563796608)\n","Loss 0.7623886547305367 : \t            Valid_acc : 0.7849883465822833\t            Valid_F1 : 0.8793288526565793\t            Valid_precision : 1.0\t            Valid_recall : 0.7849883465822833\n","[2][13] f1[13] 0.8793288526565793 (0.8730100563796608)\n","Loss 0.6903423504395918 : \t            Valid_acc : 0.7977858376757416\t            Valid_F1 : 0.8873755238311898\t            Valid_precision : 1.0\t            Valid_recall : 0.7977858376757416\n","[2][14] f1[14] 0.8873755238311898 (0.8730100563796608)\n","Loss 0.7614211783264623 : \t            Valid_acc : 0.7726761142258871\t            Valid_F1 : 0.8716332874567428\t            Valid_precision : 1.0\t            Valid_recall : 0.7726761142258871\n","[2][15] f1[15] 0.8716332874567428 (0.8716332874567428)\n","Loss 0.5857233748291478 : \t            Valid_acc : 0.81890569658198\t            Valid_F1 : 0.9003099519526649\t            Valid_precision : 1.0\t            Valid_recall : 0.81890569658198\n","[2][16] f1[16] 0.9003099519526649 (0.8716332874567428)\n","Loss 0.6071671920292305 : \t            Valid_acc : 0.8266237070857508\t            Valid_F1 : 0.9049256503539425\t            Valid_precision : 1.0\t            Valid_recall : 0.8266237070857508\n","[2][17] f1[17] 0.9049256503539425 (0.8716332874567428)\n","Loss 0.7045768535498417 : \t            Valid_acc : 0.8023433458773397\t            Valid_F1 : 0.8901454882193869\t            Valid_precision : 1.0\t            Valid_recall : 0.8023433458773397\n","[2][18] f1[18] 0.8901454882193869 (0.8716332874567428)\n","Loss 0.6201909378622518 : \t            Valid_acc : 0.8132535929347109\t            Valid_F1 : 0.8968659974411952\t            Valid_precision : 1.0\t            Valid_recall : 0.8132535929347109\n","[2][19] f1[19] 0.8968659974411952 (0.8716332874567428)\n","Loss 0.7053110418897687 : \t            Valid_acc : 0.8017622800799264\t            Valid_F1 : 0.8897420543835487\t            Valid_precision : 1.0\t            Valid_recall : 0.8017622800799264\n","[2][20] f1[20] 0.8897420543835487 (0.8716332874567428)\n","Loss 0.755758927175493 : \t            Valid_acc : 0.7840109493258681\t            Valid_F1 : 0.878775238040624\t            Valid_precision : 1.0\t            Valid_recall : 0.7840109493258681\n","[2][21] f1[21] 0.878775238040624 (0.8716332874567428)\n","Loss 0.6248059191487052 : \t            Valid_acc : 0.8061777612263027\t            Valid_F1 : 0.8924885952124011\t            Valid_precision : 1.0\t            Valid_recall : 0.8061777612263027\n","[2][22] f1[22] 0.8924885952124011 (0.8716332874567428)\n","Loss 0.7870801086678649 : \t            Valid_acc : 0.7809248018792849\t            Valid_F1 : 0.8768059927996321\t            Valid_precision : 1.0\t            Valid_recall : 0.7809248018792849\n","[2][23] f1[23] 0.8768059927996321 (0.8716332874567428)\n","Loss 0.7617116556926207 : \t            Valid_acc : 0.7830806423136415\t            Valid_F1 : 0.8781662855728376\t            Valid_precision : 1.0\t            Valid_recall : 0.7830806423136415\n","[2][24] f1[24] 0.8781662855728376 (0.8716332874567428)\n","Loss 0.7410891444394083 : \t            Valid_acc : 0.7884349015879462\t            Valid_F1 : 0.8815025005489942\t            Valid_precision : 1.0\t            Valid_recall : 0.7884349015879462\n","[2][25] f1[25] 0.8815025005489942 (0.8716332874567428)\n","Loss 0.6830411332123207 : \t            Valid_acc : 0.8050570678049619\t            Valid_F1 : 0.8918084307710729\t            Valid_precision : 1.0\t            Valid_recall : 0.8050570678049619\n","[2][26] f1[26] 0.8918084307710729 (0.8716332874567428)\n","Loss 0.665747241991939 : \t            Valid_acc : 0.8054723414700463\t            Valid_F1 : 0.8921072452337364\t            Valid_precision : 1.0\t            Valid_recall : 0.8054723414700463\n","[2][27] f1[27] 0.8921072452337364 (0.8716332874567428)\n","Loss 0.6805931252963615 : \t            Valid_acc : 0.8014203764426138\t            Valid_F1 : 0.8896342329569902\t            Valid_precision : 1.0\t            Valid_recall : 0.8014203764426138\n","[2][28] f1[28] 0.8896342329569902 (0.8716332874567428)\n","Loss 0.7193631222753814 : \t            Valid_acc : 0.7948539962689348\t            Valid_F1 : 0.8855194396294782\t            Valid_precision : 1.0\t            Valid_recall : 0.7948539962689348\n","[2][29] f1[29] 0.8855194396294782 (0.8716332874567428)\n","Loss 0.6925707572337353 : \t            Valid_acc : 0.7963357591345863\t            Valid_F1 : 0.8864580684068633\t            Valid_precision : 1.0\t            Valid_recall : 0.7963357591345863\n","[2][30] f1[30] 0.8864580684068633 (0.8716332874567428)\n","Loss 0.7156228987556515 : \t            Valid_acc : 0.7908491856785413\t            Valid_F1 : 0.8830653877703972\t            Valid_precision : 1.0\t            Valid_recall : 0.7908491856785413\n","[2][31] f1[31] 0.8830653877703972 (0.8716332874567428)\n","Loss 0.7304959030765475 : \t            Valid_acc : 0.7902570209072752\t            Valid_F1 : 0.8827092542780494\t            Valid_precision : 1.0\t            Valid_recall : 0.7902570209072752\n","[2][32] f1[32] 0.8827092542780494 (0.8716332874567428)\n","Loss 0.711699903011322 : \t            Valid_acc : 0.7994065900380934\t            Valid_F1 : 0.888321499170939\t            Valid_precision : 1.0\t            Valid_recall : 0.7994065900380934\n","[2][33] f1[33] 0.888321499170939 (0.8716332874567428)\n","Loss 0.7052461942940047 : \t            Valid_acc : 0.8071155309885008\t            Valid_F1 : 0.893024528310375\t            Valid_precision : 1.0\t            Valid_recall : 0.8071155309885008\n","[2][34] f1[34] 0.893024528310375 (0.8716332874567428)\n","Loss 0.6547934187181068 : \t            Valid_acc : 0.810309042711511\t            Valid_F1 : 0.8950288139618608\t            Valid_precision : 1.0\t            Valid_recall : 0.810309042711511\n","[2][35] f1[35] 0.8950288139618608 (0.8716332874567428)\n","Loss 0.7200629539561995 : \t            Valid_acc : 0.7948784221320067\t            Valid_F1 : 0.8855447957952992\t            Valid_precision : 1.0\t            Valid_recall : 0.7948784221320067\n","[2][36] f1[36] 0.8855447957952992 (0.8716332874567428)\n","Loss 0.6758861419829455 : \t            Valid_acc : 0.8096976297689216\t            Valid_F1 : 0.8947111068734313\t            Valid_precision : 1.0\t            Valid_recall : 0.8096976297689216\n","[2][37] f1[37] 0.8947111068734313 (0.8716332874567428)\n","Loss 0.767193283998605 : \t            Valid_acc : 0.791605705851751\t            Valid_F1 : 0.8835079203035388\t            Valid_precision : 1.0\t            Valid_recall : 0.791605705851751\n","[2][38] f1[38] 0.8835079203035388 (0.8716332874567428)\n","Loss 0.7950261506167325 : \t            Valid_acc : 0.7768408255853421\t            Valid_F1 : 0.874247221279442\t            Valid_precision : 1.0\t            Valid_recall : 0.7768408255853421\n","[2][39] f1[39] 0.874247221279442 (0.8716332874567428)\n","Loss 0.6940714382764065 : \t            Valid_acc : 0.8046239654428168\t            Valid_F1 : 0.8915786849385103\t            Valid_precision : 1.0\t            Valid_recall : 0.8046239654428168\n","[2][40] f1[40] 0.8915786849385103 (0.8716332874567428)\n","Loss 0.7029542620434905 : \t            Valid_acc : 0.8016273838919709\t            Valid_F1 : 0.8897313895950429\t            Valid_precision : 1.0\t            Valid_recall : 0.8016273838919709\n","[2][41] f1[41] 0.8897313895950429 (0.8716332874567428)\n","Loss 0.7137912254441868 : \t            Valid_acc : 0.7931944851280948\t            Valid_F1 : 0.8844904426842499\t            Valid_precision : 1.0\t            Valid_recall : 0.7931944851280948\n","[2][42] f1[42] 0.8844904426842499 (0.8716332874567428)\n","Loss 0.6605392055529536 : \t            Valid_acc : 0.8070758270417908\t            Valid_F1 : 0.8930690302834571\t            Valid_precision : 1.0\t            Valid_recall : 0.8070758270417908\n","[2][43] f1[43] 0.8930690302834571 (0.8716332874567428)\n","Loss 0.6827726571848898 : \t            Valid_acc : 0.8087751691838273\t            Valid_F1 : 0.8941605159182966\t            Valid_precision : 1.0\t            Valid_recall : 0.8087751691838273\n","[2][44] f1[44] 0.8941605159182966 (0.8716332874567428)\n","Loss 0.6335332671349699 : \t            Valid_acc : 0.8172746375295226\t            Valid_F1 : 0.8992774963440748\t            Valid_precision : 1.0\t            Valid_recall : 0.8172746375295226\n","[2][45] f1[45] 0.8992774963440748 (0.8716332874567428)\n","Loss 0.6648068947322441 : \t            Valid_acc : 0.8069473271056339\t            Valid_F1 : 0.8930334773208325\t            Valid_precision : 1.0\t            Valid_recall : 0.8069473271056339\n","[2][46] f1[46] 0.8930334773208325 (0.8716332874567428)\n","Loss 0.627686480003776 : \t            Valid_acc : 0.8186053470797875\t            Valid_F1 : 0.8999866062729797\t            Valid_precision : 1.0\t            Valid_recall : 0.8186053470797875\n","[2][47] f1[47] 0.8999866062729797 (0.8716332874567428)\n","Loss 0.7346633483063091 : \t            Valid_acc : 0.7980313570454198\t            Valid_F1 : 0.8874222691208272\t            Valid_precision : 1.0\t            Valid_recall : 0.7980313570454198\n","[2][48] f1[48] 0.8874222691208272 (0.8716332874567428)\n","Loss 0.6892044697747086 : \t            Valid_acc : 0.8026402206850881\t            Valid_F1 : 0.89035648631276\t            Valid_precision : 1.0\t            Valid_recall : 0.8026402206850881\n","[2][49] f1[49] 0.89035648631276 (0.8716332874567428)\n","Loss 0.654491071899732 : \t            Valid_acc : 0.8105103727485224\t            Valid_F1 : 0.8950774002071759\t            Valid_precision : 1.0\t            Valid_recall : 0.8105103727485224\n","[2][50] f1[50] 0.8950774002071759 (0.8716332874567428)\n","Loss 0.7504374998988528 : \t            Valid_acc : 0.793851403009389\t            Valid_F1 : 0.8849110340291184\t            Valid_precision : 1.0\t            Valid_recall : 0.793851403009389\n","[2][51] f1[51] 0.8849110340291184 (0.8716332874567428)\n","Loss 0.6034735215432716 : \t            Valid_acc : 0.8107087864351451\t            Valid_F1 : 0.8953119374498851\t            Valid_precision : 1.0\t            Valid_recall : 0.8107087864351451\n","[2][52] f1[52] 0.8953119374498851 (0.8716332874567428)\n","Loss 0.6783097323143121 : \t            Valid_acc : 0.8023618685919734\t            Valid_F1 : 0.8901914201512526\t            Valid_precision : 1.0\t            Valid_recall : 0.8023618685919734\n","[2][53] f1[53] 0.8901914201512526 (0.8716332874567428)\n","Loss 0.7295565776752703 : \t            Valid_acc : 0.785209456423154\t            Valid_F1 : 0.8795771193996837\t            Valid_precision : 1.0\t            Valid_recall : 0.785209456423154\n","[2][54] f1[54] 0.8795771193996837 (0.8716332874567428)\n","Loss 0.6721138913523067 : \t            Valid_acc : 0.7996910777601622\t            Valid_F1 : 0.8885606739295746\t            Valid_precision : 1.0\t            Valid_recall : 0.7996910777601622\n","[2][55] f1[55] 0.8885606739295746 (0.8716332874567428)\n","Loss 0.7227602005004883 : \t            Valid_acc : 0.8016586842012831\t            Valid_F1 : 0.8897087336847724\t            Valid_precision : 1.0\t            Valid_recall : 0.8016586842012831\n","[2][56] f1[56] 0.8897087336847724 (0.8716332874567428)\n","Loss 0.7461789254889344 : \t            Valid_acc : 0.7887422114435376\t            Valid_F1 : 0.8817180138569322\t            Valid_precision : 1.0\t            Valid_recall : 0.7887422114435376\n","[2][57] f1[57] 0.8817180138569322 (0.8716332874567428)\n","Loss 0.7773574680993052 : \t            Valid_acc : 0.7886083129155085\t            Valid_F1 : 0.8815864660766605\t            Valid_precision : 1.0\t            Valid_recall : 0.7886083129155085\n","[2][58] f1[58] 0.8815864660766605 (0.8716332874567428)\n","Loss 0.7124084383249283 : \t            Valid_acc : 0.7924454163911587\t            Valid_F1 : 0.8840569172741667\t            Valid_precision : 1.0\t            Valid_recall : 0.7924454163911587\n","[2][59] f1[59] 0.8840569172741667 (0.8716332874567428)\n","Loss 0.7873333231969313 : \t            Valid_acc : 0.7725538676215786\t            Valid_F1 : 0.8715388855882316\t            Valid_precision : 1.0\t            Valid_recall : 0.7725538676215786\n","[2][60] f1[60] 0.8715388855882316 (0.8715388855882316)\n","Loss 0.6543571262648611 : \t            Valid_acc : 0.8007692333360689\t            Valid_F1 : 0.8892604952495516\t            Valid_precision : 1.0\t            Valid_recall : 0.8007692333360689\n","[2][61] f1[61] 0.8892604952495516 (0.8715388855882316)\n","Loss 0.5447977681954702 : \t            Valid_acc : 0.8454637750031092\t            Valid_F1 : 0.9160692093558453\t            Valid_precision : 1.0\t            Valid_recall : 0.8454637750031092\n","[2][62] f1[62] 0.9160692093558453 (0.8715388855882316)\n","Loss 0.6404206874695691 : \t            Valid_acc : 0.8051789531773874\t            Valid_F1 : 0.8919097524768212\t            Valid_precision : 1.0\t            Valid_recall : 0.8051789531773874\n","[2][63] f1[63] 0.8919097524768212 (0.8715388855882316)\n","Loss 0.5832053779652624 : \t            Valid_acc : 0.826645255963765\t            Valid_F1 : 0.9049419868011557\t            Valid_precision : 1.0\t            Valid_recall : 0.826645255963765\n","[2][64] f1[64] 0.9049419868011557 (0.8715388855882316)\n","Loss 0.6404846667340307 : \t            Valid_acc : 0.8127329804095249\t            Valid_F1 : 0.8964840456823732\t            Valid_precision : 1.0\t            Valid_recall : 0.8127329804095249\n","[2][65] f1[65] 0.8964840456823732 (0.8715388855882316)\n","Loss 0.792829049356056 : \t            Valid_acc : 0.7635651843201592\t            Valid_F1 : 0.8657260955846291\t            Valid_precision : 1.0\t            Valid_recall : 0.7635651843201592\n","[2][66] f1[66] 0.8657260955846291 (0.8657260955846291)\n","Loss 0.6948160077586318 : \t            Valid_acc : 0.7980507255205878\t            Valid_F1 : 0.8874995586346579\t            Valid_precision : 1.0\t            Valid_recall : 0.7980507255205878\n","[2][67] f1[67] 0.8874995586346579 (0.8657260955846291)\n","Loss 0.6666701219298623 : \t            Valid_acc : 0.8140440141870546\t            Valid_F1 : 0.8973272699315842\t            Valid_precision : 1.0\t            Valid_recall : 0.8140440141870546\n","[2][68] f1[68] 0.8973272699315842 (0.8657260955846291)\n","Loss 0.6691332509120306 : \t            Valid_acc : 0.7981573840276237\t            Valid_F1 : 0.8876296994085875\t            Valid_precision : 1.0\t            Valid_recall : 0.7981573840276237\n","[2][69] f1[69] 0.8876296994085875 (0.8657260955846291)\n","Loss 0.821874809536067 : \t            Valid_acc : 0.7643441107615401\t            Valid_F1 : 0.8662231860094548\t            Valid_precision : 1.0\t            Valid_recall : 0.7643441107615401\n","[2][70] f1[70] 0.8662231860094548 (0.8657260955846291)\n","Loss 0.643838751948241 : \t            Valid_acc : 0.8114557955606772\t            Valid_F1 : 0.8956591706021982\t            Valid_precision : 1.0\t            Valid_recall : 0.8114557955606772\n","[2][71] f1[71] 0.8956591706021982 (0.8657260955846291)\n","Loss 0.7854517842784072 : \t            Valid_acc : 0.7902215919202873\t            Valid_F1 : 0.8826166884767463\t            Valid_precision : 1.0\t            Valid_recall : 0.7902215919202873\n","[2][72] f1[72] 0.8826166884767463 (0.8657260955846291)\n","Loss 0.7301720398845095 : \t            Valid_acc : 0.8017275537443834\t            Valid_F1 : 0.8897710924399928\t            Valid_precision : 1.0\t            Valid_recall : 0.8017275537443834\n","[2][73] f1[73] 0.8897710924399928 (0.8657260955846291)\n","Loss 0.6847309090874412 : \t            Valid_acc : 0.8087879364215063\t            Valid_F1 : 0.8940858879183124\t            Valid_precision : 1.0\t            Valid_recall : 0.8087879364215063\n","[2][74] f1[74] 0.8940858879183124 (0.8657260955846291)\n","Loss 0.7278629839420319 : \t            Valid_acc : 0.7947111493146168\t            Valid_F1 : 0.885452695560869\t            Valid_precision : 1.0\t            Valid_recall : 0.7947111493146168\n","[2][75] f1[75] 0.885452695560869 (0.8657260955846291)\n","Loss 0.659739123600902 : \t            Valid_acc : 0.8032611128333834\t            Valid_F1 : 0.8907583675072832\t            Valid_precision : 1.0\t            Valid_recall : 0.8032611128333834\n","[2][76] f1[76] 0.8907583675072832 (0.8657260955846291)\n","Loss 0.7377209690484133 : \t            Valid_acc : 0.7949536636216928\t            Valid_F1 : 0.8855690698638562\t            Valid_precision : 1.0\t            Valid_recall : 0.7949536636216928\n","[2][77] f1[77] 0.8855690698638562 (0.8657260955846291)\n","Loss 0.7183164701317296 : \t            Valid_acc : 0.7999741551983848\t            Valid_F1 : 0.8887083909852753\t            Valid_precision : 1.0\t            Valid_recall : 0.7999741551983848\n","[2][78] f1[78] 0.8887083909852753 (0.8657260955846291)\n","Loss 0.6848104853521694 : \t            Valid_acc : 0.8017099646231043\t            Valid_F1 : 0.889734543722761\t            Valid_precision : 1.0\t            Valid_recall : 0.8017099646231043\n","[2][79] f1[79] 0.889734543722761 (0.8657260955846291)\n","Loss 0.6403865669712876 : \t            Valid_acc : 0.8065328607694039\t            Valid_F1 : 0.8927436333534408\t            Valid_precision : 1.0\t            Valid_recall : 0.8065328607694039\n","[2][80] f1[80] 0.8927436333534408 (0.8657260955846291)\n","Loss 0.7736447277394208 : \t            Valid_acc : 0.7810232435069112\t            Valid_F1 : 0.8768302059184393\t            Valid_precision : 1.0\t            Valid_recall : 0.7810232435069112\n","[2][81] f1[81] 0.8768302059184393 (0.8657260955846291)\n","Loss 0.6428866684436798 : \t            Valid_acc : 0.8106161311309676\t            Valid_F1 : 0.8952503999031467\t            Valid_precision : 1.0\t            Valid_recall : 0.8106161311309676\n","[2][82] f1[82] 0.8952503999031467 (0.8657260955846291)\n","Loss 0.7220536781982942 : \t            Valid_acc : 0.7940578452449845\t            Valid_F1 : 0.8850146662802246\t            Valid_precision : 1.0\t            Valid_recall : 0.7940578452449845\n","[2][83] f1[83] 0.8850146662802246 (0.8657260955846291)\n","Loss 0.6662561830246088 : \t            Valid_acc : 0.8106551532617767\t            Valid_F1 : 0.8952504011850043\t            Valid_precision : 1.0\t            Valid_recall : 0.8106551532617767\n","[2][84] f1[84] 0.8952504011850043 (0.8657260955846291)\n","Loss 0.7239981099511638 : \t            Valid_acc : 0.7906492814949859\t            Valid_F1 : 0.8829555265593765\t            Valid_precision : 1.0\t            Valid_recall : 0.7906492814949859\n","[2][85] f1[85] 0.8829555265593765 (0.8657260955846291)\n","Loss 0.6798467676747929 : \t            Valid_acc : 0.8023399373387546\t            Valid_F1 : 0.890180603056878\t            Valid_precision : 1.0\t            Valid_recall : 0.8023399373387546\n","[2][86] f1[86] 0.890180603056878 (0.8657260955846291)\n","Loss 0.6752288833712087 : \t            Valid_acc : 0.7972756624720502\t            Valid_F1 : 0.8870779025355098\t            Valid_precision : 1.0\t            Valid_recall : 0.7972756624720502\n","[2][87] f1[87] 0.8870779025355098 (0.8657260955846291)\n","Loss 0.6222922783909421 : \t            Valid_acc : 0.808836583814169\t            Valid_F1 : 0.8941757152341636\t            Valid_precision : 1.0\t            Valid_recall : 0.808836583814169\n","[2][88] f1[88] 0.8941757152341636 (0.8657260955846291)\n","Loss 0.6773600966641398 : \t            Valid_acc : 0.8066574688052082\t            Valid_F1 : 0.8927918267766306\t            Valid_precision : 1.0\t            Valid_recall : 0.8066574688052082\n","[2][89] f1[89] 0.8927918267766306 (0.8657260955846291)\n","Loss 0.7427057533553152 : \t            Valid_acc : 0.7927108445938897\t            Valid_F1 : 0.8841777737309922\t            Valid_precision : 1.0\t            Valid_recall : 0.7927108445938897\n","[2][90] f1[90] 0.8841777737309922 (0.8657260955846291)\n","Loss 0.6441827556400588 : \t            Valid_acc : 0.8133286814869144\t            Valid_F1 : 0.8968953071141123\t            Valid_precision : 1.0\t            Valid_recall : 0.8133286814869144\n","[2][91] f1[91] 0.8968953071141123 (0.8657260955846291)\n","Loss 0.5948507510351412 : \t            Valid_acc : 0.8235475628373199\t            Valid_F1 : 0.903036974267902\t            Valid_precision : 1.0\t            Valid_recall : 0.8235475628373199\n","[2][92] f1[92] 0.903036974267902 (0.8657260955846291)\n","Loss 0.6313038775415132 : \t            Valid_acc : 0.8103650668548937\t            Valid_F1 : 0.8950277487924493\t            Valid_precision : 1.0\t            Valid_recall : 0.8103650668548937\n","[2][93] f1[93] 0.8950277487924493 (0.8657260955846291)\n","Loss 0.6879151589942701 : \t            Valid_acc : 0.8007593119919205\t            Valid_F1 : 0.8891359945524688\t            Valid_precision : 1.0\t            Valid_recall : 0.8007593119919205\n","[2][94] f1[94] 0.8891359945524688 (0.8657260955846291)\n","Loss 0.6954882162989993 : \t            Valid_acc : 0.7995575989561096\t            Valid_F1 : 0.8884295906825652\t            Valid_precision : 1.0\t            Valid_recall : 0.7995575989561096\n","[2][95] f1[95] 0.8884295906825652 (0.8657260955846291)\n","Loss 0.6719852144067938 : \t            Valid_acc : 0.8030548341355054\t            Valid_F1 : 0.8906137521911\t            Valid_precision : 1.0\t            Valid_recall : 0.8030548341355054\n","[2][96] f1[96] 0.8906137521911 (0.8657260955846291)\n","Loss 0.7752708833325993 : \t            Valid_acc : 0.7697386758267364\t            Valid_F1 : 0.8697104803518668\t            Valid_precision : 1.0\t            Valid_recall : 0.7697386758267364\n","[2][97] f1[97] 0.8697104803518668 (0.8657260955846291)\n","Loss 0.6548377293528933 : \t            Valid_acc : 0.8071506556244515\t            Valid_F1 : 0.893168513132097\t            Valid_precision : 1.0\t            Valid_recall : 0.8071506556244515\n","[2][98] f1[98] 0.893168513132097 (0.8657260955846291)\n","Loss 0.7872998962799708 : \t            Valid_acc : 0.7803246509605566\t            Valid_F1 : 0.8763624374021983\t            Valid_precision : 1.0\t            Valid_recall : 0.7803246509605566\n","[2][99] f1[99] 0.8763624374021983 (0.8657260955846291)\n","Worst f1 0.8657260955846291 with candidates [621, 13890, 13064, 0, 0]\n","candidates [23540  8351 18659 10832 11944  6850  7320 27960 20807 18335 27126 29171\n"," 28788  2943 10590  6093  9453 19030 25627 18890 11489 14910  3365 25159\n","  7257  9317  2403  7843  6174 14640 11000 19676 11568 16893 22464 15136\n"," 11893 28022 29905 23629 17421 18809  1756 12468 12957 23597 19090  9654\n"," 10684 22397 26095 16217  1897 18643 15166 12806 28276 23321  3950 18739\n"," 11580  2843  6934 25458 29897 17397 24299 16583  8345 23528  4318  4399\n"," 20775  1524  2026  4912  8222  4152  7652 23113 12099 25262 16427 26167\n"," 22421 24575 20393  4648 18808  3955 11016 23167  6354  8863 14422  8503\n"," 22948 29951 17879 25315]\n","Loss 0.79656999716253 : \t            Valid_acc : 0.7666724747254053\t            Valid_F1 : 0.8676439647256664\t            Valid_precision : 1.0\t            Valid_recall : 0.7666724747254053\n","[3][0] f1[0] 0.8676439647256664 (0.8657260955846291)\n","Loss 0.7735401775800821 : \t            Valid_acc : 0.7739273618621698\t            Valid_F1 : 0.8722800953510058\t            Valid_precision : 1.0\t            Valid_recall : 0.7739273618621698\n","[3][1] f1[1] 0.8722800953510058 (0.8657260955846291)\n","Loss 0.7676913864684828 : \t            Valid_acc : 0.7722130660718902\t            Valid_F1 : 0.8712334848258314\t            Valid_precision : 1.0\t            Valid_recall : 0.7722130660718902\n","[3][2] f1[2] 0.8712334848258314 (0.8657260955846291)\n","Loss 0.7932436588135633 : \t            Valid_acc : 0.7704996017046296\t            Valid_F1 : 0.8701196505241053\t            Valid_precision : 1.0\t            Valid_recall : 0.7704996017046296\n","[3][3] f1[3] 0.8701196505241053 (0.8657260955846291)\n","Loss 0.8079066213333246 : \t            Valid_acc : 0.7592634014584839\t            Valid_F1 : 0.8628531811606603\t            Valid_precision : 1.0\t            Valid_recall : 0.7592634014584839\n","[3][4] f1[4] 0.8628531811606603 (0.8628531811606603)\n","Loss 0.820574324239384 : \t            Valid_acc : 0.7671073559212488\t            Valid_F1 : 0.8679493264076475\t            Valid_precision : 1.0\t            Valid_recall : 0.7671073559212488\n","[3][5] f1[5] 0.8679493264076475 (0.8628531811606603)\n","Loss 0.731968287265662 : \t            Valid_acc : 0.7795318879815915\t            Valid_F1 : 0.8758828363348261\t            Valid_precision : 1.0\t            Valid_recall : 0.7795318879815915\n","[3][6] f1[6] 0.8758828363348261 (0.8628531811606603)\n","Loss 0.8754045480128491 : \t            Valid_acc : 0.7457527091182407\t            Valid_F1 : 0.8540706872171748\t            Valid_precision : 1.0\t            Valid_recall : 0.7457527091182407\n","[3][7] f1[7] 0.8540706872171748 (0.8540706872171748)\n","Loss 0.7943439533313116 : \t            Valid_acc : 0.7694832331583777\t            Valid_F1 : 0.8694532424725668\t            Valid_precision : 1.0\t            Valid_recall : 0.7694832331583777\n","[3][8] f1[8] 0.8694532424725668 (0.8540706872171748)\n","Loss 0.8443039312507167 : \t            Valid_acc : 0.7548640126175028\t            Valid_F1 : 0.8600238022484163\t            Valid_precision : 1.0\t            Valid_recall : 0.7548640126175028\n","[3][9] f1[9] 0.8600238022484163 (0.8540706872171748)\n","Loss 0.847015464847738 : \t            Valid_acc : 0.7493090489923826\t            Valid_F1 : 0.85641461158214\t            Valid_precision : 1.0\t            Valid_recall : 0.7493090489923826\n","[3][10] f1[10] 0.85641461158214 (0.8540706872171748)\n","Loss 0.8429849283261732 : \t            Valid_acc : 0.7497027552898005\t            Valid_F1 : 0.8567234591246735\t            Valid_precision : 1.0\t            Valid_recall : 0.7497027552898005\n","[3][11] f1[11] 0.8567234591246735 (0.8540706872171748)\n","Loss 0.7616591878009565 : \t            Valid_acc : 0.76302038329084\t            Valid_F1 : 0.8654014349092218\t            Valid_precision : 1.0\t            Valid_recall : 0.76302038329084\n","[3][12] f1[12] 0.8654014349092218 (0.8540706872171748)\n","Loss 0.7725195803425529 : \t            Valid_acc : 0.7770543005594792\t            Valid_F1 : 0.8742023709608705\t            Valid_precision : 1.0\t            Valid_recall : 0.7770543005594792\n","[3][13] f1[13] 0.8742023709608705 (0.8540706872171748)\n","Loss 0.7953537490331766 : \t            Valid_acc : 0.7597499189769626\t            Valid_F1 : 0.8631906862154172\t            Valid_precision : 1.0\t            Valid_recall : 0.7597499189769626\n","[3][14] f1[14] 0.8631906862154172 (0.8540706872171748)\n","Loss 0.7661136953216611 : \t            Valid_acc : 0.775019991570162\t            Valid_F1 : 0.8729946772411044\t            Valid_precision : 1.0\t            Valid_recall : 0.775019991570162\n","[3][15] f1[15] 0.8729946772411044 (0.8540706872171748)\n","Loss 0.7983435089841033 : \t            Valid_acc : 0.7657334410517471\t            Valid_F1 : 0.8670337341500751\t            Valid_precision : 1.0\t            Valid_recall : 0.7657334410517471\n","[3][16] f1[16] 0.8670337341500751 (0.8540706872171748)\n","Loss 0.8990086886015806 : \t            Valid_acc : 0.7347698302686556\t            Valid_F1 : 0.8469045308280388\t            Valid_precision : 1.0\t            Valid_recall : 0.7347698302686556\n","[3][17] f1[17] 0.8469045308280388 (0.8469045308280388)\n","Loss 0.8466104567050934 : \t            Valid_acc : 0.7478709008966089\t            Valid_F1 : 0.8555045454331728\t            Valid_precision : 1.0\t            Valid_recall : 0.7478709008966089\n","[3][18] f1[18] 0.8555045454331728 (0.8469045308280388)\n","Loss 0.7978269426208554 : \t            Valid_acc : 0.7608144057128385\t            Valid_F1 : 0.8639053218443937\t            Valid_precision : 1.0\t            Valid_recall : 0.7608144057128385\n","[3][19] f1[19] 0.8639053218443937 (0.8469045308280388)\n","Loss 0.7972904861424909 : \t            Valid_acc : 0.7674005788733279\t            Valid_F1 : 0.868138883367719\t            Valid_precision : 1.0\t            Valid_recall : 0.7674005788733279\n","[3][20] f1[20] 0.868138883367719 (0.8469045308280388)\n","Loss 0.7571693780747327 : \t            Valid_acc : 0.7728854205389909\t            Valid_F1 : 0.871634247157728\t            Valid_precision : 1.0\t            Valid_recall : 0.7728854205389909\n","[3][21] f1[21] 0.871634247157728 (0.8469045308280388)\n","Loss 0.7916361951466763 : \t            Valid_acc : 0.7723760355575306\t            Valid_F1 : 0.8713213604970615\t            Valid_precision : 1.0\t            Valid_recall : 0.7723760355575306\n","[3][22] f1[22] 0.8713213604970615 (0.8469045308280388)\n","Loss 0.7541408543333863 : \t            Valid_acc : 0.7781837180222861\t            Valid_F1 : 0.8750317734286995\t            Valid_precision : 1.0\t            Valid_recall : 0.7781837180222861\n","[3][23] f1[23] 0.8750317734286995 (0.8469045308280388)\n","Loss 0.6996015414144053 : \t            Valid_acc : 0.7974945976919531\t            Valid_F1 : 0.8870950263372059\t            Valid_precision : 1.0\t            Valid_recall : 0.7974945976919531\n","[3][24] f1[24] 0.8870950263372059 (0.8469045308280388)\n","Loss 0.8363230151660515 : \t            Valid_acc : 0.7524339852360235\t            Valid_F1 : 0.8584571613939225\t            Valid_precision : 1.0\t            Valid_recall : 0.7524339852360235\n","[3][25] f1[25] 0.8584571613939225 (0.8469045308280388)\n","Loss 0.800804970390869 : \t            Valid_acc : 0.7711298444513789\t            Valid_F1 : 0.8705458881472341\t            Valid_precision : 1.0\t            Valid_recall : 0.7711298444513789\n","[3][26] f1[26] 0.8705458881472341 (0.8469045308280388)\n","Loss 0.7849980385014506 : \t            Valid_acc : 0.7717875787045166\t            Valid_F1 : 0.8709249905008489\t            Valid_precision : 1.0\t            Valid_recall : 0.7717875787045166\n","[3][27] f1[27] 0.8709249905008489 (0.8469045308280388)\n","Loss 0.9119780451962443 : \t            Valid_acc : 0.7333001046425105\t            Valid_F1 : 0.845830307847214\t            Valid_precision : 1.0\t            Valid_recall : 0.7333001046425105\n","[3][28] f1[28] 0.845830307847214 (0.845830307847214)\n","Loss 0.8362605355002664 : \t            Valid_acc : 0.7536920757230342\t            Valid_F1 : 0.8592798969007631\t            Valid_precision : 1.0\t            Valid_recall : 0.7536920757230342\n","[3][29] f1[29] 0.8592798969007631 (0.845830307847214)\n","Loss 0.7851330809520952 : \t            Valid_acc : 0.767840889121887\t            Valid_F1 : 0.8684182610879736\t            Valid_precision : 1.0\t            Valid_recall : 0.767840889121887\n","[3][30] f1[30] 0.8684182610879736 (0.845830307847214)\n","Loss 0.7908169586550106 : \t            Valid_acc : 0.7681673025011557\t            Valid_F1 : 0.8686150989365159\t            Valid_precision : 1.0\t            Valid_recall : 0.7681673025011557\n","[3][31] f1[31] 0.8686150989365159 (0.845830307847214)\n","Loss 0.7564262544566934 : \t            Valid_acc : 0.7745419791742069\t            Valid_F1 : 0.8727133508751987\t            Valid_precision : 1.0\t            Valid_recall : 0.7745419791742069\n","[3][32] f1[32] 0.8727133508751987 (0.845830307847214)\n","Loss 0.8266738219694658 : \t            Valid_acc : 0.7601407370377858\t            Valid_F1 : 0.8635257466929158\t            Valid_precision : 1.0\t            Valid_recall : 0.7601407370377858\n","[3][33] f1[33] 0.8635257466929158 (0.845830307847214)\n","Loss 0.8313717679543928 : \t            Valid_acc : 0.7615583164200358\t            Valid_F1 : 0.8643678999899532\t            Valid_precision : 1.0\t            Valid_recall : 0.7615583164200358\n","[3][34] f1[34] 0.8643678999899532 (0.845830307847214)\n","Loss 0.8327577290209857 : \t            Valid_acc : 0.7523397882313475\t            Valid_F1 : 0.8583886267111484\t            Valid_precision : 1.0\t            Valid_recall : 0.7523397882313475\n","[3][35] f1[35] 0.8583886267111484 (0.845830307847214)\n","Loss 0.8134030690698912 : \t            Valid_acc : 0.7592787084688296\t            Valid_F1 : 0.8628830361519088\t            Valid_precision : 1.0\t            Valid_recall : 0.7592787084688296\n","[3][36] f1[36] 0.8628830361519088 (0.845830307847214)\n","Loss 0.7547705751476865 : \t            Valid_acc : 0.7819219801181918\t            Valid_F1 : 0.8773995667859401\t            Valid_precision : 1.0\t            Valid_recall : 0.7819219801181918\n","[3][37] f1[37] 0.8773995667859401 (0.845830307847214)\n","Loss 0.8306518043532516 : \t            Valid_acc : 0.7571076259937641\t            Valid_F1 : 0.8614319920395492\t            Valid_precision : 1.0\t            Valid_recall : 0.7571076259937641\n","[3][38] f1[38] 0.8614319920395492 (0.845830307847214)\n","Loss 0.8113440081025615 : \t            Valid_acc : 0.7655685796300324\t            Valid_F1 : 0.8669551099204974\t            Valid_precision : 1.0\t            Valid_recall : 0.7655685796300324\n","[3][39] f1[39] 0.8669551099204974 (0.845830307847214)\n","Loss 0.8570860683014898 : \t            Valid_acc : 0.7514675298128073\t            Valid_F1 : 0.8578174380965705\t            Valid_precision : 1.0\t            Valid_recall : 0.7514675298128073\n","[3][40] f1[40] 0.8578174380965705 (0.845830307847214)\n","Loss 0.804070899883906 : \t            Valid_acc : 0.760702424990098\t            Valid_F1 : 0.8638189680959277\t            Valid_precision : 1.0\t            Valid_recall : 0.760702424990098\n","[3][41] f1[41] 0.8638189680959277 (0.845830307847214)\n","Loss 0.8884155361941366 : \t            Valid_acc : 0.7414175113747501\t            Valid_F1 : 0.8511793562813791\t            Valid_precision : 1.0\t            Valid_recall : 0.7414175113747501\n","[3][42] f1[42] 0.8511793562813791 (0.845830307847214)\n","Loss 0.7954167077938715 : \t            Valid_acc : 0.7676116636620021\t            Valid_F1 : 0.8682633413479384\t            Valid_precision : 1.0\t            Valid_recall : 0.7676116636620021\n","[3][43] f1[43] 0.8682633413479384 (0.845830307847214)\n","Loss 0.8556178212165833 : \t            Valid_acc : 0.7509425199041412\t            Valid_F1 : 0.8574828760607489\t            Valid_precision : 1.0\t            Valid_recall : 0.7509425199041412\n","[3][44] f1[44] 0.8574828760607489 (0.845830307847214)\n","Loss 0.7612134389805071 : \t            Valid_acc : 0.7781454639513951\t            Valid_F1 : 0.8749977410202863\t            Valid_precision : 1.0\t            Valid_recall : 0.7781454639513951\n","[3][45] f1[45] 0.8749977410202863 (0.845830307847214)\n","Loss 0.8183938779614188 : \t            Valid_acc : 0.7546750443708415\t            Valid_F1 : 0.8599242026117861\t            Valid_precision : 1.0\t            Valid_recall : 0.7546750443708415\n","[3][46] f1[46] 0.8599242026117861 (0.845830307847214)\n","Loss 0.7972794545419288 : \t            Valid_acc : 0.7562665070283564\t            Valid_F1 : 0.8609495903327321\t            Valid_precision : 1.0\t            Valid_recall : 0.7562665070283564\n","[3][47] f1[47] 0.8609495903327321 (0.845830307847214)\n","Loss 0.8304862890279654 : \t            Valid_acc : 0.7547892916350694\t            Valid_F1 : 0.8600046904161843\t            Valid_precision : 1.0\t            Valid_recall : 0.7547892916350694\n","[3][48] f1[48] 0.8600046904161843 (0.845830307847214)\n","Loss 0.7952817321726771 : \t            Valid_acc : 0.7630333889708386\t            Valid_F1 : 0.8653464634573236\t            Valid_precision : 1.0\t            Valid_recall : 0.7630333889708386\n","[3][49] f1[49] 0.8653464634573236 (0.845830307847214)\n","Loss 0.7926319697589586 : \t            Valid_acc : 0.7623952322802996\t            Valid_F1 : 0.8649468071061641\t            Valid_precision : 1.0\t            Valid_recall : 0.7623952322802996\n","[3][50] f1[50] 0.8649468071061641 (0.845830307847214)\n","Loss 0.8054826521512234 : \t            Valid_acc : 0.7607190382123835\t            Valid_F1 : 0.8637801334958745\t            Valid_precision : 1.0\t            Valid_recall : 0.7607190382123835\n","[3][51] f1[51] 0.8637801334958745 (0.845830307847214)\n","Loss 0.9309258876424847 : \t            Valid_acc : 0.7291727702213222\t            Valid_F1 : 0.8430444032267675\t            Valid_precision : 1.0\t            Valid_recall : 0.7291727702213222\n","[3][52] f1[52] 0.8430444032267675 (0.8430444032267675)\n","Loss 0.7489526176994498 : \t            Valid_acc : 0.7761723872455181\t            Valid_F1 : 0.873751702943011\t            Valid_precision : 1.0\t            Valid_recall : 0.7761723872455181\n","[3][53] f1[53] 0.873751702943011 (0.8430444032267675)\n","Loss 0.8181156945047956 : \t            Valid_acc : 0.7579876462651381\t            Valid_F1 : 0.8620575693660029\t            Valid_precision : 1.0\t            Valid_recall : 0.7579876462651381\n","[3][54] f1[54] 0.8620575693660029 (0.8430444032267675)\n","Loss 0.7882020913741805 : \t            Valid_acc : 0.7632036245599222\t            Valid_F1 : 0.865481370297968\t            Valid_precision : 1.0\t            Valid_recall : 0.7632036245599222\n","[3][55] f1[55] 0.865481370297968 (0.8430444032267675)\n","Loss 0.7699594127409386 : \t            Valid_acc : 0.7642830884398354\t            Valid_F1 : 0.8661337146757763\t            Valid_precision : 1.0\t            Valid_recall : 0.7642830884398354\n","[3][56] f1[56] 0.8661337146757763 (0.8430444032267675)\n","Loss 0.85131825280912 : \t            Valid_acc : 0.7479385164559448\t            Valid_F1 : 0.8554912843562386\t            Valid_precision : 1.0\t            Valid_recall : 0.7479385164559448\n","[3][57] f1[57] 0.8554912843562386 (0.8430444032267675)\n","Loss 0.828200852780631 : \t            Valid_acc : 0.7538039682688982\t            Valid_F1 : 0.8593751945501786\t            Valid_precision : 1.0\t            Valid_recall : 0.7538039682688982\n","[3][58] f1[58] 0.8593751945501786 (0.8430444032267675)\n","Loss 0.8399021909995512 : \t            Valid_acc : 0.7560055632837531\t            Valid_F1 : 0.8607593605069291\t            Valid_precision : 1.0\t            Valid_recall : 0.7560055632837531\n","[3][59] f1[59] 0.8607593605069291 (0.8430444032267675)\n","Loss 0.8082382755749153 : \t            Valid_acc : 0.7575041882754942\t            Valid_F1 : 0.8617334322367395\t            Valid_precision : 1.0\t            Valid_recall : 0.7575041882754942\n","[3][60] f1[60] 0.8617334322367395 (0.8430444032267675)\n","Loss 0.8941928784955632 : \t            Valid_acc : 0.7425109833422774\t            Valid_F1 : 0.8519209267361295\t            Valid_precision : 1.0\t            Valid_recall : 0.7425109833422774\n","[3][61] f1[61] 0.8519209267361295 (0.8430444032267675)\n","Loss 0.7103141013419989 : \t            Valid_acc : 0.7861924158349424\t            Valid_F1 : 0.8801220837832646\t            Valid_precision : 1.0\t            Valid_recall : 0.7861924158349424\n","[3][62] f1[62] 0.8801220837832646 (0.8430444032267675)\n","Loss 0.8035323109590646 : \t            Valid_acc : 0.7593728645094213\t            Valid_F1 : 0.8629809805288123\t            Valid_precision : 1.0\t            Valid_recall : 0.7593728645094213\n","[3][63] f1[63] 0.8629809805288123 (0.8430444032267675)\n","Loss 0.7887261898228617 : \t            Valid_acc : 0.76574021175479\t            Valid_F1 : 0.8670800484547424\t            Valid_precision : 1.0\t            Valid_recall : 0.76574021175479\n","[3][64] f1[64] 0.8670800484547424 (0.8430444032267675)\n","Loss 0.7942687760699879 : \t            Valid_acc : 0.7623910012263582\t            Valid_F1 : 0.8649159218024589\t            Valid_precision : 1.0\t            Valid_recall : 0.7623910012263582\n","[3][65] f1[65] 0.8649159218024589 (0.8430444032267675)\n","Loss 0.791045755147934 : \t            Valid_acc : 0.7622751104938028\t            Valid_F1 : 0.8648242453486095\t            Valid_precision : 1.0\t            Valid_recall : 0.7622751104938028\n","[3][66] f1[66] 0.8648242453486095 (0.8430444032267675)\n","Loss 0.8553799458525397 : \t            Valid_acc : 0.7571438810791324\t            Valid_F1 : 0.8614935080819046\t            Valid_precision : 1.0\t            Valid_recall : 0.7571438810791324\n","[3][67] f1[67] 0.8614935080819046 (0.8430444032267675)\n","Loss 0.8620064077955304 : \t            Valid_acc : 0.7496577980622685\t            Valid_F1 : 0.8566301975663217\t            Valid_precision : 1.0\t            Valid_recall : 0.7496577980622685\n","[3][68] f1[68] 0.8566301975663217 (0.8430444032267675)\n","Loss 0.8377173940340678 : \t            Valid_acc : 0.7450551938087245\t            Valid_F1 : 0.853668970533719\t            Valid_precision : 1.0\t            Valid_recall : 0.7450551938087245\n","[3][69] f1[69] 0.853668970533719 (0.8430444032267675)\n","Loss 0.8364481632456635 : \t            Valid_acc : 0.7476460870931656\t            Valid_F1 : 0.8553913464079824\t            Valid_precision : 1.0\t            Valid_recall : 0.7476460870931656\n","[3][70] f1[70] 0.8553913464079824 (0.8430444032267675)\n","Loss 0.7212421067736365 : \t            Valid_acc : 0.7903289717360271\t            Valid_F1 : 0.8826498299349907\t            Valid_precision : 1.0\t            Valid_recall : 0.7903289717360271\n","[3][71] f1[71] 0.8826498299349907 (0.8430444032267675)\n","Loss 0.7791335149244829 : \t            Valid_acc : 0.7680436757436417\t            Valid_F1 : 0.8685575343144077\t            Valid_precision : 1.0\t            Valid_recall : 0.7680436757436417\n","[3][72] f1[72] 0.8685575343144077 (0.8430444032267675)\n","Loss 0.6865432826858578 : \t            Valid_acc : 0.7804126603682909\t            Valid_F1 : 0.8764748942485708\t            Valid_precision : 1.0\t            Valid_recall : 0.7804126603682909\n","[3][73] f1[73] 0.8764748942485708 (0.8430444032267675)\n","Loss 0.9372702584122167 : \t            Valid_acc : 0.7316954476556453\t            Valid_F1 : 0.8446625820296308\t            Valid_precision : 1.0\t            Valid_recall : 0.7316954476556453\n","[3][74] f1[74] 0.8446625820296308 (0.8430444032267675)\n","Loss 0.7992784371881774 : \t            Valid_acc : 0.7614568563927362\t            Valid_F1 : 0.8643045754524051\t            Valid_precision : 1.0\t            Valid_recall : 0.7614568563927362\n","[3][75] f1[75] 0.8643045754524051 (0.8430444032267675)\n","Loss 0.8119208731434562 : \t            Valid_acc : 0.768590990554444\t            Valid_F1 : 0.8688474382501266\t            Valid_precision : 1.0\t            Valid_recall : 0.768590990554444\n","[3][76] f1[76] 0.8688474382501266 (0.8430444032267675)\n","Loss 0.7935662247014769 : \t            Valid_acc : 0.7741036387165318\t            Valid_F1 : 0.8724176170456327\t            Valid_precision : 1.0\t            Valid_recall : 0.7741036387165318\n","[3][77] f1[77] 0.8724176170456327 (0.8430444032267675)\n","Loss 0.7463965334675529 : \t            Valid_acc : 0.7812812432217812\t            Valid_F1 : 0.8769490564261985\t            Valid_precision : 1.0\t            Valid_recall : 0.7812812432217812\n","[3][78] f1[78] 0.8769490564261985 (0.8430444032267675)\n","Loss 0.8420267701148987 : \t            Valid_acc : 0.7453902223771599\t            Valid_F1 : 0.8539092608497072\t            Valid_precision : 1.0\t            Valid_recall : 0.7453902223771599\n","[3][79] f1[79] 0.8539092608497072 (0.8430444032267675)\n","Loss 0.852517153729092 : \t            Valid_acc : 0.7449940574790039\t            Valid_F1 : 0.8535769665486767\t            Valid_precision : 1.0\t            Valid_recall : 0.7449940574790039\n","[3][80] f1[80] 0.8535769665486767 (0.8430444032267675)\n","Loss 0.7873610131668322 : \t            Valid_acc : 0.7640410118379155\t            Valid_F1 : 0.8659461712712104\t            Valid_precision : 1.0\t            Valid_recall : 0.7640410118379155\n","[3][81] f1[81] 0.8659461712712104 (0.8430444032267675)\n","Loss 0.8163909108349772 : \t            Valid_acc : 0.7605231205583353\t            Valid_F1 : 0.8637302285755621\t            Valid_precision : 1.0\t            Valid_recall : 0.7605231205583353\n","[3][82] f1[82] 0.8637302285755621 (0.8430444032267675)\n","Loss 0.7438354392846426 : \t            Valid_acc : 0.7750503513667901\t            Valid_F1 : 0.8730046186202641\t            Valid_precision : 1.0\t            Valid_recall : 0.7750503513667901\n","[3][83] f1[83] 0.8730046186202641 (0.8430444032267675)\n","Loss 0.796375317103935 : \t            Valid_acc : 0.7628673213753389\t            Valid_F1 : 0.8652249417106834\t            Valid_precision : 1.0\t            Valid_recall : 0.7628673213753389\n","[3][84] f1[84] 0.8652249417106834 (0.8430444032267675)\n","Loss 0.817825457814968 : \t            Valid_acc : 0.7511161330456182\t            Valid_F1 : 0.8576014382983685\t            Valid_precision : 1.0\t            Valid_recall : 0.7511161330456182\n","[3][85] f1[85] 0.8576014382983685 (0.8430444032267675)\n","Loss 0.7918235921498501 : \t            Valid_acc : 0.7713621313816775\t            Valid_F1 : 0.8706810060454595\t            Valid_precision : 1.0\t            Valid_recall : 0.7713621313816775\n","[3][86] f1[86] 0.8706810060454595 (0.8430444032267675)\n","Loss 0.9128963102897009 : \t            Valid_acc : 0.7343681856376104\t            Valid_F1 : 0.846521435089613\t            Valid_precision : 1.0\t            Valid_recall : 0.7343681856376104\n","[3][87] f1[87] 0.846521435089613 (0.8430444032267675)\n","Loss 0.776948700122761 : \t            Valid_acc : 0.7718569938317597\t            Valid_F1 : 0.8709834204931044\t            Valid_precision : 1.0\t            Valid_recall : 0.7718569938317597\n","[3][88] f1[88] 0.8709834204931044 (0.8430444032267675)\n","Loss 0.8499069435126854 : \t            Valid_acc : 0.7545689426956532\t            Valid_F1 : 0.8597827647873109\t            Valid_precision : 1.0\t            Valid_recall : 0.7545689426956532\n","[3][89] f1[89] 0.8597827647873109 (0.8430444032267675)\n","Loss 0.8174688910896127 : \t            Valid_acc : 0.7590551522962645\t            Valid_F1 : 0.8627843868255812\t            Valid_precision : 1.0\t            Valid_recall : 0.7590551522962645\n","[3][90] f1[90] 0.8627843868255812 (0.8430444032267675)\n","Loss 0.7757107516129812 : \t            Valid_acc : 0.7709563437914465\t            Valid_F1 : 0.8704036542697625\t            Valid_precision : 1.0\t            Valid_recall : 0.7709563437914465\n","[3][91] f1[91] 0.8704036542697625 (0.8430444032267675)\n","Loss 0.7096129100431096 : \t            Valid_acc : 0.7925064258613731\t            Valid_F1 : 0.8840566678361758\t            Valid_precision : 1.0\t            Valid_recall : 0.7925064258613731\n","[3][92] f1[92] 0.8840566678361758 (0.8430444032267675)\n","Loss 0.8005356639623642 : \t            Valid_acc : 0.7675946018532871\t            Valid_F1 : 0.8682492110017801\t            Valid_precision : 1.0\t            Valid_recall : 0.7675946018532871\n","[3][93] f1[93] 0.8682492110017801 (0.8430444032267675)\n","Loss 0.8170672537702502 : \t            Valid_acc : 0.7636468634016225\t            Valid_F1 : 0.8657005810644898\t            Valid_precision : 1.0\t            Valid_recall : 0.7636468634016225\n","[3][94] f1[94] 0.8657005810644898 (0.8430444032267675)\n","Loss 0.7919517475547213 : \t            Valid_acc : 0.7637364257068858\t            Valid_F1 : 0.8658093300660115\t            Valid_precision : 1.0\t            Valid_recall : 0.7637364257068858\n","[3][95] f1[95] 0.8658093300660115 (0.8430444032267675)\n","Loss 0.8164697519757531 : \t            Valid_acc : 0.7522438936397469\t            Valid_F1 : 0.8583174934095773\t            Valid_precision : 1.0\t            Valid_recall : 0.7522438936397469\n","[3][96] f1[96] 0.8583174934095773 (0.8430444032267675)\n","Loss 0.7971048793106368 : \t            Valid_acc : 0.758622847247287\t            Valid_F1 : 0.862507725008385\t            Valid_precision : 1.0\t            Valid_recall : 0.758622847247287\n","[3][97] f1[97] 0.862507725008385 (0.8430444032267675)\n","Loss 0.7662248286333951 : \t            Valid_acc : 0.7739158275766075\t            Valid_F1 : 0.8723066527343858\t            Valid_precision : 1.0\t            Valid_recall : 0.7739158275766075\n","[3][98] f1[98] 0.8723066527343858 (0.8430444032267675)\n","Loss 0.8358416552796508 : \t            Valid_acc : 0.757228063343773\t            Valid_F1 : 0.8615523676188697\t            Valid_precision : 1.0\t            Valid_recall : 0.757228063343773\n","[3][99] f1[99] 0.8615523676188697 (0.8430444032267675)\n","Worst f1 0.8430444032267675 with candidates [621, 13890, 13064, 1897, 0]\n","candidates [  457  1886   936   230   488  1015   195   245  1686   575   420  2818\n","   213   508   601  1951  1287  1042   531   117   696  1810  2308  1131\n","   396   581  2828   314  2852   530   226  2577   175   466  4466  2520\n","  1568   212   238  1703   115   184   351   348   740   715  1532  1026\n","  2294   757  1956  2591   174   475  1579  2318  1899  1857   215   119\n","  2151   854  3632   247   435   118  3180  1004   210   301   487  1629\n","   633  5238  1812  6528   361  6292  5141  1351   558   476  2225   211\n"," 18890   252  2036  3323  3810   452  1679  1225  6354  3915   217  1114\n","  2835  4775  4338  1591]\n","Loss 0.8471194785652738 : \t            Valid_acc : 0.7562259576859635\t            Valid_F1 : 0.8609714864266275\t            Valid_precision : 1.0\t            Valid_recall : 0.7562259576859635\n","[4][0] f1[0] 0.8609714864266275 (0.8430444032267675)\n","Loss 1.0542959570884705 : \t            Valid_acc : 0.7064879956619845\t            Valid_F1 : 0.8276137966466709\t            Valid_precision : 1.0\t            Valid_recall : 0.7064879956619845\n","[4][1] f1[1] 0.8276137966466709 (0.8276137966466709)\n"]}]},{"cell_type":"code","source":["#print(tokenizer.decode([621, 4865, 21241]))\n","#print(tokenizer.decode([621, 13890, 21241]))# Loss => unless communist normativ\n","#print(tokenizer.decode([621, 13890, 13064]))# Accuracy => unless communist tolerate\n","#print(tokenizer.decode([621, 13890, 13064]))# F1 => unless communist tolerate\n","#print(tokenizer.encode(\"the the the\")) #[101, 207, 207, 207, 102]"],"metadata":{"id":"pdhC5LNWQk_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","extracted_grads = []\n","model.eval()\n","model.to(device)\n","loss_obtained = get_loss_and_metrics(model, dataloader, device)\n","print(f'loss_obtained {loss_obtained}')\n","\"\"\""],"metadata":{"id":"S4JCX2TmE_yA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","extracted_grads = []\n","\n","# get initial loss for the trigger\n","model.zero_grad()\n","loss = get_loss(model, BATCH_SIZE, trigger_tokens, target_tokens, device)\n","best_loss = loss\n","counter = 0\n","end_iter = False\n","\"\"\""],"metadata":{"id":"-nddZPP1B1RJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","del extracted_grads\n","del dataloader\n","del model\n","del input_ids\n","del attention_masks\n","del labels\n","del loss_obtained\n","del dataset\n","\"\"\""],"metadata":{"id":"3IWgPUFKkRy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()\n","\"\"\""],"metadata":{"id":"vDMAFktYISWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(extracted_grads)"],"metadata":{"id":"G4QJtyr7K8oc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids[0][1]"],"metadata":{"id":"J7cGz0zGLVeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"y5TYKJ9aUK6o"},"execution_count":null,"outputs":[]}]}